{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Approach for Unet Training \n",
    "\n",
    "------\n",
    "\n",
    "## Overview\n",
    "\n",
    "\n",
    "\n",
    "The purpose of this learn.ipynb notebook is to investigate whether an image can exhibit a preference for being segmented more effectively using a UNet model trained on polar or cartesian-dominant images.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Structure\n",
    "```\n",
    "data\n",
    "└── endoscopic\n",
    "    ├── cartesian\n",
    "    │   ├── image\n",
    "    │   └── label\n",
    "    └── polar\n",
    "        ├── image\n",
    "        └── label\n",
    "```\n",
    "\n",
    "Inside of each end folder there are 956 images, named as `0.tif` to `955.tif`\n",
    "and I believe, for now, the naming of the images are one to one correctly matched, meaning the ``/data/endoscopic/**cartesian**/image/0.tif`` is transformed from `/data/endoscopic/**polar**/image/0.tif`\n",
    "\n",
    "Instead of putting a seperate set of images aside to be test set, we chose to use k-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import from files and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from defines import *\n",
    "from model import *\n",
    "from data import *\n",
    "import sys\n",
    "\n",
    "from numpy import loadtxt\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import math\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this if your computer has a cuda visible device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20230913_155034\n"
     ]
    }
   ],
   "source": [
    "print(PARAM_SYSTEM_TIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test code for correct file structure setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize folder tree in current directory\n",
    "os.system(\"tree -d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count of files in data directories\n",
    "os.system(\"ls \" + os.path.join(PARAM_PATH_CARTE,PARAM_IMG_FOLDER) + \" | wc -l\")\n",
    "os.system(\"ls \" + os.path.join(PARAM_PATH_CARTE,PARAM_MSK_FOLDER) + \" | wc -l\")\n",
    "os.system(\"ls \" + os.path.join(PARAM_PATH_POLAR,PARAM_IMG_FOLDER) + \" | wc -l\")\n",
    "os.system(\"ls \" + os.path.join(PARAM_PATH_POLAR,PARAM_MSK_FOLDER) + \" | wc -l\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output: \n",
    "956\n",
    "956\n",
    "956\n",
    "956\n",
    "**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training test\n",
    "\n",
    "This part is used to see if we can train a model using the current configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Superparameters (temporary) for a test run of model training test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 256, 256, 64  1792        ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 256, 256, 64  36928       ['conv2d_24[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 128, 128, 64  0          ['conv2d_25[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 128, 128, 12  73856       ['max_pooling2d_4[0][0]']        \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_26[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 64, 64, 128)  0          ['conv2d_27[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 64, 64, 256)  295168      ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_28[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 256)  0          ['conv2d_29[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 32, 32, 512)  1180160     ['max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_30[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 32, 32, 512)  0           ['conv2d_31[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 512)  0          ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 16, 16, 1024  4719616     ['max_pooling2d_7[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 16, 16, 1024  9438208     ['conv2d_32[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 16, 16, 1024  0           ['conv2d_33[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSampling2D)  (None, 32, 32, 1024  0          ['dropout_3[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 32, 32, 512)  2097664     ['up_sampling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 32, 32, 1024  0           ['dropout_2[0][0]',              \n",
      "                                )                                 'conv2d_34[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 32, 32, 512)  4719104     ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_35[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_5 (UpSampling2D)  (None, 64, 64, 512)  0          ['conv2d_36[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 64, 64, 256)  524544      ['up_sampling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 64, 64, 512)  0           ['conv2d_29[0][0]',              \n",
      "                                                                  'conv2d_37[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 64, 64, 256)  1179904     ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_38[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_6 (UpSampling2D)  (None, 128, 128, 25  0          ['conv2d_39[0][0]']              \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 128, 128, 12  131200      ['up_sampling2d_6[0][0]']        \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 128, 128, 25  0           ['conv2d_27[0][0]',              \n",
      "                                6)                                'conv2d_40[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 128, 128, 12  295040      ['concatenate_6[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_41[0][0]']              \n",
      "                                8)                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " up_sampling2d_7 (UpSampling2D)  (None, 256, 256, 12  0          ['conv2d_42[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 256, 256, 64  32832       ['up_sampling2d_7[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 256, 256, 12  0           ['conv2d_25[0][0]',              \n",
      "                                8)                                'conv2d_43[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 256, 256, 64  73792       ['concatenate_7[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 256, 256, 64  36928       ['conv2d_44[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 256, 256, 2)  1154        ['conv2d_45[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 256, 256, 1)  3           ['conv2d_46[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,032,837\n",
      "Trainable params: 31,032,837\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "PARAM_BETA_TEST_NUM = 2\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "data_gen_args = dict(rotation_range=50,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    shear_range=0.35,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "temp_save_dir = os.path.join(os.getcwd(),'temp')\n",
    "test_gene = trainGenerator(batch_size, PARAM_PATH_POLAR, PARAM_IMG_FOLDER, PARAM_MSK_FOLDER, data_gen_args)\n",
    "test_model = unet(PARAM_BETA1[PARAM_BETA_TEST_NUM], PARAM_BETA2[PARAM_BETA_TEST_NUM]) \n",
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected output\n",
    "<details>\n",
    "    <summary><b><font color=\"green\">Click here to expand</font></b></summary>\n",
    "    <code>\n",
    "Model: \"model_5\"\n",
    "__________________________________________________________________________________________________\n",
    " Layer (type)                   Output Shape         Param #     Connected to                     \n",
    "==================================================================================================\n",
    " input_6 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
    "                                )]                                                                \n",
    "                                                                                                  \n",
    " conv2d_120 (Conv2D)            (None, 256, 256, 64  1792        ['input_6[0][0]']                \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_121 (Conv2D)            (None, 256, 256, 64  36928       ['conv2d_120[0][0]']             \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " max_pooling2d_20 (MaxPooling2D  (None, 128, 128, 64  0          ['conv2d_121[0][0]']             \n",
    " )                              )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_122 (Conv2D)            (None, 128, 128, 12  73856       ['max_pooling2d_20[0][0]']       \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " conv2d_123 (Conv2D)            (None, 128, 128, 12  147584      ['conv2d_122[0][0]']             \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " max_pooling2d_21 (MaxPooling2D  (None, 64, 64, 128)  0          ['conv2d_123[0][0]']             \n",
    " )                                                                                                \n",
    "                                                                                                  \n",
    " conv2d_124 (Conv2D)            (None, 64, 64, 256)  295168      ['max_pooling2d_21[0][0]']       \n",
    "                                                                                                  \n",
    " conv2d_125 (Conv2D)            (None, 64, 64, 256)  590080      ['conv2d_124[0][0]']             \n",
    "                                                                                                  \n",
    " max_pooling2d_22 (MaxPooling2D  (None, 32, 32, 256)  0          ['conv2d_125[0][0]']             \n",
    " )                                                                                                \n",
    "                                                                                                  \n",
    " conv2d_126 (Conv2D)            (None, 32, 32, 512)  1180160     ['max_pooling2d_22[0][0]']       \n",
    "                                                                                                  \n",
    " conv2d_127 (Conv2D)            (None, 32, 32, 512)  2359808     ['conv2d_126[0][0]']             \n",
    "                                                                                                  \n",
    " dropout_10 (Dropout)           (None, 32, 32, 512)  0           ['conv2d_127[0][0]']             \n",
    "                                                                                                  \n",
    " max_pooling2d_23 (MaxPooling2D  (None, 16, 16, 512)  0          ['dropout_10[0][0]']             \n",
    " )                                                                                                \n",
    "                                                                                                  \n",
    " conv2d_128 (Conv2D)            (None, 16, 16, 1024  4719616     ['max_pooling2d_23[0][0]']       \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_129 (Conv2D)            (None, 16, 16, 1024  9438208     ['conv2d_128[0][0]']             \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " dropout_11 (Dropout)           (None, 16, 16, 1024  0           ['conv2d_129[0][0]']             \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " up_sampling2d_20 (UpSampling2D  (None, 32, 32, 1024  0          ['dropout_11[0][0]']             \n",
    " )                              )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_130 (Conv2D)            (None, 32, 32, 512)  2097664     ['up_sampling2d_20[0][0]']       \n",
    "                                                                                                  \n",
    " concatenate_20 (Concatenate)   (None, 32, 32, 1024  0           ['dropout_10[0][0]',             \n",
    "                                )                                 'conv2d_130[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_131 (Conv2D)            (None, 32, 32, 512)  4719104     ['concatenate_20[0][0]']         \n",
    "                                                                                                  \n",
    " conv2d_132 (Conv2D)            (None, 32, 32, 512)  2359808     ['conv2d_131[0][0]']             \n",
    "                                                                                                  \n",
    " up_sampling2d_21 (UpSampling2D  (None, 64, 64, 512)  0          ['conv2d_132[0][0]']             \n",
    " )                                                                                                \n",
    "                                                                                                  \n",
    " conv2d_133 (Conv2D)            (None, 64, 64, 256)  524544      ['up_sampling2d_21[0][0]']       \n",
    "                                                                                                  \n",
    " concatenate_21 (Concatenate)   (None, 64, 64, 512)  0           ['conv2d_125[0][0]',             \n",
    "                                                                  'conv2d_133[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_134 (Conv2D)            (None, 64, 64, 256)  1179904     ['concatenate_21[0][0]']         \n",
    "                                                                                                  \n",
    " conv2d_135 (Conv2D)            (None, 64, 64, 256)  590080      ['conv2d_134[0][0]']             \n",
    "                                                                                                  \n",
    " up_sampling2d_22 (UpSampling2D  (None, 128, 128, 25  0          ['conv2d_135[0][0]']             \n",
    " )                              6)                                                                \n",
    "                                                                                                  \n",
    " conv2d_136 (Conv2D)            (None, 128, 128, 12  131200      ['up_sampling2d_22[0][0]']       \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " concatenate_22 (Concatenate)   (None, 128, 128, 25  0           ['conv2d_123[0][0]',             \n",
    "                                6)                                'conv2d_136[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_137 (Conv2D)            (None, 128, 128, 12  295040      ['concatenate_22[0][0]']         \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " conv2d_138 (Conv2D)            (None, 128, 128, 12  147584      ['conv2d_137[0][0]']             \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " up_sampling2d_23 (UpSampling2D  (None, 256, 256, 12  0          ['conv2d_138[0][0]']             \n",
    " )                              8)                                                                \n",
    "                                                                                                  \n",
    " conv2d_139 (Conv2D)            (None, 256, 256, 64  32832       ['up_sampling2d_23[0][0]']       \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " concatenate_23 (Concatenate)   (None, 256, 256, 12  0           ['conv2d_121[0][0]',             \n",
    "                                8)                                'conv2d_139[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_140 (Conv2D)            (None, 256, 256, 64  73792       ['concatenate_23[0][0]']         \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_141 (Conv2D)            (None, 256, 256, 64  36928       ['conv2d_140[0][0]']             \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_142 (Conv2D)            (None, 256, 256, 9)  5193        ['conv2d_141[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_143 (Conv2D)            (None, 256, 256, 3)  30          ['conv2d_142[0][0]']             \n",
    "                                                                                                  \n",
    "==================================================================================================\n",
    "Total params: 31,036,903\n",
    "Trainable params: 31,036,903\n",
    "Non-trainable params: 0\n",
    "</code>\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint('unet_endoscopic.hdf5', monitor = 'loss', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 956 images belonging to 1 classes.\n",
      "Found 956 images belonging to 1 classes.\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f1f7c60a290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f1f7c60a290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function dice_coef_loss at 0x7f1f7c623d40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function dice_coef_loss at 0x7f1f7c623d40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-13 15:52:18.734732: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n",
      "2023-09-13 15:52:19.185989: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - ETA: 0s - loss: 0.8236 - accuracy: 0.1196 - dice_coef_loss: 0.8236\n",
      "Epoch 1: loss improved from inf to 0.82358, saving model to unet_endoscopic.hdf5\n",
      "500/500 [==============================] - 70s 131ms/step - loss: 0.8236 - accuracy: 0.1196 - dice_coef_loss: 0.8236\n",
      "Epoch 2/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8208 - accuracy: 0.1003 - dice_coef_loss: 0.8208\n",
      "Epoch 2: loss improved from 0.82358 to 0.82081, saving model to unet_endoscopic.hdf5\n",
      "500/500 [==============================] - 66s 132ms/step - loss: 0.8208 - accuracy: 0.1003 - dice_coef_loss: 0.8208\n",
      "Epoch 3/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8263 - accuracy: 0.0970 - dice_coef_loss: 0.8263\n",
      "Epoch 3: loss did not improve from 0.82081\n",
      "500/500 [==============================] - 65s 131ms/step - loss: 0.8263 - accuracy: 0.0970 - dice_coef_loss: 0.8263\n",
      "Epoch 4/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7588 - accuracy: 0.5387 - dice_coef_loss: 0.7588\n",
      "Epoch 4: loss improved from 0.82081 to 0.75880, saving model to unet_endoscopic.hdf5\n",
      "500/500 [==============================] - 66s 132ms/step - loss: 0.7588 - accuracy: 0.5387 - dice_coef_loss: 0.7588\n",
      "Epoch 5/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7541 - accuracy: 0.8250 - dice_coef_loss: 0.7541\n",
      "Epoch 5: loss improved from 0.75880 to 0.75413, saving model to unet_endoscopic.hdf5\n",
      "500/500 [==============================] - 66s 132ms/step - loss: 0.7541 - accuracy: 0.8250 - dice_coef_loss: 0.7541\n",
      "Epoch 6/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8473 - accuracy: 0.8772 - dice_coef_loss: 0.8473\n",
      "Epoch 6: loss did not improve from 0.75413\n",
      "500/500 [==============================] - 65s 131ms/step - loss: 0.8473 - accuracy: 0.8772 - dice_coef_loss: 0.8473\n",
      "Epoch 7/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7973 - accuracy: 0.8368 - dice_coef_loss: 0.7973\n",
      "Epoch 7: loss did not improve from 0.75413\n",
      "500/500 [==============================] - 65s 130ms/step - loss: 0.7973 - accuracy: 0.8368 - dice_coef_loss: 0.7973\n",
      "Epoch 8/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8862 - accuracy: 0.8885 - dice_coef_loss: 0.8862\n",
      "Epoch 8: loss did not improve from 0.75413\n",
      "500/500 [==============================] - 65s 131ms/step - loss: 0.8862 - accuracy: 0.8885 - dice_coef_loss: 0.8862\n",
      "Epoch 9/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8941 - accuracy: 0.8883 - dice_coef_loss: 0.8941\n",
      "Epoch 9: loss did not improve from 0.75413\n",
      "500/500 [==============================] - 65s 131ms/step - loss: 0.8941 - accuracy: 0.8883 - dice_coef_loss: 0.8941\n",
      "Epoch 10/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8924 - accuracy: 0.8865 - dice_coef_loss: 0.8924\n",
      "Epoch 10: loss did not improve from 0.75413\n",
      "500/500 [==============================] - 65s 131ms/step - loss: 0.8924 - accuracy: 0.8865 - dice_coef_loss: 0.8924\n",
      "Epoch 11/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.9080 - accuracy: 0.8904 - dice_coef_loss: 0.9080\n",
      "Epoch 11: loss did not improve from 0.75413\n",
      "500/500 [==============================] - 65s 130ms/step - loss: 0.9080 - accuracy: 0.8904 - dice_coef_loss: 0.9080\n",
      "Epoch 12/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.9077 - accuracy: 0.8864 - dice_coef_loss: 0.9077\n",
      "Epoch 12: loss did not improve from 0.75413\n",
      "500/500 [==============================] - 65s 130ms/step - loss: 0.9077 - accuracy: 0.8864 - dice_coef_loss: 0.9077\n",
      "Epoch 13/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.9059 - accuracy: 0.8893 - dice_coef_loss: 0.9059\n",
      "Epoch 13: loss did not improve from 0.75413\n",
      "500/500 [==============================] - 65s 130ms/step - loss: 0.9059 - accuracy: 0.8893 - dice_coef_loss: 0.9059\n",
      "Epoch 14/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.9046 - accuracy: 0.8899 - dice_coef_loss: 0.9046\n",
      "Epoch 14: loss did not improve from 0.75413\n",
      "500/500 [==============================] - 65s 130ms/step - loss: 0.9046 - accuracy: 0.8899 - dice_coef_loss: 0.9046\n",
      "Epoch 15/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.9064 - accuracy: 0.8900 - dice_coef_loss: 0.9064\n",
      "Epoch 15: loss did not improve from 0.75413\n",
      "500/500 [==============================] - 66s 133ms/step - loss: 0.9064 - accuracy: 0.8900 - dice_coef_loss: 0.9064\n",
      "Epoch 16/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.9067 - accuracy: 0.8885 - dice_coef_loss: 0.9067\n",
      "Epoch 16: loss did not improve from 0.75413\n",
      "500/500 [==============================] - 65s 131ms/step - loss: 0.9067 - accuracy: 0.8885 - dice_coef_loss: 0.9067\n",
      "Epoch 17/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.9646 - accuracy: 0.8987 - dice_coef_loss: 0.9646\n",
      "Epoch 17: loss did not improve from 0.75413\n",
      "500/500 [==============================] - 65s 130ms/step - loss: 0.9646 - accuracy: 0.8987 - dice_coef_loss: 0.9646\n",
      "Epoch 18/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.9161 - accuracy: 0.8907 - dice_coef_loss: 0.9161\n",
      "Epoch 18: loss did not improve from 0.75413\n",
      "500/500 [==============================] - 65s 130ms/step - loss: 0.9161 - accuracy: 0.8907 - dice_coef_loss: 0.9161\n",
      "Epoch 19/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8645 - accuracy: 0.8825 - dice_coef_loss: 0.8645\n",
      "Epoch 19: loss did not improve from 0.75413\n",
      "500/500 [==============================] - 65s 130ms/step - loss: 0.8645 - accuracy: 0.8825 - dice_coef_loss: 0.8645\n",
      "Epoch 20/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8694 - accuracy: 0.8790 - dice_coef_loss: 0.8694\n",
      "Epoch 20: loss did not improve from 0.75413\n",
      "500/500 [==============================] - 65s 130ms/step - loss: 0.8694 - accuracy: 0.8790 - dice_coef_loss: 0.8694\n"
     ]
    }
   ],
   "source": [
    "test_run = test_model.fit(test_gene, verbose = 1, steps_per_epoch = 500, epochs = 20, callbacks = [model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(test_run.history.keys())\n",
    "plt.plot(test_run.history['loss'])\n",
    "plt.plot(test_run.history['accuracy'])\n",
    "plt.title('Test Run')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss', 'accuracy'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAM_PATH_TEST = './test'\n",
    "image_name = '29.tif'\n",
    "img = io.imread(os.path.join(PARAM_PATH_TEST,image_name),as_gray = False)\n",
    "img = trans.resize(img,[256,256])\n",
    "img = np.reshape(img,(1,)+img.shape)\n",
    "\n",
    "results = test_model.predict(img,1,verbose=1)\n",
    "#saveResult(Path,results)\n",
    "img = results[0,:,:]\n",
    "print(results.shape)\n",
    "io.imsave(os.path.join(PARAM_PATH_TEST,\"result.png\"),img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Relocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following block, the code loads in one analysis file from previous research. \n",
    "\n",
    "### #File name postfix\n",
    "_C_ is the dice scores of the predictions generated by Unet C: this Unet C is trained using all 7404 images, in their cartesian form. The raw image was directly input into the Unet and the prediction was generated.\n",
    "\n",
    "_P_ is the dice scores of the predictions generated by Unet P: this Unet P is trained using all 7404 images but in their polar form. The raw images were transformed, and then input for prediction. The prediction is in polar space.\n",
    "\n",
    "_P2C_ is the dice scores of the predictions generated by the same Unet P as mentioned above, but the dice score is generated by transforming the prediction back to cartesian, and compared to their original label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#file_name = 'analysis_dice_back_Test_C.npy'\n",
    "file_name = 'analysis_dice_back_Test_P.npy'\n",
    "#file_name = 'analysis_dice_back_Test_P2C.npy'\n",
    "np_file = os.path.join(PARAM_PATH_SCORES, file_name)\n",
    "#load npy file\n",
    "img_score = np.load(np_file)\n",
    "#sort scores in descending order and store index\n",
    "sorted_score = np.flip(np.argsort(img_score))\n",
    "#print(sorted_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_score = pd.DataFrame(sorted_score)\n",
    "\n",
    "#fetch top polar dominant and non-polar dominant image\n",
    "num_polar = round(len(sorted_score)/2)\n",
    "num_cartesian = len(sorted_score) - num_polar\n",
    "dfPolar = sorted_score.head(num_polar)\n",
    "dfCartesian = sorted_score.tail(num_cartesian)\n",
    "print(\"Polar: \\n\", dfPolar)\n",
    "print(\"Cartesian: \\n\", dfCartesian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new directories for polar dominant images and cartesian dominant images based on sorted dice scores\n",
    "\n",
    "if os.path.exists(PARAM_PATH_TEMP_POLAR):#\n",
    "    shutil.rmtree(PARAM_PATH_TEMP_POLAR)\n",
    "os.makedirs(PARAM_PATH_TEMP_POLAR)\n",
    "this_folder = os.path.join(PARAM_PATH_TEMP_POLAR,PARAM_SUB_FOLDER_POLAR)#Creation of subfolder\n",
    "os.makedirs(os.path.join(this_folder,PARAM_IMG_FOLDER))\n",
    "os.makedirs(os.path.join(this_folder,PARAM_MSK_FOLDER))\n",
    "this_folder = os.path.join(PARAM_PATH_TEMP_POLAR,PARAM_SUB_FOLDER_CARTE)\n",
    "os.makedirs(os.path.join(this_folder,PARAM_IMG_FOLDER))\n",
    "os.makedirs(os.path.join(this_folder,PARAM_MSK_FOLDER))\n",
    "\n",
    "if os.path.exists(PARAM_PATH_TEMP_CARTE):\n",
    "    shutil.rmtree(PARAM_PATH_TEMP_CARTE)\n",
    "os.makedirs(PARAM_PATH_TEMP_CARTE)\n",
    "this_folder = os.path.join(PARAM_PATH_TEMP_CARTE,PARAM_SUB_FOLDER_POLAR)#Creation of subfolder\n",
    "os.makedirs(os.path.join(this_folder,PARAM_IMG_FOLDER))\n",
    "os.makedirs(os.path.join(this_folder,PARAM_MSK_FOLDER))\n",
    "this_folder = os.path.join(PARAM_PATH_TEMP_CARTE,PARAM_SUB_FOLDER_CARTE)\n",
    "os.makedirs(os.path.join(this_folder,PARAM_IMG_FOLDER))\n",
    "os.makedirs(os.path.join(this_folder,PARAM_MSK_FOLDER))\n",
    "\n",
    "for img in dfPolar[0]:\n",
    "    img_name = str(img) + \".tif\"\n",
    "    #Copy polar img and mask in\n",
    "    this_folder = os.path.join(PARAM_PATH_TEMP_POLAR,PARAM_SUB_FOLDER_POLAR)\n",
    "    src = os.path.join(PARAM_PATH_POLAR, PARAM_IMG_FOLDER, img_name)\n",
    "    shutil.copy2(src, os.path.join(this_folder,PARAM_IMG_FOLDER))\n",
    "    src = os.path.join(PARAM_PATH_POLAR, PARAM_MSK_FOLDER, img_name)\n",
    "    shutil.copy2(src, os.path.join(this_folder,PARAM_MSK_FOLDER))\n",
    "    #Copy cartesian img and mask in\n",
    "    this_folder = os.path.join(PARAM_PATH_TEMP_POLAR,PARAM_SUB_FOLDER_CARTE)\n",
    "    src = os.path.join(PARAM_PATH_CARTE, PARAM_IMG_FOLDER, img_name)\n",
    "    shutil.copy2(src, os.path.join(this_folder,PARAM_IMG_FOLDER))\n",
    "    src = os.path.join(PARAM_PATH_CARTE, PARAM_MSK_FOLDER, img_name)\n",
    "    shutil.copy2(src, os.path.join(this_folder,PARAM_MSK_FOLDER))\n",
    "    \n",
    "for img in dfCartesian[0]:\n",
    "    img_name = str(img) + \".tif\"\n",
    "    #Copy polar img and mask in\n",
    "    this_folder = os.path.join(PARAM_PATH_TEMP_CARTE,PARAM_SUB_FOLDER_POLAR)\n",
    "    src = os.path.join(PARAM_PATH_POLAR, PARAM_IMG_FOLDER, img_name)\n",
    "    shutil.copy2(src, os.path.join(this_folder,PARAM_IMG_FOLDER))\n",
    "    src = os.path.join(PARAM_PATH_POLAR, PARAM_MSK_FOLDER, img_name)\n",
    "    shutil.copy2(src, os.path.join(this_folder,PARAM_MSK_FOLDER))\n",
    "    #Copy cartesian img and mask in    \n",
    "    this_folder = os.path.join(PARAM_PATH_TEMP_CARTE,PARAM_SUB_FOLDER_CARTE)\n",
    "    src = os.path.join(PARAM_PATH_CARTE, PARAM_IMG_FOLDER, img_name)\n",
    "    shutil.copy2(src, os.path.join(this_folder,PARAM_IMG_FOLDER))\n",
    "    src = os.path.join(PARAM_PATH_CARTE, PARAM_MSK_FOLDER, img_name)\n",
    "    shutil.copy2(src, os.path.join(this_folder,PARAM_MSK_FOLDER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K fold Validation (obtain training & testing sets)\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits=PARAM_SPLIT_NUM)\n",
    "for train_index,test_index in kfold.split(dfPolar):\n",
    "    polar_train,polar_test=dfPolar.iloc[train_index, :],dfPolar.iloc[test_index, :]\n",
    "    cartesian_train,cartesian_test=dfCartesian.iloc[train_index, :],dfCartesian.iloc[test_index, :]\n",
    "    print(\"polar train: \", polar_train, \"polar test: \", polar_test)\n",
    "    print(\"cartesian train\" , cartesian_train, \"cartesian test\", cartesian_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy Code Below\n",
    "### written by Wenfan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from defines import *\n",
    "from model import *\n",
    "from data import *\n",
    "import sys\n",
    "\n",
    "from numpy import loadtxt\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "\n",
    "import glob\n",
    "import os \n",
    "import math\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data_jupyter'# main folder path\n",
    "\n",
    "D = 'all_images'\n",
    "L = 'all_labels'\n",
    "\n",
    "D_P_im = 'polar_im'\n",
    "D_C_im = 'car_im'\n",
    "D_P = 'polar_l'\n",
    "D_C = 'car_l'\n",
    "\n",
    "prev_number_of_D_P = -1\n",
    "prev_number_of_D_C = -1\n",
    "\n",
    "diff = math.inf\n",
    "\n",
    "model_P = unet(PARAM_BETA1[PARAM_BETA_TEST_NUM], PARAM_BETA2[PARAM_BETA_TEST_NUM])\n",
    "model_C = unet(PARAM_BETA1[PARAM_BETA_TEST_NUM], PARAM_BETA2[PARAM_BETA_TEST_NUM])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill in the weights here\n",
    "model_P.load_weights() \n",
    "model_C.load_weights() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "#change file name of D, L\n",
    "for count, filename in enumerate(os.listdir(path+'/'+D)): \n",
    "    dst = str(count) + \".png\"\n",
    "    src = path+'/'+D+'/'+filename\n",
    "    dst = path+'/'+D+'/'+dst\n",
    "\n",
    "    os.rename(src, dst) \n",
    "    \n",
    "for count, filename in enumerate(os.listdir(path+'/'+L)): \n",
    "    dst = str(count) + \".tif\"\n",
    "    src = path+'/'+L+'/'+filename\n",
    "    dst = path+'/'+L+'/'+dst\n",
    "\n",
    "    os.rename(src, dst) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dscore(im, im_name):\n",
    "    label = Image.open(os.path.join(L, im_name))\n",
    "    \n",
    "    pixelIm = im.load()\n",
    "    pixelLabel = label.load()\n",
    "    \n",
    "    upper = 0\n",
    "    lower = im.size[0] * im.size[1]\n",
    "    \n",
    "    for i in range(im.size[0]):\n",
    "        for j in range(im.size[1]):\n",
    "            if pixelIm[i,j] == pixelLabel[i,j]:\n",
    "                upper = upper + 1\n",
    "            \n",
    "    upper = upper * 2\n",
    "    \n",
    "    return upper / lower\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while (diff > 0): \n",
    "    #load model\n",
    "    #if count > 0:\n",
    "    #    model_P.load_weights('model_P_weights_' + (count - 1))\n",
    "    #    model_C.load_weights('model_C_weights_' + (count - 1))\n",
    "    \n",
    "    count = count + 1\n",
    "    \n",
    "    testGene_P, testGene_C = testGenerator(path,D,L)\n",
    "    \n",
    "    #perdict\n",
    "    results_P = model_P.predict(testGene_P, PARAM_N_TESTS, verbose=1)\n",
    "    results_C = model_C.predict(testGene_C, PARAM_N_TESTS, verbose=1)\n",
    "\n",
    "    np.save(PARAM_PATH_TEST_NPY_P, results_P)\n",
    "    saveResult(PARAM_PATH_TEST_RESULTS_P, results_P)\n",
    "    np.save(PARAM_PATH_TEST_NPY_C, results_C)\n",
    "    saveResult(PARAM_PATH_TEST_RESULTS_C, results_C)\n",
    "    \n",
    "    mergeIm(path, D, L, PARAM_PATH_TEST_RESULTS_P, path+'/'+D_P)\n",
    "    mergeIm(path, D, L, PARAM_PATH_TEST_RESULTS_C, path+'/'+D_C)\n",
    "    \n",
    "    #change file name of D_P, D_C\n",
    "    for count, filename in enumerate(os.listdir(path+'/'+D_P)): \n",
    "        dst = str(count) + \".tif\"\n",
    "        src = path+'/'+D_P+'/'+filenaLme\n",
    "        dst = path+'/'+D_P+'/'+dst\n",
    "\n",
    "        os.rename(src, dst) \n",
    "  \n",
    "    for count, filename in enumerate(os.listdir(path+'/'+D_C)): \n",
    "        dst = str(count) + \".tif\"\n",
    "        src = path+'/'+D_C+'/'+filename\n",
    "        dst = path+'/'+D_C+'/'+dst\n",
    "\n",
    "        os.rename(src, dst) \n",
    "    \n",
    "    #find the better one (based on L) and modify D_P, D_P_im, D_C, D_C_im\n",
    "    for file in os.listdir(D):\n",
    "        im_P = Image.open(path+'/'+D_P+'/'+file)\n",
    "        im_C = Image.open(path+'/'+D_C+'/'+file)\n",
    "        \n",
    "        if dscore(im_P, file) > dscore(im_C, file):\n",
    "            shutil.copyfile(path+'/'+D+'/'+file, path+'/'+D_P_im+'/'+file)\n",
    "            os.remove(path+'/'+D_C+'/'+file)\n",
    "        else:\n",
    "            shutil.copyfile(path+'/'+D+'/'+file, path+'/'+D_C_im+'/'+file)\n",
    "            os.remove(path+'/'+D_P+'/'+file)\n",
    "            \n",
    "    number_of_D_P = len(glob.glob(D_P))\n",
    "    number_of_D_C = len(glob.glob(D_C))\n",
    "\n",
    "    # file numbers difference\n",
    "    diff = Math.abs(prev_number_of_D_P - number_of_D_P + prev_number_of_D_C - number_of_D_C) / 2\n",
    "    \n",
    "    prev_number_of_D_P = number_of_D_P\n",
    "    prev_number_of_D_C = number_of_D_P\n",
    "    \n",
    "    #train model_P only on D_P, model_C only on D_C\n",
    "    myGene_P = trainGenerator(PARAM_BATCHES, \n",
    "                            path, \n",
    "                            D_P, \n",
    "                            D_P_im, \n",
    "                            PARAM_DATA_ARGS, \n",
    "                            save_to_dir = PARAM_AUG_FOLDER_P)\n",
    "    \n",
    "    myGene_C = trainGenerator(PARAM_BATCHES, \n",
    "                            path, \n",
    "                            D_C, \n",
    "                            D_C_im, \n",
    "                            PARAM_DATA_ARGS, \n",
    "                            save_to_dir = PARAM_AUG_FOLDER_C)\n",
    "    \n",
    "    model_checkpoint_P = ModelCheckpoint( PARAM_SAVED_MODEL, \n",
    "                                         monitor = PARAM_METRICS, \n",
    "                                         verbose = 1, \n",
    "                                         save_best_only = PARAM_SAVE_BEST_ONLY)\n",
    "    \n",
    "    model_P.fit_generator(myGene_P,\n",
    "                        steps_per_epoch = PARAM_EPOCH_STEPS,\n",
    "                        epochs = PARAM_N_EPOCHS,\n",
    "                        callbacks = [model_checkpoint])\n",
    "    model_C.fit_generator(myGene_C,\n",
    "                        steps_per_epoch = PARAM_EPOCH_STEPS,\n",
    "                        epochs = PARAM_N_EPOCHS,\n",
    "                        callbacks = [model_checkpoint])\n",
    "    \n",
    "    model_P.save_weights('model_P_weights_' + count)\n",
    "    model_C.save_weights('model_C_weights_' + count)\n",
    "    \n",
    "    shutil.rmtree(path+'/'+D_P)\n",
    "    shutil.rmtree(path+'/'+D_C)\n",
    "    shutil.rmtree(path+'/'+D_P_im)\n",
    "    shutil.rmtree(path+'/'+D_C_im)\n",
    "    \n",
    "\n",
    "save_model(model_P, 'model_P.h5')\n",
    "save_model(model_C, 'model_C.h5')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
