{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Approach for Unet Training \n",
    "\n",
    "------\n",
    "\n",
    "## Overview\n",
    "\n",
    "\n",
    "\n",
    "The purpose of this learn.ipynb notebook is to investigate whether an image can exhibit a preference for being segmented more effectively using a UNet model trained on polar or cartesian-dominant images.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Structure\n",
    "```\n",
    "data\n",
    "└── endoscopic\n",
    "    ├── cartesian\n",
    "    │   ├── image\n",
    "    │   └── label\n",
    "    └── polar\n",
    "        ├── image\n",
    "        └── label\n",
    "```\n",
    "\n",
    "Inside of each end folder there are 956 images, named as `0.tif` to `955.tif`\n",
    "and I believe, for now, the naming of the images are one to one correctly matched, meaning the ``/data/endoscopic/**cartesian**/image/0.tif`` is transformed from `/data/endoscopic/**polar**/image/0.tif`\n",
    "\n",
    "Instead of putting a seperate set of images aside to be test set, we chose to use k-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import from files and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from defines import *\n",
    "from model import *\n",
    "from data import *\n",
    "import sys\n",
    "\n",
    "from numpy import loadtxt\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import math\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this if your computer has a cuda visible device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PARAM_SYSTEM_TIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test code for correct file structure setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize folder tree in current directory\n",
    "os.system(\"tree -d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count of files in data directories\n",
    "os.system(\"ls \" + os.path.join(PARAM_PATH_CARTE,PARAM_IMG_FOLDER) + \" | wc -l\")\n",
    "os.system(\"ls \" + os.path.join(PARAM_PATH_CARTE,PARAM_MSK_FOLDER) + \" | wc -l\")\n",
    "os.system(\"ls \" + os.path.join(PARAM_PATH_POLAR,PARAM_IMG_FOLDER) + \" | wc -l\")\n",
    "os.system(\"ls \" + os.path.join(PARAM_PATH_POLAR,PARAM_MSK_FOLDER) + \" | wc -l\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output: \n",
    "956\n",
    "956\n",
    "956\n",
    "956\n",
    "**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Relocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following block, the code loads in one analysis file from previous research. \n",
    "\n",
    "### #File name postfix\n",
    "_C_ is the dice scores of the predictions generated by Unet C: this Unet C is trained using all 7404 images, in their cartesian form. The raw image was directly input into the Unet and the prediction was generated.\n",
    "\n",
    "_P_ is the dice scores of the predictions generated by Unet P: this Unet P is trained using all 7404 images but in their polar form. The raw images were transformed, and then input for prediction. The prediction is in polar space.\n",
    "\n",
    "_P2C_ is the dice scores of the predictions generated by the same Unet P as mentioned above, but the dice score is generated by transforming the prediction back to cartesian, and compared to their original label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#file_name = 'analysis_dice_back_Test_C.npy'\n",
    "file_name = 'analysis_dice_back_Test_P.npy'\n",
    "#file_name = 'analysis_dice_back_Test_P2C.npy'\n",
    "np_file = os.path.join(PARAM_PATH_SCORES, file_name)\n",
    "#load npy file\n",
    "img_score = np.load(np_file)\n",
    "#sort scores in descending order and store index\n",
    "sorted_score = np.flip(np.argsort(img_score))\n",
    "#print(sorted_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_score = pd.DataFrame(sorted_score)\n",
    "\n",
    "#fetch top polar dominant and non-polar dominant image\n",
    "num_polar = round(len(sorted_score)/2)\n",
    "num_cartesian = len(sorted_score) - num_polar\n",
    "dfPolar = sorted_score.head(num_polar)\n",
    "dfCartesian = sorted_score.tail(num_cartesian)\n",
    "print(\"Polar: \\n\", dfPolar)\n",
    "print(\"Cartesian: \\n\", dfCartesian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new directories for polar dominant images and cartesian dominant images based on sorted dice scores\n",
    "\n",
    "if os.path.exists(PARAM_PATH_TEMP_POLAR):#\n",
    "    shutil.rmtree(PARAM_PATH_TEMP_POLAR)\n",
    "os.makedirs(PARAM_PATH_TEMP_POLAR)\n",
    "this_folder = os.path.join(PARAM_PATH_TEMP_POLAR,PARAM_SUB_FOLDER_POLAR)#Creation of subfolder\n",
    "os.makedirs(os.path.join(this_folder,PARAM_IMG_FOLDER))\n",
    "os.makedirs(os.path.join(this_folder,PARAM_MSK_FOLDER))\n",
    "this_folder = os.path.join(PARAM_PATH_TEMP_POLAR,PARAM_SUB_FOLDER_CARTE)\n",
    "os.makedirs(os.path.join(this_folder,PARAM_IMG_FOLDER))\n",
    "os.makedirs(os.path.join(this_folder,PARAM_MSK_FOLDER))\n",
    "\n",
    "if os.path.exists(PARAM_PATH_TEMP_CARTE):\n",
    "    shutil.rmtree(PARAM_PATH_TEMP_CARTE)\n",
    "os.makedirs(PARAM_PATH_TEMP_CARTE)\n",
    "this_folder = os.path.join(PARAM_PATH_TEMP_CARTE,PARAM_SUB_FOLDER_POLAR)#Creation of subfolder\n",
    "os.makedirs(os.path.join(this_folder,PARAM_IMG_FOLDER))\n",
    "os.makedirs(os.path.join(this_folder,PARAM_MSK_FOLDER))\n",
    "this_folder = os.path.join(PARAM_PATH_TEMP_CARTE,PARAM_SUB_FOLDER_CARTE)\n",
    "os.makedirs(os.path.join(this_folder,PARAM_IMG_FOLDER))\n",
    "os.makedirs(os.path.join(this_folder,PARAM_MSK_FOLDER))\n",
    "\n",
    "for img in dfPolar[0]:\n",
    "    img_name = str(img) + \".tif\"\n",
    "    #Copy polar img and mask in\n",
    "    this_folder = os.path.join(PARAM_PATH_TEMP_POLAR,PARAM_SUB_FOLDER_POLAR)\n",
    "    src = os.path.join(PARAM_PATH_POLAR, PARAM_IMG_FOLDER, img_name)\n",
    "    shutil.copy2(src, os.path.join(this_folder,PARAM_IMG_FOLDER))\n",
    "    src = os.path.join(PARAM_PATH_POLAR, PARAM_MSK_FOLDER, img_name)\n",
    "    shutil.copy2(src, os.path.join(this_folder,PARAM_MSK_FOLDER))\n",
    "    #Copy cartesian img and mask in\n",
    "    this_folder = os.path.join(PARAM_PATH_TEMP_POLAR,PARAM_SUB_FOLDER_CARTE)\n",
    "    src = os.path.join(PARAM_PATH_CARTE, PARAM_IMG_FOLDER, img_name)\n",
    "    shutil.copy2(src, os.path.join(this_folder,PARAM_IMG_FOLDER))\n",
    "    src = os.path.join(PARAM_PATH_CARTE, PARAM_MSK_FOLDER, img_name)\n",
    "    shutil.copy2(src, os.path.join(this_folder,PARAM_MSK_FOLDER))\n",
    "    \n",
    "for img in dfCartesian[0]:\n",
    "    img_name = str(img) + \".tif\"\n",
    "    #Copy polar img and mask in\n",
    "    this_folder = os.path.join(PARAM_PATH_TEMP_CARTE,PARAM_SUB_FOLDER_POLAR)\n",
    "    src = os.path.join(PARAM_PATH_POLAR, PARAM_IMG_FOLDER, img_name)\n",
    "    shutil.copy2(src, os.path.join(this_folder,PARAM_IMG_FOLDER))\n",
    "    src = os.path.join(PARAM_PATH_POLAR, PARAM_MSK_FOLDER, img_name)\n",
    "    shutil.copy2(src, os.path.join(this_folder,PARAM_MSK_FOLDER))\n",
    "    #Copy cartesian img and mask in    \n",
    "    this_folder = os.path.join(PARAM_PATH_TEMP_CARTE,PARAM_SUB_FOLDER_CARTE)\n",
    "    src = os.path.join(PARAM_PATH_CARTE, PARAM_IMG_FOLDER, img_name)\n",
    "    shutil.copy2(src, os.path.join(this_folder,PARAM_IMG_FOLDER))\n",
    "    src = os.path.join(PARAM_PATH_CARTE, PARAM_MSK_FOLDER, img_name)\n",
    "    shutil.copy2(src, os.path.join(this_folder,PARAM_MSK_FOLDER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K fold Validation (obtain training & testing sets)\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits=PARAM_SPLIT_NUM)\n",
    "for train_index,test_index in kfold.split(dfPolar):\n",
    "    polar_train,polar_test=dfPolar.iloc[train_index, :],dfPolar.iloc[test_index, :]\n",
    "    cartesian_train,cartesian_test=dfCartesian.iloc[train_index, :],dfCartesian.iloc[test_index, :]\n",
    "    print(\"polar train: \", polar_train, \"polar test: \", polar_test)\n",
    "    print(\"cartesian train\" , cartesian_train, \"cartesian test\", cartesian_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training test\n",
    "\n",
    "This part is used to see if we can train a model using the current configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Superparameters (temporary) for a test run of model training test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 256, 256, 64  1792        ['input_4[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 256, 256, 64  36928       ['conv2d_72[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_12 (MaxPooling2D  (None, 128, 128, 64  0          ['conv2d_73[0][0]']              \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 128, 128, 12  73856       ['max_pooling2d_12[0][0]']       \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_74[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_13 (MaxPooling2D  (None, 64, 64, 128)  0          ['conv2d_75[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 64, 64, 256)  295168      ['max_pooling2d_13[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_76[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_14 (MaxPooling2D  (None, 32, 32, 256)  0          ['conv2d_77[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 32, 32, 512)  1180160     ['max_pooling2d_14[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_78[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 32, 32, 512)  0           ['conv2d_79[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_15 (MaxPooling2D  (None, 16, 16, 512)  0          ['dropout_6[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 16, 16, 1024  4719616     ['max_pooling2d_15[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 16, 16, 1024  9438208     ['conv2d_80[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 16, 16, 1024  0           ['conv2d_81[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_12 (UpSampling2D  (None, 32, 32, 1024  0          ['dropout_7[0][0]']              \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 32, 32, 512)  2097664     ['up_sampling2d_12[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_12 (Concatenate)   (None, 32, 32, 1024  0           ['dropout_6[0][0]',              \n",
      "                                )                                 'conv2d_82[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 32, 32, 512)  4719104     ['concatenate_12[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_83[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_13 (UpSampling2D  (None, 64, 64, 512)  0          ['conv2d_84[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 64, 64, 256)  524544      ['up_sampling2d_13[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_13 (Concatenate)   (None, 64, 64, 512)  0           ['conv2d_77[0][0]',              \n",
      "                                                                  'conv2d_85[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 64, 64, 256)  1179904     ['concatenate_13[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_86[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_14 (UpSampling2D  (None, 128, 128, 25  0          ['conv2d_87[0][0]']              \n",
      " )                              6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 128, 128, 12  131200      ['up_sampling2d_14[0][0]']       \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_14 (Concatenate)   (None, 128, 128, 25  0           ['conv2d_75[0][0]',              \n",
      "                                6)                                'conv2d_88[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 128, 128, 12  295040      ['concatenate_14[0][0]']         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_89[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " up_sampling2d_15 (UpSampling2D  (None, 256, 256, 12  0          ['conv2d_90[0][0]']              \n",
      " )                              8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 256, 256, 64  32832       ['up_sampling2d_15[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_15 (Concatenate)   (None, 256, 256, 12  0           ['conv2d_73[0][0]',              \n",
      "                                8)                                'conv2d_91[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 256, 256, 64  73792       ['concatenate_15[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 256, 256, 64  36928       ['conv2d_92[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_94 (Conv2D)             (None, 256, 256, 2)  1154        ['conv2d_93[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_95 (Conv2D)             (None, 256, 256, 1)  3           ['conv2d_94[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,032,837\n",
      "Trainable params: 31,032,837\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "PARAM_BETA_TEST_NUM = 3\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "data_gen_args = dict(rotation_range = 80,      # TODO: improve the data augmentation\n",
    "                width_shift_range =0.02,\n",
    "                height_shift_range =0.02,\n",
    "                shear_range = 0.35,\n",
    "                zoom_range = 0.075,\n",
    "                horizontal_flip = True,\n",
    "                fill_mode = 'nearest',\n",
    "                rescale = 1./255)\n",
    "test_gene = trainGenerator(batch_size, PARAM_PATH_CARTE, PARAM_IMG_FOLDER, PARAM_MSK_FOLDER, data_gen_args)\n",
    "test_model = unet(PARAM_BETA1[PARAM_BETA_TEST_NUM], PARAM_BETA2[PARAM_BETA_TEST_NUM]) \n",
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected output\n",
    "<details>\n",
    "    <summary><b><font color=\"green\">Click here to expand</font></b></summary>\n",
    "    <code>\n",
    "Model: \"model_5\"\n",
    "__________________________________________________________________________________________________\n",
    " Layer (type)                   Output Shape         Param #     Connected to                     \n",
    "==================================================================================================\n",
    " input_6 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
    "                                )]                                                                \n",
    "                                                                                                  \n",
    " conv2d_120 (Conv2D)            (None, 256, 256, 64  1792        ['input_6[0][0]']                \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_121 (Conv2D)            (None, 256, 256, 64  36928       ['conv2d_120[0][0]']             \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " max_pooling2d_20 (MaxPooling2D  (None, 128, 128, 64  0          ['conv2d_121[0][0]']             \n",
    " )                              )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_122 (Conv2D)            (None, 128, 128, 12  73856       ['max_pooling2d_20[0][0]']       \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " conv2d_123 (Conv2D)            (None, 128, 128, 12  147584      ['conv2d_122[0][0]']             \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " max_pooling2d_21 (MaxPooling2D  (None, 64, 64, 128)  0          ['conv2d_123[0][0]']             \n",
    " )                                                                                                \n",
    "                                                                                                  \n",
    " conv2d_124 (Conv2D)            (None, 64, 64, 256)  295168      ['max_pooling2d_21[0][0]']       \n",
    "                                                                                                  \n",
    " conv2d_125 (Conv2D)            (None, 64, 64, 256)  590080      ['conv2d_124[0][0]']             \n",
    "                                                                                                  \n",
    " max_pooling2d_22 (MaxPooling2D  (None, 32, 32, 256)  0          ['conv2d_125[0][0]']             \n",
    " )                                                                                                \n",
    "                                                                                                  \n",
    " conv2d_126 (Conv2D)            (None, 32, 32, 512)  1180160     ['max_pooling2d_22[0][0]']       \n",
    "                                                                                                  \n",
    " conv2d_127 (Conv2D)            (None, 32, 32, 512)  2359808     ['conv2d_126[0][0]']             \n",
    "                                                                                                  \n",
    " dropout_10 (Dropout)           (None, 32, 32, 512)  0           ['conv2d_127[0][0]']             \n",
    "                                                                                                  \n",
    " max_pooling2d_23 (MaxPooling2D  (None, 16, 16, 512)  0          ['dropout_10[0][0]']             \n",
    " )                                                                                                \n",
    "                                                                                                  \n",
    " conv2d_128 (Conv2D)            (None, 16, 16, 1024  4719616     ['max_pooling2d_23[0][0]']       \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_129 (Conv2D)            (None, 16, 16, 1024  9438208     ['conv2d_128[0][0]']             \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " dropout_11 (Dropout)           (None, 16, 16, 1024  0           ['conv2d_129[0][0]']             \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " up_sampling2d_20 (UpSampling2D  (None, 32, 32, 1024  0          ['dropout_11[0][0]']             \n",
    " )                              )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_130 (Conv2D)            (None, 32, 32, 512)  2097664     ['up_sampling2d_20[0][0]']       \n",
    "                                                                                                  \n",
    " concatenate_20 (Concatenate)   (None, 32, 32, 1024  0           ['dropout_10[0][0]',             \n",
    "                                )                                 'conv2d_130[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_131 (Conv2D)            (None, 32, 32, 512)  4719104     ['concatenate_20[0][0]']         \n",
    "                                                                                                  \n",
    " conv2d_132 (Conv2D)            (None, 32, 32, 512)  2359808     ['conv2d_131[0][0]']             \n",
    "                                                                                                  \n",
    " up_sampling2d_21 (UpSampling2D  (None, 64, 64, 512)  0          ['conv2d_132[0][0]']             \n",
    " )                                                                                                \n",
    "                                                                                                  \n",
    " conv2d_133 (Conv2D)            (None, 64, 64, 256)  524544      ['up_sampling2d_21[0][0]']       \n",
    "                                                                                                  \n",
    " concatenate_21 (Concatenate)   (None, 64, 64, 512)  0           ['conv2d_125[0][0]',             \n",
    "                                                                  'conv2d_133[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_134 (Conv2D)            (None, 64, 64, 256)  1179904     ['concatenate_21[0][0]']         \n",
    "                                                                                                  \n",
    " conv2d_135 (Conv2D)            (None, 64, 64, 256)  590080      ['conv2d_134[0][0]']             \n",
    "                                                                                                  \n",
    " up_sampling2d_22 (UpSampling2D  (None, 128, 128, 25  0          ['conv2d_135[0][0]']             \n",
    " )                              6)                                                                \n",
    "                                                                                                  \n",
    " conv2d_136 (Conv2D)            (None, 128, 128, 12  131200      ['up_sampling2d_22[0][0]']       \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " concatenate_22 (Concatenate)   (None, 128, 128, 25  0           ['conv2d_123[0][0]',             \n",
    "                                6)                                'conv2d_136[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_137 (Conv2D)            (None, 128, 128, 12  295040      ['concatenate_22[0][0]']         \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " conv2d_138 (Conv2D)            (None, 128, 128, 12  147584      ['conv2d_137[0][0]']             \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " up_sampling2d_23 (UpSampling2D  (None, 256, 256, 12  0          ['conv2d_138[0][0]']             \n",
    " )                              8)                                                                \n",
    "                                                                                                  \n",
    " conv2d_139 (Conv2D)            (None, 256, 256, 64  32832       ['up_sampling2d_23[0][0]']       \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " concatenate_23 (Concatenate)   (None, 256, 256, 12  0           ['conv2d_121[0][0]',             \n",
    "                                8)                                'conv2d_139[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_140 (Conv2D)            (None, 256, 256, 64  73792       ['concatenate_23[0][0]']         \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_141 (Conv2D)            (None, 256, 256, 64  36928       ['conv2d_140[0][0]']             \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_142 (Conv2D)            (None, 256, 256, 9)  5193        ['conv2d_141[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_143 (Conv2D)            (None, 256, 256, 3)  30          ['conv2d_142[0][0]']             \n",
    "                                                                                                  \n",
    "==================================================================================================\n",
    "Total params: 31,036,903\n",
    "Trainable params: 31,036,903\n",
    "Non-trainable params: 0\n",
    "</code>\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint('unet_endoscopic.hdf5', monitor = 'loss', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 955 images belonging to 1 classes.\n",
      "Found 955 images belonging to 1 classes.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2dec31c200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f2dec31c200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7201 - accuracy: 0.5551 - dice_coef_loss: 0.7201\n",
      "Epoch 1: loss improved from inf to 0.72005, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 20s 189ms/step - loss: 0.7201 - accuracy: 0.5551 - dice_coef_loss: 0.7201\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5375 - accuracy: 0.8382 - dice_coef_loss: 0.5375\n",
      "Epoch 2: loss improved from 0.72005 to 0.53749, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 0.5375 - accuracy: 0.8382 - dice_coef_loss: 0.5375\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5643 - accuracy: 0.8275 - dice_coef_loss: 0.5643\n",
      "Epoch 3: loss did not improve from 0.53749\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.5643 - accuracy: 0.8275 - dice_coef_loss: 0.5643\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4876 - accuracy: 0.8468 - dice_coef_loss: 0.4906\n",
      "Epoch 4: loss improved from 0.53749 to 0.48759, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 0.4876 - accuracy: 0.8468 - dice_coef_loss: 0.4906\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4978 - accuracy: 0.8546 - dice_coef_loss: 0.4978\n",
      "Epoch 5: loss did not improve from 0.48759\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.4978 - accuracy: 0.8546 - dice_coef_loss: 0.4978\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4911 - accuracy: 0.8562 - dice_coef_loss: 0.4911\n",
      "Epoch 6: loss did not improve from 0.48759\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.4911 - accuracy: 0.8562 - dice_coef_loss: 0.4911\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4947 - accuracy: 0.8753 - dice_coef_loss: 0.4969\n",
      "Epoch 7: loss did not improve from 0.48759\n",
      "100/100 [==============================] - 18s 178ms/step - loss: 0.4947 - accuracy: 0.8753 - dice_coef_loss: 0.4969\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4337 - accuracy: 0.8831 - dice_coef_loss: 0.4337\n",
      "Epoch 8: loss improved from 0.48759 to 0.43372, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 0.4337 - accuracy: 0.8831 - dice_coef_loss: 0.4337\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4227 - accuracy: 0.8846 - dice_coef_loss: 0.4227\n",
      "Epoch 9: loss improved from 0.43372 to 0.42269, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 0.4227 - accuracy: 0.8846 - dice_coef_loss: 0.4227\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4140 - accuracy: 0.8870 - dice_coef_loss: 0.4123\n",
      "Epoch 10: loss improved from 0.42269 to 0.41402, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 0.4140 - accuracy: 0.8870 - dice_coef_loss: 0.4123\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4194 - accuracy: 0.9037 - dice_coef_loss: 0.4194\n",
      "Epoch 11: loss did not improve from 0.41402\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4194 - accuracy: 0.9037 - dice_coef_loss: 0.4194\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4337 - accuracy: 0.8911 - dice_coef_loss: 0.4337\n",
      "Epoch 12: loss did not improve from 0.41402\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4337 - accuracy: 0.8911 - dice_coef_loss: 0.4337\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3950 - accuracy: 0.8900 - dice_coef_loss: 0.3927\n",
      "Epoch 13: loss improved from 0.41402 to 0.39497, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 0.3950 - accuracy: 0.8900 - dice_coef_loss: 0.3927\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3793 - accuracy: 0.8961 - dice_coef_loss: 0.3793\n",
      "Epoch 14: loss improved from 0.39497 to 0.37929, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 0.3793 - accuracy: 0.8961 - dice_coef_loss: 0.3793\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3785 - accuracy: 0.9016 - dice_coef_loss: 0.3785\n",
      "Epoch 15: loss improved from 0.37929 to 0.37849, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 0.3785 - accuracy: 0.9016 - dice_coef_loss: 0.3785\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3901 - accuracy: 0.9013 - dice_coef_loss: 0.3900\n",
      "Epoch 16: loss did not improve from 0.37849\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.3901 - accuracy: 0.9013 - dice_coef_loss: 0.3900\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3797 - accuracy: 0.9048 - dice_coef_loss: 0.3797\n",
      "Epoch 17: loss did not improve from 0.37849\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.3797 - accuracy: 0.9048 - dice_coef_loss: 0.3797\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3610 - accuracy: 0.9139 - dice_coef_loss: 0.3610\n",
      "Epoch 18: loss improved from 0.37849 to 0.36096, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 0.3610 - accuracy: 0.9139 - dice_coef_loss: 0.3610\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3705 - accuracy: 0.9041 - dice_coef_loss: 0.3705\n",
      "Epoch 19: loss did not improve from 0.36096\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.3705 - accuracy: 0.9041 - dice_coef_loss: 0.3705\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3452 - accuracy: 0.9048 - dice_coef_loss: 0.3495\n",
      "Epoch 20: loss improved from 0.36096 to 0.34525, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 0.3452 - accuracy: 0.9048 - dice_coef_loss: 0.3495\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3734 - accuracy: 0.9180 - dice_coef_loss: 0.3734\n",
      "Epoch 21: loss did not improve from 0.34525\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.3734 - accuracy: 0.9180 - dice_coef_loss: 0.3734\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3377 - accuracy: 0.9139 - dice_coef_loss: 0.3377\n",
      "Epoch 22: loss improved from 0.34525 to 0.33766, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 188ms/step - loss: 0.3377 - accuracy: 0.9139 - dice_coef_loss: 0.3377\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3490 - accuracy: 0.9065 - dice_coef_loss: 0.3492\n",
      "Epoch 23: loss did not improve from 0.33766\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.3490 - accuracy: 0.9065 - dice_coef_loss: 0.3492\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3339 - accuracy: 0.9178 - dice_coef_loss: 0.3339\n",
      "Epoch 24: loss improved from 0.33766 to 0.33392, saving model to unet_endoscopic.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 19s 187ms/step - loss: 0.3339 - accuracy: 0.9178 - dice_coef_loss: 0.3339\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3305 - accuracy: 0.9151 - dice_coef_loss: 0.3305\n",
      "Epoch 25: loss improved from 0.33392 to 0.33053, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 0.3305 - accuracy: 0.9151 - dice_coef_loss: 0.3305\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3313 - accuracy: 0.9193 - dice_coef_loss: 0.3295\n",
      "Epoch 26: loss did not improve from 0.33053\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.3313 - accuracy: 0.9193 - dice_coef_loss: 0.3295\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3287 - accuracy: 0.9139 - dice_coef_loss: 0.3287\n",
      "Epoch 27: loss improved from 0.33053 to 0.32872, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 0.3287 - accuracy: 0.9139 - dice_coef_loss: 0.3287\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3415 - accuracy: 0.9177 - dice_coef_loss: 0.3415\n",
      "Epoch 28: loss did not improve from 0.32872\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.3415 - accuracy: 0.9177 - dice_coef_loss: 0.3415\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3258 - accuracy: 0.9190 - dice_coef_loss: 0.3296\n",
      "Epoch 29: loss improved from 0.32872 to 0.32577, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 0.3258 - accuracy: 0.9190 - dice_coef_loss: 0.3296\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3218 - accuracy: 0.9166 - dice_coef_loss: 0.3218\n",
      "Epoch 30: loss improved from 0.32577 to 0.32182, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 0.3218 - accuracy: 0.9166 - dice_coef_loss: 0.3218\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2963 - accuracy: 0.9243 - dice_coef_loss: 0.2963\n",
      "Epoch 31: loss improved from 0.32182 to 0.29628, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 0.2963 - accuracy: 0.9243 - dice_coef_loss: 0.2963\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3290 - accuracy: 0.9165 - dice_coef_loss: 0.3304\n",
      "Epoch 32: loss did not improve from 0.29628\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.3290 - accuracy: 0.9165 - dice_coef_loss: 0.3304\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3042 - accuracy: 0.9240 - dice_coef_loss: 0.3042\n",
      "Epoch 33: loss did not improve from 0.29628\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.3042 - accuracy: 0.9240 - dice_coef_loss: 0.3042\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3040 - accuracy: 0.9267 - dice_coef_loss: 0.3040\n",
      "Epoch 34: loss did not improve from 0.29628\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.3040 - accuracy: 0.9267 - dice_coef_loss: 0.3040\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2966 - accuracy: 0.9250 - dice_coef_loss: 0.2966\n",
      "Epoch 35: loss did not improve from 0.29628\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.2966 - accuracy: 0.9250 - dice_coef_loss: 0.2966\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3172 - accuracy: 0.9165 - dice_coef_loss: 0.3157\n",
      "Epoch 36: loss did not improve from 0.29628\n",
      "100/100 [==============================] - 18s 178ms/step - loss: 0.3172 - accuracy: 0.9165 - dice_coef_loss: 0.3157\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2640 - accuracy: 0.9339 - dice_coef_loss: 0.2640\n",
      "Epoch 37: loss improved from 0.29628 to 0.26403, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 0.2640 - accuracy: 0.9339 - dice_coef_loss: 0.2640\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2892 - accuracy: 0.9308 - dice_coef_loss: 0.2892\n",
      "Epoch 38: loss did not improve from 0.26403\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.2892 - accuracy: 0.9308 - dice_coef_loss: 0.2892\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2868 - accuracy: 0.9298 - dice_coef_loss: 0.2869\n",
      "Epoch 39: loss did not improve from 0.26403\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.2868 - accuracy: 0.9298 - dice_coef_loss: 0.2869\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2729 - accuracy: 0.9287 - dice_coef_loss: 0.2729\n",
      "Epoch 40: loss did not improve from 0.26403\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.2729 - accuracy: 0.9287 - dice_coef_loss: 0.2729\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2915 - accuracy: 0.9290 - dice_coef_loss: 0.2915\n",
      "Epoch 41: loss did not improve from 0.26403\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.2915 - accuracy: 0.9290 - dice_coef_loss: 0.2915\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2630 - accuracy: 0.9292 - dice_coef_loss: 0.2633\n",
      "Epoch 42: loss improved from 0.26403 to 0.26305, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 0.2630 - accuracy: 0.9292 - dice_coef_loss: 0.2633\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2623 - accuracy: 0.9349 - dice_coef_loss: 0.2623\n",
      "Epoch 43: loss improved from 0.26305 to 0.26233, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 0.2623 - accuracy: 0.9349 - dice_coef_loss: 0.2623\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2705 - accuracy: 0.9311 - dice_coef_loss: 0.2705\n",
      "Epoch 44: loss did not improve from 0.26233\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.2705 - accuracy: 0.9311 - dice_coef_loss: 0.2705\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2880 - accuracy: 0.9352 - dice_coef_loss: 0.2908\n",
      "Epoch 45: loss did not improve from 0.26233\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.2880 - accuracy: 0.9352 - dice_coef_loss: 0.2908\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2972 - accuracy: 0.9267 - dice_coef_loss: 0.2972\n",
      "Epoch 46: loss did not improve from 0.26233\n",
      "100/100 [==============================] - 18s 185ms/step - loss: 0.2972 - accuracy: 0.9267 - dice_coef_loss: 0.2972\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3003 - accuracy: 0.9190 - dice_coef_loss: 0.3003\n",
      "Epoch 47: loss did not improve from 0.26233\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 0.3003 - accuracy: 0.9190 - dice_coef_loss: 0.3003\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2434 - accuracy: 0.9358 - dice_coef_loss: 0.2484\n",
      "Epoch 48: loss improved from 0.26233 to 0.24339, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 0.2434 - accuracy: 0.9358 - dice_coef_loss: 0.2484\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2930 - accuracy: 0.9351 - dice_coef_loss: 0.2930\n",
      "Epoch 49: loss did not improve from 0.24339\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.2930 - accuracy: 0.9351 - dice_coef_loss: 0.2930\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2305 - accuracy: 0.9418 - dice_coef_loss: 0.2305\n",
      "Epoch 50: loss improved from 0.24339 to 0.23048, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 0.2305 - accuracy: 0.9418 - dice_coef_loss: 0.2305\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2710 - accuracy: 0.9318 - dice_coef_loss: 0.2710\n",
      "Epoch 51: loss did not improve from 0.23048\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 0.2710 - accuracy: 0.9318 - dice_coef_loss: 0.2710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3152 - accuracy: 0.9182 - dice_coef_loss: 0.3182\n",
      "Epoch 52: loss did not improve from 0.23048\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.3152 - accuracy: 0.9182 - dice_coef_loss: 0.3182\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2713 - accuracy: 0.9313 - dice_coef_loss: 0.2713\n",
      "Epoch 53: loss did not improve from 0.23048\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.2713 - accuracy: 0.9313 - dice_coef_loss: 0.2713\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2528 - accuracy: 0.9281 - dice_coef_loss: 0.2528\n",
      "Epoch 54: loss did not improve from 0.23048\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.2528 - accuracy: 0.9281 - dice_coef_loss: 0.2528\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2976 - accuracy: 0.9225 - dice_coef_loss: 0.2969\n",
      "Epoch 55: loss did not improve from 0.23048\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.2976 - accuracy: 0.9225 - dice_coef_loss: 0.2969\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2805 - accuracy: 0.9332 - dice_coef_loss: 0.2805\n",
      "Epoch 56: loss did not improve from 0.23048\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.2805 - accuracy: 0.9332 - dice_coef_loss: 0.2805\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2405 - accuracy: 0.9363 - dice_coef_loss: 0.2405\n",
      "Epoch 57: loss did not improve from 0.23048\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.2405 - accuracy: 0.9363 - dice_coef_loss: 0.2405\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2450 - accuracy: 0.9401 - dice_coef_loss: 0.2462\n",
      "Epoch 58: loss did not improve from 0.23048\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.2450 - accuracy: 0.9401 - dice_coef_loss: 0.2462\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2366 - accuracy: 0.9428 - dice_coef_loss: 0.2366\n",
      "Epoch 59: loss did not improve from 0.23048\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.2366 - accuracy: 0.9428 - dice_coef_loss: 0.2366\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2615 - accuracy: 0.9298 - dice_coef_loss: 0.2615\n",
      "Epoch 60: loss did not improve from 0.23048\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 0.2615 - accuracy: 0.9298 - dice_coef_loss: 0.2615\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2072 - accuracy: 0.9457 - dice_coef_loss: 0.2064\n",
      "Epoch 61: loss improved from 0.23048 to 0.20723, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 188ms/step - loss: 0.2072 - accuracy: 0.9457 - dice_coef_loss: 0.2064\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2332 - accuracy: 0.9371 - dice_coef_loss: 0.2332\n",
      "Epoch 62: loss did not improve from 0.20723\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.2332 - accuracy: 0.9371 - dice_coef_loss: 0.2332\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2870 - accuracy: 0.9331 - dice_coef_loss: 0.2870\n",
      "Epoch 63: loss did not improve from 0.20723\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.2870 - accuracy: 0.9331 - dice_coef_loss: 0.2870\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2323 - accuracy: 0.9404 - dice_coef_loss: 0.2353\n",
      "Epoch 64: loss did not improve from 0.20723\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.2323 - accuracy: 0.9404 - dice_coef_loss: 0.2353\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2438 - accuracy: 0.9336 - dice_coef_loss: 0.2438\n",
      "Epoch 65: loss did not improve from 0.20723\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.2438 - accuracy: 0.9336 - dice_coef_loss: 0.2438\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2419 - accuracy: 0.9365 - dice_coef_loss: 0.2419\n",
      "Epoch 66: loss did not improve from 0.20723\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.2419 - accuracy: 0.9365 - dice_coef_loss: 0.2419\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2529 - accuracy: 0.9343 - dice_coef_loss: 0.2549\n",
      "Epoch 67: loss did not improve from 0.20723\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.2529 - accuracy: 0.9343 - dice_coef_loss: 0.2549\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2515 - accuracy: 0.9340 - dice_coef_loss: 0.2515\n",
      "Epoch 68: loss did not improve from 0.20723\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 0.2515 - accuracy: 0.9340 - dice_coef_loss: 0.2515\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2282 - accuracy: 0.9425 - dice_coef_loss: 0.2282\n",
      "Epoch 69: loss did not improve from 0.20723\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.2282 - accuracy: 0.9425 - dice_coef_loss: 0.2282\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2224 - accuracy: 0.9438 - dice_coef_loss: 0.2224\n",
      "Epoch 70: loss did not improve from 0.20723\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 0.2224 - accuracy: 0.9438 - dice_coef_loss: 0.2224\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2327 - accuracy: 0.9454 - dice_coef_loss: 0.2319\n",
      "Epoch 71: loss did not improve from 0.20723\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.2327 - accuracy: 0.9454 - dice_coef_loss: 0.2319\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2257 - accuracy: 0.9372 - dice_coef_loss: 0.2257\n",
      "Epoch 72: loss did not improve from 0.20723\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.2257 - accuracy: 0.9372 - dice_coef_loss: 0.2257\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2296 - accuracy: 0.9412 - dice_coef_loss: 0.2296\n",
      "Epoch 73: loss did not improve from 0.20723\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.2296 - accuracy: 0.9412 - dice_coef_loss: 0.2296\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2304 - accuracy: 0.9431 - dice_coef_loss: 0.2291\n",
      "Epoch 74: loss did not improve from 0.20723\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.2304 - accuracy: 0.9431 - dice_coef_loss: 0.2291\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2141 - accuracy: 0.9424 - dice_coef_loss: 0.2141\n",
      "Epoch 75: loss did not improve from 0.20723\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 0.2141 - accuracy: 0.9424 - dice_coef_loss: 0.2141\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2689 - accuracy: 0.9350 - dice_coef_loss: 0.2689\n",
      "Epoch 76: loss did not improve from 0.20723\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.2689 - accuracy: 0.9350 - dice_coef_loss: 0.2689\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2226 - accuracy: 0.9445 - dice_coef_loss: 0.2226\n",
      "Epoch 77: loss did not improve from 0.20723\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.2226 - accuracy: 0.9445 - dice_coef_loss: 0.2226\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2153 - accuracy: 0.9441 - dice_coef_loss: 0.2153\n",
      "Epoch 78: loss did not improve from 0.20723\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.2153 - accuracy: 0.9441 - dice_coef_loss: 0.2153\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2149 - accuracy: 0.9430 - dice_coef_loss: 0.2149\n",
      "Epoch 79: loss did not improve from 0.20723\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.2149 - accuracy: 0.9430 - dice_coef_loss: 0.2149\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2332 - accuracy: 0.9392 - dice_coef_loss: 0.2327\n",
      "Epoch 80: loss did not improve from 0.20723\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.2332 - accuracy: 0.9392 - dice_coef_loss: 0.2327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2626 - accuracy: 0.9431 - dice_coef_loss: 0.2626\n",
      "Epoch 81: loss did not improve from 0.20723\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.2626 - accuracy: 0.9431 - dice_coef_loss: 0.2626\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2019 - accuracy: 0.9457 - dice_coef_loss: 0.2019\n",
      "Epoch 82: loss improved from 0.20723 to 0.20188, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 191ms/step - loss: 0.2019 - accuracy: 0.9457 - dice_coef_loss: 0.2019\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2705 - accuracy: 0.9202 - dice_coef_loss: 0.2732\n",
      "Epoch 83: loss did not improve from 0.20188\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 0.2705 - accuracy: 0.9202 - dice_coef_loss: 0.2732\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2218 - accuracy: 0.9428 - dice_coef_loss: 0.2218\n",
      "Epoch 84: loss did not improve from 0.20188\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.2218 - accuracy: 0.9428 - dice_coef_loss: 0.2218\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2043 - accuracy: 0.9478 - dice_coef_loss: 0.2043\n",
      "Epoch 85: loss did not improve from 0.20188\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.2043 - accuracy: 0.9478 - dice_coef_loss: 0.2043\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2065 - accuracy: 0.9451 - dice_coef_loss: 0.2065\n",
      "Epoch 86: loss did not improve from 0.20188\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.2065 - accuracy: 0.9451 - dice_coef_loss: 0.2065\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2116 - accuracy: 0.9419 - dice_coef_loss: 0.2160\n",
      "Epoch 87: loss did not improve from 0.20188\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.2116 - accuracy: 0.9419 - dice_coef_loss: 0.2160\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2370 - accuracy: 0.9364 - dice_coef_loss: 0.2370\n",
      "Epoch 88: loss did not improve from 0.20188\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.2370 - accuracy: 0.9364 - dice_coef_loss: 0.2370\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2163 - accuracy: 0.9447 - dice_coef_loss: 0.2163\n",
      "Epoch 89: loss did not improve from 0.20188\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.2163 - accuracy: 0.9447 - dice_coef_loss: 0.2163\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2157 - accuracy: 0.9465 - dice_coef_loss: 0.2147\n",
      "Epoch 90: loss did not improve from 0.20188\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.2157 - accuracy: 0.9465 - dice_coef_loss: 0.2147\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2271 - accuracy: 0.9393 - dice_coef_loss: 0.2271\n",
      "Epoch 91: loss did not improve from 0.20188\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.2271 - accuracy: 0.9393 - dice_coef_loss: 0.2271\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2028 - accuracy: 0.9475 - dice_coef_loss: 0.2028\n",
      "Epoch 92: loss did not improve from 0.20188\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.2028 - accuracy: 0.9475 - dice_coef_loss: 0.2028\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2106 - accuracy: 0.9495 - dice_coef_loss: 0.2102\n",
      "Epoch 93: loss did not improve from 0.20188\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.2106 - accuracy: 0.9495 - dice_coef_loss: 0.2102\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2496 - accuracy: 0.9419 - dice_coef_loss: 0.2496\n",
      "Epoch 94: loss did not improve from 0.20188\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.2496 - accuracy: 0.9419 - dice_coef_loss: 0.2496\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2055 - accuracy: 0.9479 - dice_coef_loss: 0.2055\n",
      "Epoch 95: loss did not improve from 0.20188\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.2055 - accuracy: 0.9479 - dice_coef_loss: 0.2055\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2161 - accuracy: 0.9428 - dice_coef_loss: 0.2177\n",
      "Epoch 96: loss did not improve from 0.20188\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.2161 - accuracy: 0.9428 - dice_coef_loss: 0.2177\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2326 - accuracy: 0.9426 - dice_coef_loss: 0.2326\n",
      "Epoch 97: loss did not improve from 0.20188\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.2326 - accuracy: 0.9426 - dice_coef_loss: 0.2326\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2582 - accuracy: 0.9404 - dice_coef_loss: 0.2582\n",
      "Epoch 98: loss did not improve from 0.20188\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.2582 - accuracy: 0.9404 - dice_coef_loss: 0.2582\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2194 - accuracy: 0.9413 - dice_coef_loss: 0.2192\n",
      "Epoch 99: loss did not improve from 0.20188\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.2194 - accuracy: 0.9413 - dice_coef_loss: 0.2192\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2045 - accuracy: 0.9413 - dice_coef_loss: 0.2045\n",
      "Epoch 100: loss did not improve from 0.20188\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 0.2045 - accuracy: 0.9413 - dice_coef_loss: 0.2045\n"
     ]
    }
   ],
   "source": [
    "test_run = test_model.fit(test_gene, verbose = 1, steps_per_epoch = 100, epochs = 100, callbacks = [model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(test_run.history.keys())\n",
    "plt.plot(test_run.history['loss'])\n",
    "plt.plot(test_run.history['accuracy'])\n",
    "plt.title('Test Run')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss', 'accuracy'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f2e5c1b8ef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f2e5c1b8ef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 0s 149ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "PARAM_PATH_TEST = './test'\n",
    "image_name = '14.tif'\n",
    "img = io.imread(os.path.join(PARAM_PATH_TEST,image_name),as_gray = False)\n",
    "img = trans.resize(img,[256,256])\n",
    "img = np.reshape(img,(1,)+img.shape)\n",
    "\n",
    "results = test_model.predict(img,1,verbose=1)\n",
    "#saveResult(Path,results)\n",
    "img = results[0,:,:]\n",
    "print(results.shape)\n",
    "io.imsave(os.path.join(PARAM_PATH_TEST,\"result.png\"),img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy Code Below\n",
    "### written by Wenfan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from defines import *\n",
    "from model import *\n",
    "from data import *\n",
    "import sys\n",
    "\n",
    "from numpy import loadtxt\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "\n",
    "import glob\n",
    "import os \n",
    "import math\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data_jupyter'# main folder path\n",
    "\n",
    "D = 'all_images'\n",
    "L = 'all_labels'\n",
    "\n",
    "D_P_im = 'polar_im'\n",
    "D_C_im = 'car_im'\n",
    "D_P = 'polar_l'\n",
    "D_C = 'car_l'\n",
    "\n",
    "prev_number_of_D_P = -1\n",
    "prev_number_of_D_C = -1\n",
    "\n",
    "diff = math.inf\n",
    "\n",
    "model_P = unet(PARAM_BETA1[PARAM_BETA_TEST_NUM], PARAM_BETA2[PARAM_BETA_TEST_NUM])\n",
    "model_C = unet(PARAM_BETA1[PARAM_BETA_TEST_NUM], PARAM_BETA2[PARAM_BETA_TEST_NUM])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill in the weights here\n",
    "model_P.load_weights() \n",
    "model_C.load_weights() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "#change file name of D, L\n",
    "for count, filename in enumerate(os.listdir(path+'/'+D)): \n",
    "    dst = str(count) + \".png\"\n",
    "    src = path+'/'+D+'/'+filename\n",
    "    dst = path+'/'+D+'/'+dst\n",
    "\n",
    "    os.rename(src, dst) \n",
    "    \n",
    "for count, filename in enumerate(os.listdir(path+'/'+L)): \n",
    "    dst = str(count) + \".tif\"\n",
    "    src = path+'/'+L+'/'+filename\n",
    "    dst = path+'/'+L+'/'+dst\n",
    "\n",
    "    os.rename(src, dst) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dscore(im, im_name):\n",
    "    label = Image.open(os.path.join(L, im_name))\n",
    "    \n",
    "    pixelIm = im.load()\n",
    "    pixelLabel = label.load()\n",
    "    \n",
    "    upper = 0\n",
    "    lower = im.size[0] * im.size[1]\n",
    "    \n",
    "    for i in range(im.size[0]):\n",
    "        for j in range(im.size[1]):\n",
    "            if pixelIm[i,j] == pixelLabel[i,j]:\n",
    "                upper = upper + 1\n",
    "            \n",
    "    upper = upper * 2\n",
    "    \n",
    "    return upper / lower\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while (diff > 0): \n",
    "    #load model\n",
    "    #if count > 0:\n",
    "    #    model_P.load_weights('model_P_weights_' + (count - 1))\n",
    "    #    model_C.load_weights('model_C_weights_' + (count - 1))\n",
    "    \n",
    "    count = count + 1\n",
    "    \n",
    "    testGene_P, testGene_C = testGenerator(path,D,L)\n",
    "    \n",
    "    #perdict\n",
    "    results_P = model_P.predict(testGene_P, PARAM_N_TESTS, verbose=1)\n",
    "    results_C = model_C.predict(testGene_C, PARAM_N_TESTS, verbose=1)\n",
    "\n",
    "    np.save(PARAM_PATH_TEST_NPY_P, results_P)\n",
    "    saveResult(PARAM_PATH_TEST_RESULTS_P, results_P)\n",
    "    np.save(PARAM_PATH_TEST_NPY_C, results_C)\n",
    "    saveResult(PARAM_PATH_TEST_RESULTS_C, results_C)\n",
    "    \n",
    "    mergeIm(path, D, L, PARAM_PATH_TEST_RESULTS_P, path+'/'+D_P)\n",
    "    mergeIm(path, D, L, PARAM_PATH_TEST_RESULTS_C, path+'/'+D_C)\n",
    "    \n",
    "    #change file name of D_P, D_C\n",
    "    for count, filename in enumerate(os.listdir(path+'/'+D_P)): \n",
    "        dst = str(count) + \".tif\"\n",
    "        src = path+'/'+D_P+'/'+filenaLme\n",
    "        dst = path+'/'+D_P+'/'+dst\n",
    "\n",
    "        os.rename(src, dst) \n",
    "  \n",
    "    for count, filename in enumerate(os.listdir(path+'/'+D_C)): \n",
    "        dst = str(count) + \".tif\"\n",
    "        src = path+'/'+D_C+'/'+filename\n",
    "        dst = path+'/'+D_C+'/'+dst\n",
    "\n",
    "        os.rename(src, dst) \n",
    "    \n",
    "    #find the better one (based on L) and modify D_P, D_P_im, D_C, D_C_im\n",
    "    for file in os.listdir(D):\n",
    "        im_P = Image.open(path+'/'+D_P+'/'+file)\n",
    "        im_C = Image.open(path+'/'+D_C+'/'+file)\n",
    "        \n",
    "        if dscore(im_P, file) > dscore(im_C, file):\n",
    "            shutil.copyfile(path+'/'+D+'/'+file, path+'/'+D_P_im+'/'+file)\n",
    "            os.remove(path+'/'+D_C+'/'+file)\n",
    "        else:\n",
    "            shutil.copyfile(path+'/'+D+'/'+file, path+'/'+D_C_im+'/'+file)\n",
    "            os.remove(path+'/'+D_P+'/'+file)\n",
    "            \n",
    "    number_of_D_P = len(glob.glob(D_P))\n",
    "    number_of_D_C = len(glob.glob(D_C))\n",
    "\n",
    "    # file numbers difference\n",
    "    diff = Math.abs(prev_number_of_D_P - number_of_D_P + prev_number_of_D_C - number_of_D_C) / 2\n",
    "    \n",
    "    prev_number_of_D_P = number_of_D_P\n",
    "    prev_number_of_D_C = number_of_D_P\n",
    "    \n",
    "    #train model_P only on D_P, model_C only on D_C\n",
    "    myGene_P = trainGenerator(PARAM_BATCHES, \n",
    "                            path, \n",
    "                            D_P, \n",
    "                            D_P_im, \n",
    "                            PARAM_DATA_ARGS, \n",
    "                            save_to_dir = PARAM_AUG_FOLDER_P)\n",
    "    \n",
    "    myGene_C = trainGenerator(PARAM_BATCHES, \n",
    "                            path, \n",
    "                            D_C, \n",
    "                            D_C_im, \n",
    "                            PARAM_DATA_ARGS, \n",
    "                            save_to_dir = PARAM_AUG_FOLDER_C)\n",
    "    \n",
    "    model_checkpoint_P = ModelCheckpoint( PARAM_SAVED_MODEL, \n",
    "                                         monitor = PARAM_METRICS, \n",
    "                                         verbose = 1, \n",
    "                                         save_best_only = PARAM_SAVE_BEST_ONLY)\n",
    "    \n",
    "    model_P.fit_generator(myGene_P,\n",
    "                        steps_per_epoch = PARAM_EPOCH_STEPS,\n",
    "                        epochs = PARAM_N_EPOCHS,\n",
    "                        callbacks = [model_checkpoint])\n",
    "    model_C.fit_generator(myGene_C,\n",
    "                        steps_per_epoch = PARAM_EPOCH_STEPS,\n",
    "                        epochs = PARAM_N_EPOCHS,\n",
    "                        callbacks = [model_checkpoint])\n",
    "    \n",
    "    model_P.save_weights('model_P_weights_' + count)\n",
    "    model_C.save_weights('model_C_weights_' + count)\n",
    "    \n",
    "    shutil.rmtree(path+'/'+D_P)\n",
    "    shutil.rmtree(path+'/'+D_C)\n",
    "    shutil.rmtree(path+'/'+D_P_im)\n",
    "    shutil.rmtree(path+'/'+D_C_im)\n",
    "    \n",
    "\n",
    "save_model(model_P, 'model_P.h5')\n",
    "save_model(model_C, 'model_C.h5')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
