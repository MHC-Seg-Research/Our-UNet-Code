{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Approach for Unet Training \n",
    "\n",
    "------\n",
    "\n",
    "## Overview\n",
    "\n",
    "\n",
    "\n",
    "The purpose of this learn.ipynb notebook is to investigate whether an image can exhibit a preference for being segmented more effectively using a UNet model trained on polar or cartesian-dominant images.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Structure\n",
    "```\n",
    "data\n",
    "└── endoscopic\n",
    "    ├── cartesian\n",
    "    │   ├── image\n",
    "    │   └── label\n",
    "    └── polar\n",
    "        ├── image\n",
    "        └── label\n",
    "```\n",
    "\n",
    "Inside of each end folder there are 956 images, named as `0.tif` to `955.tif`\n",
    "and I believe, for now, the naming of the images are one to one correctly matched, meaning the ``/data/endoscopic/**cartesian**/image/0.tif`` is transformed from `/data/endoscopic/**polar**/image/0.tif`\n",
    "\n",
    "Instead of putting a seperate set of images aside to be test set, we chose to use k-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from defines import *\n",
    "from model import *\n",
    "from data import *\n",
    "import sys\n",
    "\n",
    "from numpy import loadtxt\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from skimage.io import imread\n",
    "from skimage import img_as_ubyte\n",
    "from skimage.transform import resize\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import math\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import from files and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this if your computer has a cuda visible device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PARAM_SYSTEM_TIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test code for correct file structure setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize folder tree in current directory\n",
    "os.system(\"tree -d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count of files in data directories\n",
    "os.system(\"ls \" + os.path.join(PARAM_PATH_CARTE,PARAM_IMG_FOLDER) + \" | wc -l\")\n",
    "os.system(\"ls \" + os.path.join(PARAM_PATH_CARTE,PARAM_MSK_FOLDER) + \" | wc -l\")\n",
    "os.system(\"ls \" + os.path.join(PARAM_PATH_POLAR,PARAM_IMG_FOLDER) + \" | wc -l\")\n",
    "os.system(\"ls \" + os.path.join(PARAM_PATH_POLAR,PARAM_MSK_FOLDER) + \" | wc -l\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Expected Output:\n",
    "7404\\\n",
    "7404\\\n",
    "7404\\\n",
    "7404\\\n",
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Relocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following block, the code loads in one analysis file from previous research. \n",
    "\n",
    "### #File name postfix\n",
    "_C_ is the dice scores of the predictions generated by Unet C: this Unet C is trained using all 7404 images, in their cartesian form. The raw image was directly input into the Unet and the prediction was generated.\n",
    "\n",
    "_P_ is the dice scores of the predictions generated by Unet P: this Unet P is trained using all 7404 images but in their polar form. The raw images were transformed, and then input for prediction. The prediction is in polar space.\n",
    "\n",
    "_P2C_ is the dice scores of the predictions generated by the same Unet P as mentioned above, but the dice score is generated by transforming the prediction back to cartesian, and compared to their original label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name = 'analysis_dice_back_Test_C.npy'\n",
    "#file_name = 'analysis_dice_back_Test_P.npy'\n",
    "#file_name = 'analysis_dice_back_Test_P2C.npy'\n",
    "file_name = 'analysis_dice_back_Train_P.npy'\n",
    "\n",
    "np_file = os.path.join(PARAM_PATH_SCORES, file_name)\n",
    "#load npy file\n",
    "img_score = np.load(np_file)\n",
    "\n",
    "#sort scores in descending order and store index\n",
    "sorted_score = np.flip(np.argsort(img_score))\n",
    "\n",
    "#------DEBUG--------\n",
    "#print(len(sorted_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sorted_score` should be a list of length 7404, sorted by the method we chose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_score = pd.DataFrame(sorted_score)\n",
    "\n",
    "#fetch top polar dominant and non-polar dominant image\n",
    "num_polar = round(len(sorted_score)/2)\n",
    "num_cartesian = len(sorted_score) - num_polar\n",
    "dfPolar = sorted_score.head(num_polar)\n",
    "dfCartesian = sorted_score.tail(num_cartesian)\n",
    "#print(\"Polar: \\n\", dfPolar)\n",
    "#print(\"Cartesian: \\n\", dfCartesian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in `dfPolar` should be the best half of images (filename), which performs better than the other half, according to the data we used above. In `dfCartesian` there's the other half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filePrep import *\n",
    "\n",
    "K = 5\n",
    "\n",
    "checkNcreateTempFolder(PARAM_PATH_TEMP_POLAR, K)\n",
    "checkNcreateTempFolder(PARAM_PATH_TEMP_CARTE, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two lines creates the new temporary folder.\n",
    "Instead of making kfolds later, the kfolds is assigned now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = K, shuffle = True, random_state = 42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the KFold package to assign the paramters like n_splits and so.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for train_index,test_index in kf.split(dfPolar):\n",
    "    fillFolder(test_index, dfPolar, PARAM_PATH_POLAR, PARAM_PATH_CARTE, PARAM_PATH_TEMP_POLAR, i)\n",
    "    i += 1\n",
    "i = 0\n",
    "print('------------------------------------')\n",
    "for train_index,test_index in kf.split(dfCartesian):\n",
    "    fillFolder(test_index, dfCartesian, PARAM_PATH_POLAR, PARAM_PATH_CARTE, PARAM_PATH_TEMP_CARTE, i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we should have all `k-folds` set up. The next step is to write a training loop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the limitation of flow_from_directory, which, it does not allow the combination of multiple directories. And, the limitation of my knowledge of flow_from_dataframe. **I believe this is solvable using flow_from_dataframe** I decide to move training set into a separate temporary folder when training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "PARAM_BETA_TEST_NUM = 6\n",
    "data_gen_args = dict(rotation_range = 50,      # TODO: improve the data augmentation\n",
    "                width_shift_range =0.2,\n",
    "                height_shift_range =0.2,\n",
    "                shear_range = 0.35,\n",
    "                zoom_range = 0.05,\n",
    "                horizontal_flip = True,\n",
    "                fill_mode = 'nearest',\n",
    "                rescale = 1./255)\n",
    "#Train polar models\n",
    "working_parent_folder = PARAM_PATH_TEMP_POLAR\n",
    "Polar_history = []\n",
    "for i in range(K):\n",
    "    working_test_folder_i = os.path.join(working_parent_folder, str(i), PARAM_SUB_FOLDER_POLAR)\n",
    "    temp_folder_path = os.path.join(working_parent_folder,'temp')\n",
    "    os.mkdir(temp_folder_path)\n",
    "    for j in range(K):\n",
    "        if i != j:\n",
    "            for subfolder_name in ['image','label']:\n",
    "                subfolder_path = os.path.join(working_parent_folder,str(j),'polar',subfolder_name)\n",
    "                temp_subfolder_path = os.path.join(temp_folder_path,subfolder_name)\n",
    "                for root, dirs, files in os.walk(subfolder_path):\n",
    "                    for file in files:\n",
    "                        src_file = os.path.join(root, file)\n",
    "                        dest_file = os.path.join(temp_subfolder_path,os.path.relpath(src_file, subfolder_path))\n",
    "                        os.makedirs(os.path.dirname(dest_file), exist_ok=True)\n",
    "                        shutil.copy(src_file, dest_file)\n",
    "    test_gene = trainGenerator(batch_size, temp_folder_path, PARAM_IMG_FOLDER, PARAM_MSK_FOLDER, data_gen_args)\n",
    "    model = unet(PARAM_BETA1[PARAM_BETA_TEST_NUM], PARAM_BETA2[PARAM_BETA_TEST_NUM]) \n",
    "    model_checkpoint = ModelCheckpoint(os.path.join(working_parent_folder,str(i),'checkpoint.hdf5'), monitor = 'loss', verbose=1, save_best_only=True)\n",
    "    test_run = model.fit(test_gene, verbose = 1, steps_per_epoch = 100, epochs = 100, callbacks = [model_checkpoint])\n",
    "    Polar_history.append(test_run)\n",
    "    shutil.rmtree(temp_folder_path)\n",
    "    \n",
    "#Train cartesian models\n",
    "data_gen_args = dict(rotation_range = 80,      # TODO: improve the data augmentation\n",
    "                width_shift_range =0.02,\n",
    "                height_shift_range =0.02,\n",
    "                shear_range = 0.35,\n",
    "                zoom_range = 0.075,\n",
    "                horizontal_flip = True,\n",
    "                fill_mode = 'nearest',\n",
    "                rescale = 1./255)\n",
    "working_parent_folder = PARAM_PATH_TEMP_CARTE\n",
    "Cartesian_history = []\n",
    "for i in range(K):\n",
    "    working_test_folder_i = os.path.join(working_parent_folder, str(i), PARAM_SUB_FOLDER_CARTE)\n",
    "    temp_folder_path = os.path.join(working_parent_folder,'temp')\n",
    "    os.mkdir(temp_folder_path)\n",
    "    for j in range(K):\n",
    "        if i != j:\n",
    "            for subfolder_name in ['image','label']:\n",
    "                subfolder_path = os.path.join(working_parent_folder,str(j),'carte',subfolder_name)\n",
    "                temp_subfolder_path = os.path.join(temp_folder_path,subfolder_name)\n",
    "                for root, dirs, files in os.walk(subfolder_path):\n",
    "                    for file in files:\n",
    "                        src_file = os.path.join(root, file)\n",
    "                        dest_file = os.path.join(temp_subfolder_path,os.path.relpath(src_file, subfolder_path))\n",
    "                        os.makedirs(os.path.dirname(dest_file), exist_ok=True)\n",
    "                        shutil.copy(src_file, dest_file)\n",
    "    test_gene = trainGenerator(batch_size, temp_folder_path, PARAM_IMG_FOLDER, PARAM_MSK_FOLDER, data_gen_args)\n",
    "    model = unet(PARAM_BETA1[PARAM_BETA_TEST_NUM], PARAM_BETA2[PARAM_BETA_TEST_NUM]) \n",
    "    model_checkpoint = ModelCheckpoint(os.path.join(working_parent_folder,str(i),'checkpoint.hdf5'), monitor = 'loss', verbose=1, save_best_only=True)\n",
    "    test_run = model.fit(test_gene, verbose = 1, steps_per_epoch = 100, epochs = 100, callbacks = [model_checkpoint])\n",
    "    Cartesian_history.append(test_run)\n",
    "    shutil.rmtree(temp_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last block there trained all 10 models, the 10 models' checkpoints are saved in the temp folder of each test model. For example, if stored in folder `temp/polar_Dom/0/`, the model is assumed to be trained on all folders except the current folder -- namingly, `folder 1,2,3,4`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for single_run in Polar_history:\n",
    "    plt.plot(single_run.history['loss'])\n",
    "    plt.plot(single_run.history['accuracy'])\n",
    "    plt.title('Polar Run')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['loss', 'accuracy'], loc='upper left')\n",
    "    plt.show()\n",
    "print('________________________________________________')\n",
    "for single_run in Cartesian_history:\n",
    "    plt.plot(single_run.history['loss'])\n",
    "    plt.plot(single_run.history['accuracy'])\n",
    "    plt.title('Cartesian Run')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['loss', 'accuracy'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now, all of the ten models from each group are trained, the next step is to load each of them and predict using every other images that are not in the training set as inputs. Note that `polar dominant models` should only take `polar` images as inputs and `cartesian dominant models` should only take `cartesian` images as inputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block is supposed to get and check the number of images and masks in the source folder. *could be moved to previous blocks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WE have a matching number of images and labels here, count =  7404\n"
     ]
    }
   ],
   "source": [
    "#Predict using polar dominant images\n",
    "image_extension = 'tif'\n",
    "image_count = 0\n",
    "img_pattern = os.path.join(PARAM_PATH_POLAR, PARAM_IMG_FOLDER, f'*.{image_extension}')\n",
    "image_files = glob.glob(img_pattern)\n",
    "msk_pattern = os.path.join(PARAM_PATH_POLAR, PARAM_MSK_FOLDER, f'*.{image_extension}')\n",
    "msk_files = glob.glob(msk_pattern)\n",
    "#length matching check\n",
    "if len(image_files) == len(msk_files):\n",
    "    print('WE have a matching number of images and labels here, count = ', len(msk_files))\n",
    "else:\n",
    "    print('Something is wrong with the original data set. [Unmatching number of images/masks.]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5 #if we don't want to train again, run this\n",
    "PARAM_BETA_TEST_NUM = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a numpy array to showcase the distribution of files\n",
    "\n",
    "n = len(image_files)\n",
    "m = K * 2\n",
    "\n",
    "filematrix = np.zeros((n,m))\n",
    "for img_type in ['polar', 'carte']:\n",
    "    #\n",
    "    img_extenstion = 'tif'\n",
    "    #\n",
    "    for_counter = 0\n",
    "    if img_type == 'polar':\n",
    "        working_parent_folder = PARAM_PATH_TEMP_POLAR\n",
    "    else:\n",
    "        working_parent_folder = PARAM_PATH_TEMP_CARTE\n",
    "        for_counter += 1\n",
    "    for i in range(K):\n",
    "        image_path = os.path.join(working_parent_folder, str(i), img_type, PARAM_IMG_FOLDER)\n",
    "        img_pattern = os.path.join(image_path, f'*.{image_extension}')\n",
    "        image_files = glob.glob(img_pattern)\n",
    "        for file_name in image_files:\n",
    "            file_name_shorten = os.path.basename(file_name)\n",
    "            file_name_raw, ext = os.path.splitext(file_name_shorten)\n",
    "            filematrix[int(file_name_raw),i + for_counter * K] = 1\n",
    "        number_of_ones = np.count_nonzero(filematrix == 1)\n",
    "        #print(number_of_ones)  #uncomment this line when png file is not satisfactory, we can track the number of ones during each step  \n",
    "plt.imsave('filematrix.png', filematrix, cmap = 'binary')\n",
    "row_indices, col_indices = np.where(filematrix == 0)\n",
    "indices = list(zip(row_indices, col_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we will have a .png file saved to the root directory, zoom in and we should be able to see only one pixel is colored black in each row.\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next block, we will loop through all sub folders, register all images appears in the training set, and reverse, and take the images from that specific big class, directly from the original data folder, and throw them to a temporary folder.\n",
    "\n",
    "Now that we have the `filematrix`, we can go over each coloumn, pull out files into a temporary folder and make a round of prediction using that model if the value is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-26 21:17:42.584945: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-26 21:17:42.716719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-26 21:17:42.716862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-26 21:17:42.717948: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-26 21:17:42.718926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-26 21:17:42.719036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-26 21:17:42.719128: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-26 21:17:43.813223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-26 21:17:43.813408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-26 21:17:43.813540: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-26 21:17:43.813635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6954 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "2023-09-26 21:17:53.340473: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 5239996416 exceeds 10% of free system memory.\n",
      "2023-09-26 21:17:55.878495: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 5239996416 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f67ac5e0680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f67ac5e0680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-26 21:17:57.688198: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.58GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-09-26 21:17:57.688239: W tensorflow/core/kernels/gpu_utils.cc:50] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\n",
      "2023-09-26 21:17:59.210866: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n",
      "2023-09-26 21:18:00.690875: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-09-26 21:18:01.325748: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 691.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-09-26 21:18:12.223314: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.56GiB (rounded to 1677721600)requested by op model/conv2d_1/Conv2D\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-09-26 21:18:12.223384: I tensorflow/core/common_runtime/bfc_allocator.cc:1027] BFCAllocator dump for GPU_0_bfc\n",
      "2023-09-26 21:18:12.223412: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (256): \tTotal Chunks: 28, Chunks in use: 28. 7.0KiB allocated for chunks. 7.0KiB in use in bin. 1.4KiB client-requested in use in bin.\n",
      "2023-09-26 21:18:12.223433: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (512): \tTotal Chunks: 6, Chunks in use: 5. 3.2KiB allocated for chunks. 2.8KiB in use in bin. 2.5KiB client-requested in use in bin.\n",
      "2023-09-26 21:18:12.223452: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (1024): \tTotal Chunks: 6, Chunks in use: 6. 6.8KiB allocated for chunks. 6.8KiB in use in bin. 6.0KiB client-requested in use in bin.\n",
      "2023-09-26 21:18:12.223473: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (2048): \tTotal Chunks: 5, Chunks in use: 5. 12.0KiB allocated for chunks. 12.0KiB in use in bin. 10.0KiB client-requested in use in bin.\n",
      "2023-09-26 21:18:12.223494: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (4096): \tTotal Chunks: 6, Chunks in use: 4. 30.5KiB allocated for chunks. 22.0KiB in use in bin. 19.2KiB client-requested in use in bin.\n",
      "2023-09-26 21:18:12.223511: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-26 21:18:12.223528: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-26 21:18:12.223543: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-26 21:18:12.223562: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (65536): \tTotal Chunks: 1, Chunks in use: 0. 124.5KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-26 21:18:12.223594: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (131072): \tTotal Chunks: 3, Chunks in use: 3. 417.8KiB allocated for chunks. 417.8KiB in use in bin. 416.0KiB client-requested in use in bin.\n",
      "2023-09-26 21:18:12.223616: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (262144): \tTotal Chunks: 3, Chunks in use: 2. 1.06MiB allocated for chunks. 800.2KiB in use in bin. 576.0KiB client-requested in use in bin.\n",
      "2023-09-26 21:18:12.223635: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (524288): \tTotal Chunks: 4, Chunks in use: 3. 2.53MiB allocated for chunks. 1.96MiB in use in bin. 1.62MiB client-requested in use in bin.\n",
      "2023-09-26 21:18:12.223653: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (1048576): \tTotal Chunks: 3, Chunks in use: 2. 3.89MiB allocated for chunks. 2.45MiB in use in bin. 2.25MiB client-requested in use in bin.\n",
      "2023-09-26 21:18:12.223673: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (2097152): \tTotal Chunks: 4, Chunks in use: 3. 10.38MiB allocated for chunks. 7.00MiB in use in bin. 6.50MiB client-requested in use in bin.\n",
      "2023-09-26 21:18:12.223693: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (4194304): \tTotal Chunks: 3, Chunks in use: 2. 14.75MiB allocated for chunks. 9.00MiB in use in bin. 9.00MiB client-requested in use in bin.\n",
      "2023-09-26 21:18:12.223712: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (8388608): \tTotal Chunks: 5, Chunks in use: 3. 50.50MiB allocated for chunks. 28.00MiB in use in bin. 26.00MiB client-requested in use in bin.\n",
      "2023-09-26 21:18:12.223733: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (16777216): \tTotal Chunks: 2, Chunks in use: 2. 36.00MiB allocated for chunks. 36.00MiB in use in bin. 36.00MiB client-requested in use in bin.\n",
      "2023-09-26 21:18:12.223752: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (33554432): \tTotal Chunks: 1, Chunks in use: 1. 36.00MiB allocated for chunks. 36.00MiB in use in bin. 36.00MiB client-requested in use in bin.\n",
      "2023-09-26 21:18:12.223769: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-26 21:18:12.223790: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (134217728): \tTotal Chunks: 1, Chunks in use: 0. 150.00MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-26 21:18:12.223809: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (268435456): \tTotal Chunks: 2, Chunks in use: 2. 6.49GiB allocated for chunks. 6.49GiB in use in bin. 6.44GiB client-requested in use in bin.\n",
      "2023-09-26 21:18:12.223828: I tensorflow/core/common_runtime/bfc_allocator.cc:1050] Bin for 1.56GiB was 256.00MiB, Chunk State: \n",
      "2023-09-26 21:18:12.223842: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 7292256256\n",
      "2023-09-26 21:18:12.223866: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530000000 of size 1280 next 1\n",
      "2023-09-26 21:18:12.223880: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530000500 of size 256 next 2\n",
      "2023-09-26 21:18:12.223893: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530000600 of size 256 next 3\n",
      "2023-09-26 21:18:12.223905: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530000700 of size 256 next 4\n",
      "2023-09-26 21:18:12.223917: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530000800 of size 256 next 7\n",
      "2023-09-26 21:18:12.223929: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530000900 of size 256 next 8\n",
      "2023-09-26 21:18:12.223943: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530000a00 of size 768 next 14\n",
      "2023-09-26 21:18:12.223958: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530000d00 of size 256 next 15\n",
      "2023-09-26 21:18:12.223971: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530000e00 of size 1536 next 21\n",
      "2023-09-26 21:18:12.223983: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530001400 of size 256 next 22\n",
      "2023-09-26 21:18:12.223996: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530001500 of size 3072 next 28\n",
      "2023-09-26 21:18:12.224009: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530002100 of size 256 next 29\n",
      "2023-09-26 21:18:12.224021: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530002200 of size 6912 next 5\n",
      "2023-09-26 21:18:12.224034: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530003d00 of size 256 next 79\n",
      "2023-09-26 21:18:12.224047: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530003e00 of size 512 next 13\n",
      "2023-09-26 21:18:12.224060: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530004000 of size 1024 next 19\n",
      "2023-09-26 21:18:12.224073: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530004400 of size 2048 next 16\n",
      "2023-09-26 21:18:12.224085: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530004c00 of size 3072 next 6\n",
      "2023-09-26 21:18:12.224097: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530005800 of size 256 next 35\n",
      "2023-09-26 21:18:12.224110: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f6530005900 of size 4096 next 36\n",
      "2023-09-26 21:18:12.224122: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530006900 of size 256 next 39\n",
      "2023-09-26 21:18:12.224134: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530006a00 of size 2048 next 40\n",
      "2023-09-26 21:18:12.224147: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530007200 of size 2048 next 44\n",
      "2023-09-26 21:18:12.224159: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530007a00 of size 1024 next 30\n",
      "2023-09-26 21:18:12.224171: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530007e00 of size 1024 next 46\n",
      "2023-09-26 21:18:12.224183: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530008200 of size 256 next 47\n",
      "2023-09-26 21:18:12.224196: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530008300 of size 1024 next 45\n",
      "2023-09-26 21:18:12.224209: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530008700 of size 512 next 51\n",
      "2023-09-26 21:18:12.224221: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530008900 of size 256 next 65\n",
      "2023-09-26 21:18:12.224233: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530008a00 of size 256 next 63\n",
      "2023-09-26 21:18:12.224246: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530008b00 of size 256 next 67\n",
      "2023-09-26 21:18:12.224258: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530008c00 of size 256 next 81\n",
      "2023-09-26 21:18:12.224270: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f6530008d00 of size 512 next 53\n",
      "2023-09-26 21:18:12.224282: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530008f00 of size 256 next 54\n",
      "2023-09-26 21:18:12.224294: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530009000 of size 512 next 55\n",
      "2023-09-26 21:18:12.224307: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530009200 of size 512 next 58\n",
      "2023-09-26 21:18:12.224319: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530009400 of size 256 next 10\n",
      "2023-09-26 21:18:12.224331: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530009500 of size 256 next 60\n",
      "2023-09-26 21:18:12.224343: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530009600 of size 256 next 61\n",
      "2023-09-26 21:18:12.224356: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530009700 of size 426240 next 11\n",
      "2023-09-26 21:18:12.224368: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530071800 of size 4608 next 64\n",
      "2023-09-26 21:18:12.224383: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f6530072a00 of size 127488 next 68\n",
      "2023-09-26 21:18:12.224396: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530091c00 of size 256 next 71\n",
      "2023-09-26 21:18:12.224408: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530091d00 of size 256 next 72\n",
      "2023-09-26 21:18:12.224421: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530091e00 of size 256 next 73\n",
      "2023-09-26 21:18:12.224432: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530091f00 of size 256 next 74\n",
      "2023-09-26 21:18:12.224445: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530092000 of size 256 next 75\n",
      "2023-09-26 21:18:12.224457: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530092100 of size 256 next 76\n",
      "2023-09-26 21:18:12.224469: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530092200 of size 256 next 77\n",
      "2023-09-26 21:18:12.224481: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530092300 of size 256 next 78\n",
      "2023-09-26 21:18:12.224493: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530092400 of size 6912 next 69\n",
      "2023-09-26 21:18:12.224506: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f6530093f00 of size 4608 next 70\n",
      "2023-09-26 21:18:12.224518: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530095100 of size 149248 next 12\n",
      "2023-09-26 21:18:12.224532: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f65300b9800 of size 884736 next 59\n",
      "2023-09-26 21:18:12.224545: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f6530191800 of size 589824 next 17\n",
      "2023-09-26 21:18:12.224557: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530221800 of size 4096 next 23\n",
      "2023-09-26 21:18:12.224570: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530222800 of size 585728 next 18\n",
      "2023-09-26 21:18:12.224583: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f65302b1800 of size 131072 next 9\n",
      "2023-09-26 21:18:12.224596: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f65302d1800 of size 393216 next 56\n",
      "2023-09-26 21:18:12.224609: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530331800 of size 147456 next 62\n",
      "2023-09-26 21:18:12.224622: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f6530355800 of size 294912 next 66\n",
      "2023-09-26 21:18:12.224634: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f653039d800 of size 1392640 next 20\n",
      "2023-09-26 21:18:12.224647: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f65304f1800 of size 1179648 next 57\n",
      "2023-09-26 21:18:12.224660: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f6530611800 of size 3538944 next 24\n",
      "2023-09-26 21:18:12.224673: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530971800 of size 2359296 next 25\n",
      "2023-09-26 21:18:12.224686: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530bb1800 of size 589824 next 52\n",
      "2023-09-26 21:18:12.224699: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f6530c41800 of size 1507328 next 49\n",
      "2023-09-26 21:18:12.224712: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6530db1800 of size 2621440 next 26\n",
      "2023-09-26 21:18:12.224725: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6531031800 of size 4718592 next 27\n",
      "2023-09-26 21:18:12.224737: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f65314b1800 of size 4718592 next 50\n",
      "2023-09-26 21:18:12.224750: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f6531931800 of size 14155776 next 31\n",
      "2023-09-26 21:18:12.224763: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f65326b1800 of size 9437184 next 32\n",
      "2023-09-26 21:18:12.224775: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6532fb1800 of size 2359296 next 48\n",
      "2023-09-26 21:18:12.224788: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f65331f1800 of size 6029312 next 41\n",
      "2023-09-26 21:18:12.224801: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f65337b1800 of size 10485760 next 33\n",
      "2023-09-26 21:18:12.224813: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f65341b1800 of size 18874368 next 34\n",
      "2023-09-26 21:18:12.224826: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f65353b1800 of size 18874368 next 42\n",
      "2023-09-26 21:18:12.224841: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f65365b1800 of size 9437184 next 38\n",
      "2023-09-26 21:18:12.224854: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f6536eb1800 of size 9437184 next 43\n",
      "2023-09-26 21:18:12.224867: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f65377b1800 of size 37748736 next 37\n",
      "2023-09-26 21:18:12.224880: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f6539bb1800 of size 5239996416 next 80\n",
      "2023-09-26 21:18:12.224893: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f66720f1800 of size 157286400 next 83\n",
      "2023-09-26 21:18:12.224907: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f667b6f1800 of size 1731717120 next 18446744073709551615\n",
      "2023-09-26 21:18:12.224919: I tensorflow/core/common_runtime/bfc_allocator.cc:1088]      Summary of in-use Chunks by size: \n",
      "2023-09-26 21:18:12.224937: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 28 Chunks of size 256 totalling 7.0KiB\n",
      "2023-09-26 21:18:12.224952: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 4 Chunks of size 512 totalling 2.0KiB\n",
      "2023-09-26 21:18:12.224967: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 768 totalling 768B\n",
      "2023-09-26 21:18:12.224981: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 4 Chunks of size 1024 totalling 4.0KiB\n",
      "2023-09-26 21:18:12.224996: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-09-26 21:18:12.225010: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 1536 totalling 1.5KiB\n",
      "2023-09-26 21:18:12.225025: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 3 Chunks of size 2048 totalling 6.0KiB\n",
      "2023-09-26 21:18:12.225039: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 3072 totalling 6.0KiB\n",
      "2023-09-26 21:18:12.225054: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 4096 totalling 4.0KiB\n",
      "2023-09-26 21:18:12.225068: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 4608 totalling 4.5KiB\n",
      "2023-09-26 21:18:12.225084: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 6912 totalling 13.5KiB\n",
      "2023-09-26 21:18:12.225100: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 131072 totalling 128.0KiB\n",
      "2023-09-26 21:18:12.225117: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 147456 totalling 144.0KiB\n",
      "2023-09-26 21:18:12.225132: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 149248 totalling 145.8KiB\n",
      "2023-09-26 21:18:12.225148: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 393216 totalling 384.0KiB\n",
      "2023-09-26 21:18:12.225165: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 426240 totalling 416.2KiB\n",
      "2023-09-26 21:18:12.225180: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 585728 totalling 572.0KiB\n",
      "2023-09-26 21:18:12.225196: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 589824 totalling 576.0KiB\n",
      "2023-09-26 21:18:12.225211: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 884736 totalling 864.0KiB\n",
      "2023-09-26 21:18:12.225227: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 1179648 totalling 1.12MiB\n",
      "2023-09-26 21:18:12.225241: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 1392640 totalling 1.33MiB\n",
      "2023-09-26 21:18:12.225256: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 2359296 totalling 4.50MiB\n",
      "2023-09-26 21:18:12.225271: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 2621440 totalling 2.50MiB\n",
      "2023-09-26 21:18:12.225286: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 4718592 totalling 9.00MiB\n",
      "2023-09-26 21:18:12.225301: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 9437184 totalling 18.00MiB\n",
      "2023-09-26 21:18:12.225316: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 10485760 totalling 10.00MiB\n",
      "2023-09-26 21:18:12.225332: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 18874368 totalling 36.00MiB\n",
      "2023-09-26 21:18:12.225347: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 37748736 totalling 36.00MiB\n",
      "2023-09-26 21:18:12.225362: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 1731717120 totalling 1.61GiB\n",
      "2023-09-26 21:18:12.225377: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 5239996416 totalling 4.88GiB\n",
      "2023-09-26 21:18:12.225392: I tensorflow/core/common_runtime/bfc_allocator.cc:1095] Sum Total of in-use chunks: 6.61GiB\n",
      "2023-09-26 21:18:12.225407: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] total_region_allocated_bytes_: 7292256256 memory_limit_: 7292256256 available bytes: 0 curr_region_allocation_bytes_: 14584512512\n",
      "2023-09-26 21:18:12.225430: I tensorflow/core/common_runtime/bfc_allocator.cc:1103] Stats: \n",
      "Limit:                      7292256256\n",
      "InUse:                      7099279872\n",
      "MaxInUse:                   7256573184\n",
      "NumAllocs:                         176\n",
      "MaxAllocSize:               5239996416\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-09-26 21:18:12.225481: W tensorflow/core/common_runtime/bfc_allocator.cc:491] ***************************************************************************_************************\n",
      "2023-09-26 21:18:12.225573: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:684 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[100,64,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/conv2d_1/Conv2D' defined at (most recent call last):\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 387, in do_execute\n      cell_id=cell_id,\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2976, in run_cell\n      raw_cell, store_history, silent, shell_futures, cell_id\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3258, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_4222/304618131.py\", line 34, in <module>\n      results = current_model.predict(testGene_X, 100, verbose=1)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/engine/training.py\", line 2033, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/engine/training.py\", line 1845, in predict_function\n      return step_function(self, iterator)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/engine/training.py\", line 1834, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/engine/training.py\", line 1823, in run_step\n      outputs = model.predict_step(data)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/engine/training.py\", line 1791, in predict_step\n      return self(x, training=False)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/engine/functional.py\", line 459, in call\n      inputs, training=training, mask=mask)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/layers/convolutional/base_conv.py\", line 250, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/layers/convolutional/base_conv.py\", line 232, in convolution_op\n      name=self.__class__.__name__)\nNode: 'model/conv2d_1/Conv2D'\nOOM when allocating tensor with shape[100,64,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/conv2d_1/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_930]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4222/304618131.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mcurrent_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mtestGene_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestGene_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_test_folder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPARAM_IMG_FOLDER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPARAM_MSK_FOLDER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestGene_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model/conv2d_1/Conv2D' defined at (most recent call last):\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 387, in do_execute\n      cell_id=cell_id,\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2976, in run_cell\n      raw_cell, store_history, silent, shell_futures, cell_id\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3258, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_4222/304618131.py\", line 34, in <module>\n      results = current_model.predict(testGene_X, 100, verbose=1)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/engine/training.py\", line 2033, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/engine/training.py\", line 1845, in predict_function\n      return step_function(self, iterator)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/engine/training.py\", line 1834, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/engine/training.py\", line 1823, in run_step\n      outputs = model.predict_step(data)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/engine/training.py\", line 1791, in predict_step\n      return self(x, training=False)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/engine/functional.py\", line 459, in call\n      inputs, training=training, mask=mask)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/layers/convolutional/base_conv.py\", line 250, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/home/panda/anaconda3/envs/unet/lib/python3.7/site-packages/keras/layers/convolutional/base_conv.py\", line 232, in convolution_op\n      name=self.__class__.__name__)\nNode: 'model/conv2d_1/Conv2D'\nOOM when allocating tensor with shape[100,64,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/conv2d_1/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_930]"
     ]
    }
   ],
   "source": [
    "\n",
    "for img_type in ['polar', 'carte']:\n",
    "    for_counter = 0\n",
    "    if img_type == 'polar':\n",
    "        working_parent_folder = PARAM_PATH_TEMP_POLAR\n",
    "        src_folder = PARAM_PATH_POLAR\n",
    "    else:\n",
    "        working_parent_folder = PARAM_PATH_TEMP_CARTE\n",
    "        src_folder = PARAM_PATH_CARTE\n",
    "        for_counter += 1\n",
    "    for i in range(K):\n",
    "        current_folder_index = i + for_counter * K\n",
    "        temp_test_folder_name = 'temptest'\n",
    "        #print(working_parent_folder)\n",
    "        if os.path.exists(temp_test_folder_name):\n",
    "            shutil.rmtree(temp_test_folder_name)\n",
    "        temp_test_img_folder = os.path.join(temp_test_folder_name,PARAM_IMG_FOLDER)\n",
    "        temp_test_msk_folder = os.path.join(temp_test_folder_name,PARAM_MSK_FOLDER)\n",
    "        os.makedirs(temp_test_img_folder)\n",
    "        os.makedirs(temp_test_msk_folder)\n",
    "        test_n_count = 0\n",
    "        for indice in indices:\n",
    "            if indice[1] == current_folder_index:\n",
    "                test_n_count += 1\n",
    "                img_name = str(indice[0]) + '.' + img_extenstion\n",
    "                src = os.path.join(src_folder,PARAM_IMG_FOLDER,img_name)\n",
    "                shutil.copy2(src, temp_test_img_folder)\n",
    "                src = os.path.join(src_folder,PARAM_MSK_FOLDER,img_name)\n",
    "                shutil.copy2(src, temp_test_msk_folder)\n",
    "        \n",
    "        model_path = os.path.join(working_parent_folder, str(i), 'checkpoint.hdf5')\n",
    "        current_model = unet(PARAM_BETA1[PARAM_BETA_TEST_NUM], PARAM_BETA2[PARAM_BETA_TEST_NUM])\n",
    "        current_model.load_weights(model_path) \n",
    "        testGene_X, testGene_Y = testGenerator(temp_test_folder_name, PARAM_IMG_FOLDER, PARAM_MSK_FOLDER)\n",
    "        results = current_model.predict(testGene_X, 100, verbose=1)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuiling's K-fold function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K fold Validation (obtain training & testing sets)\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits=PARAM_SPLIT_NUM)\n",
    "for train_index,test_index in kfold.split(dfPolar):\n",
    "    polar_train,polar_test=dfPolar.iloc[train_index, :],dfPolar.iloc[test_index, :]\n",
    "    cartesian_train,cartesian_test=dfCartesian.iloc[train_index, :],dfCartesian.iloc[test_index, :]\n",
    "    #print(\"polar train: \", polar_train, \"polar test: \", polar_test)\n",
    "    #print(\"cartesian train\" , cartesian_train, \"cartesian test\", cartesian_test)\n",
    "    batch_size = 3\n",
    "    PARAM_BETA_TEST_NUM = 6\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "    data_gen_args = dict(rotation_range = 80,      # TODO: improve the data augmentation\n",
    "                width_shift_range =0.02,\n",
    "                height_shift_range =0.02,\n",
    "                shear_range = 0.35,\n",
    "                zoom_range = 0.075,\n",
    "                horizontal_flip = True,\n",
    "                fill_mode = 'nearest',\n",
    "                rescale = 1./255)\n",
    "    print('-------------------------------------------------------------')\n",
    "    test_model = unet(PARAM_BETA1[PARAM_BETA_TEST_NUM], PARAM_BETA2[PARAM_BETA_TEST_NUM]) \n",
    "    test_run = test_model.fit(polar_train, polar_test, verbose = 1, steps_per_epoch = 50, epochs = 5, callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training test\n",
    "\n",
    "This part is used to see if we can train a model using the current configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Superparameters (temporary) for a test run of model training test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "PARAM_BETA_TEST_NUM = 6\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "data_gen_args = dict(rotation_range = 80,      # TODO: improve the data augmentation\n",
    "                width_shift_range =0.02,\n",
    "                height_shift_range =0.02,\n",
    "                shear_range = 0.35,\n",
    "                zoom_range = 0.075,\n",
    "                horizontal_flip = True,\n",
    "                fill_mode = 'nearest',\n",
    "                rescale = 1./255)\n",
    "test_gene = trainGenerator(batch_size, PARAM_PATH_CARTE, PARAM_IMG_FOLDER, PARAM_MSK_FOLDER, data_gen_args)\n",
    "test_model = unet(PARAM_BETA1[PARAM_BETA_TEST_NUM], PARAM_BETA2[PARAM_BETA_TEST_NUM]) \n",
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected output\n",
    "<details>\n",
    "    <summary><b><font color=\"green\">Click here to expand</font></b></summary>\n",
    "    <code>\n",
    "Model: \"model_5\"\n",
    "__________________________________________________________________________________________________\n",
    " Layer (type)                   Output Shape         Param #     Connected to                     \n",
    "==================================================================================================\n",
    " input_6 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
    "                                )]                                                                \n",
    "                                                                                                  \n",
    " conv2d_120 (Conv2D)            (None, 256, 256, 64  1792        ['input_6[0][0]']                \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_121 (Conv2D)            (None, 256, 256, 64  36928       ['conv2d_120[0][0]']             \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " max_pooling2d_20 (MaxPooling2D  (None, 128, 128, 64  0          ['conv2d_121[0][0]']             \n",
    " )                              )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_122 (Conv2D)            (None, 128, 128, 12  73856       ['max_pooling2d_20[0][0]']       \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " conv2d_123 (Conv2D)            (None, 128, 128, 12  147584      ['conv2d_122[0][0]']             \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " max_pooling2d_21 (MaxPooling2D  (None, 64, 64, 128)  0          ['conv2d_123[0][0]']             \n",
    " )                                                                                                \n",
    "                                                                                                  \n",
    " conv2d_124 (Conv2D)            (None, 64, 64, 256)  295168      ['max_pooling2d_21[0][0]']       \n",
    "                                                                                                  \n",
    " conv2d_125 (Conv2D)            (None, 64, 64, 256)  590080      ['conv2d_124[0][0]']             \n",
    "                                                                                                  \n",
    " max_pooling2d_22 (MaxPooling2D  (None, 32, 32, 256)  0          ['conv2d_125[0][0]']             \n",
    " )                                                                                                \n",
    "                                                                                                  \n",
    " conv2d_126 (Conv2D)            (None, 32, 32, 512)  1180160     ['max_pooling2d_22[0][0]']       \n",
    "                                                                                                  \n",
    " conv2d_127 (Conv2D)            (None, 32, 32, 512)  2359808     ['conv2d_126[0][0]']             \n",
    "                                                                                                  \n",
    " dropout_10 (Dropout)           (None, 32, 32, 512)  0           ['conv2d_127[0][0]']             \n",
    "                                                                                                  \n",
    " max_pooling2d_23 (MaxPooling2D  (None, 16, 16, 512)  0          ['dropout_10[0][0]']             \n",
    " )                                                                                                \n",
    "                                                                                                  \n",
    " conv2d_128 (Conv2D)            (None, 16, 16, 1024  4719616     ['max_pooling2d_23[0][0]']       \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_129 (Conv2D)            (None, 16, 16, 1024  9438208     ['conv2d_128[0][0]']             \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " dropout_11 (Dropout)           (None, 16, 16, 1024  0           ['conv2d_129[0][0]']             \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " up_sampling2d_20 (UpSampling2D  (None, 32, 32, 1024  0          ['dropout_11[0][0]']             \n",
    " )                              )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_130 (Conv2D)            (None, 32, 32, 512)  2097664     ['up_sampling2d_20[0][0]']       \n",
    "                                                                                                  \n",
    " concatenate_20 (Concatenate)   (None, 32, 32, 1024  0           ['dropout_10[0][0]',             \n",
    "                                )                                 'conv2d_130[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_131 (Conv2D)            (None, 32, 32, 512)  4719104     ['concatenate_20[0][0]']         \n",
    "                                                                                                  \n",
    " conv2d_132 (Conv2D)            (None, 32, 32, 512)  2359808     ['conv2d_131[0][0]']             \n",
    "                                                                                                  \n",
    " up_sampling2d_21 (UpSampling2D  (None, 64, 64, 512)  0          ['conv2d_132[0][0]']             \n",
    " )                                                                                                \n",
    "                                                                                                  \n",
    " conv2d_133 (Conv2D)            (None, 64, 64, 256)  524544      ['up_sampling2d_21[0][0]']       \n",
    "                                                                                                  \n",
    " concatenate_21 (Concatenate)   (None, 64, 64, 512)  0           ['conv2d_125[0][0]',             \n",
    "                                                                  'conv2d_133[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_134 (Conv2D)            (None, 64, 64, 256)  1179904     ['concatenate_21[0][0]']         \n",
    "                                                                                                  \n",
    " conv2d_135 (Conv2D)            (None, 64, 64, 256)  590080      ['conv2d_134[0][0]']             \n",
    "                                                                                                  \n",
    " up_sampling2d_22 (UpSampling2D  (None, 128, 128, 25  0          ['conv2d_135[0][0]']             \n",
    " )                              6)                                                                \n",
    "                                                                                                  \n",
    " conv2d_136 (Conv2D)            (None, 128, 128, 12  131200      ['up_sampling2d_22[0][0]']       \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " concatenate_22 (Concatenate)   (None, 128, 128, 25  0           ['conv2d_123[0][0]',             \n",
    "                                6)                                'conv2d_136[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_137 (Conv2D)            (None, 128, 128, 12  295040      ['concatenate_22[0][0]']         \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " conv2d_138 (Conv2D)            (None, 128, 128, 12  147584      ['conv2d_137[0][0]']             \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " up_sampling2d_23 (UpSampling2D  (None, 256, 256, 12  0          ['conv2d_138[0][0]']             \n",
    " )                              8)                                                                \n",
    "                                                                                                  \n",
    " conv2d_139 (Conv2D)            (None, 256, 256, 64  32832       ['up_sampling2d_23[0][0]']       \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " concatenate_23 (Concatenate)   (None, 256, 256, 12  0           ['conv2d_121[0][0]',             \n",
    "                                8)                                'conv2d_139[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_140 (Conv2D)            (None, 256, 256, 64  73792       ['concatenate_23[0][0]']         \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_141 (Conv2D)            (None, 256, 256, 64  36928       ['conv2d_140[0][0]']             \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_142 (Conv2D)            (None, 256, 256, 9)  5193        ['conv2d_141[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_143 (Conv2D)            (None, 256, 256, 3)  30          ['conv2d_142[0][0]']             \n",
    "                                                                                                  \n",
    "==================================================================================================\n",
    "Total params: 31,036,903\n",
    "Trainable params: 31,036,903\n",
    "Non-trainable params: 0\n",
    "</code>\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint('unet_endoscopic.hdf5', monitor = 'loss', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item1, item2 in test_gene:\n",
    "    print(item1.shape)\n",
    "    print(item2.shape)\n",
    "    print('----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_run = test_model.fit(test_gene, verbose = 1, steps_per_epoch = 100, epochs = 100, callbacks = [model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(test_run.history.keys())\n",
    "plt.plot(test_run.history['loss'])\n",
    "plt.plot(test_run.history['accuracy'])\n",
    "plt.title('Test Run')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss', 'accuracy'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAM_PATH_TEST = './test'\n",
    "image_name = '14.tif'\n",
    "img = io.imread(os.path.join(PARAM_PATH_TEST,image_name),as_gray = False)\n",
    "img = trans.resize(img,[256,256])\n",
    "img = np.reshape(img,(1,)+img.shape)\n",
    "\n",
    "results = test_model.predict(img,1,verbose=1)\n",
    "#saveResult(Path,results)\n",
    "img = results[0,:,:]\n",
    "print(results.shape)\n",
    "io.imsave(os.path.join(PARAM_PATH_TEST,\"result.png\"),img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
