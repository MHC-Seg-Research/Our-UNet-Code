{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Approach for Unet Training \n",
    "\n",
    "------\n",
    "\n",
    "## Overview\n",
    "\n",
    "\n",
    "\n",
    "The purpose of this learn.ipynb notebook is to investigate whether an image can exhibit a preference for being segmented more effectively using a UNet model trained on polar or cartesian-dominant images.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Structure\n",
    "```\n",
    "data\n",
    "└── endoscopic\n",
    "    ├── cartesian\n",
    "    │   ├── image\n",
    "    │   └── label\n",
    "    └── polar\n",
    "        ├── image\n",
    "        └── label\n",
    "```\n",
    "\n",
    "Inside of each end folder there are 956 images, named as `0.tif` to `955.tif`\n",
    "and I believe, for now, the naming of the images are one to one correctly matched, meaning the ``/data/endoscopic/**cartesian**/image/0.tif`` is transformed from `/data/endoscopic/**polar**/image/0.tif`\n",
    "\n",
    "Instead of putting a seperate set of images aside to be test set, we chose to use k-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import from files and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from defines import *\n",
    "from model import *\n",
    "from data import *\n",
    "import sys\n",
    "\n",
    "from numpy import loadtxt\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import math\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this if your computer has a cuda visible device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PARAM_SYSTEM_TIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test code for correct file structure setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize folder tree in current directory\n",
    "os.system(\"tree -d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count of files in data directories\n",
    "os.system(\"ls \" + os.path.join(PARAM_PATH_CARTE,PARAM_IMG_FOLDER) + \" | wc -l\")\n",
    "os.system(\"ls \" + os.path.join(PARAM_PATH_CARTE,PARAM_MSK_FOLDER) + \" | wc -l\")\n",
    "os.system(\"ls \" + os.path.join(PARAM_PATH_POLAR,PARAM_IMG_FOLDER) + \" | wc -l\")\n",
    "os.system(\"ls \" + os.path.join(PARAM_PATH_POLAR,PARAM_MSK_FOLDER) + \" | wc -l\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output: \n",
    "956\n",
    "956\n",
    "956\n",
    "956\n",
    "**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training test\n",
    "\n",
    "This part is used to see if we can train a model using the current configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Superparameters (temporary) for a test run of model training test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 256, 256, 64  1792        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 256, 256, 64  36928       ['conv2d[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 128, 128, 64  0           ['conv2d_1[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 128, 128, 12  73856       ['max_pooling2d[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 128, 128, 12  147584      ['conv2d_2[0][0]']               \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0          ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 64, 64, 256)  295168      ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 64, 64, 256)  590080      ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0          ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 32, 32, 512)  1180160     ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 32, 32, 512)  2359808     ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 32, 32, 512)  0           ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0          ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 16, 16, 1024  4719616     ['max_pooling2d_3[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 16, 16, 1024  9438208     ['conv2d_8[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 16, 16, 1024  0           ['conv2d_9[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 32, 32, 1024  0           ['dropout_1[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 32, 32, 512)  2097664     ['up_sampling2d[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 32, 32, 1024  0           ['dropout[0][0]',                \n",
      "                                )                                 'conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 32, 32, 512)  4719104     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 512)  0          ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 64, 64, 256)  524544      ['up_sampling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 64, 64, 512)  0           ['conv2d_5[0][0]',               \n",
      "                                                                  'conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 64, 64, 256)  1179904     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 25  0          ['conv2d_15[0][0]']              \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 128, 128, 12  131200      ['up_sampling2d_2[0][0]']        \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 128, 128, 25  0           ['conv2d_3[0][0]',               \n",
      "                                6)                                'conv2d_16[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 128, 128, 12  295040      ['concatenate_2[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_17[0][0]']              \n",
      "                                8)                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 12  0          ['conv2d_18[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 256, 256, 64  32832       ['up_sampling2d_3[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 256, 256, 12  0           ['conv2d_1[0][0]',               \n",
      "                                8)                                'conv2d_19[0][0]']              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-12 19:56:01.815230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-12 19:56:01.878504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-12 19:56:01.880684: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-12 19:56:01.883346: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-12 19:56:01.884366: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-12 19:56:01.886291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-12 19:56:01.888223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-12 19:56:02.587695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-12 19:56:02.588740: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-12 19:56:02.589720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-12 19:56:02.590602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3953 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:04:00.0, compute capability: 7.5\n",
      "/home/zyck/anaconda3/envs/unet/lib/python3.7/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 256, 256, 64  73792       ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 256, 256, 64  36928       ['conv2d_20[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 256, 256, 2)  1154        ['conv2d_21[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 256, 256, 1)  3           ['conv2d_22[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,032,837\n",
      "Trainable params: 31,032,837\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "PARAM_BETA_TEST_NUM = 0\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "data_gen_args = dict(rotation_range=50,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    shear_range=0.35,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "temp_save_dir = os.path.join(os.getcwd(),'temp')\n",
    "test_gene = trainGenerator(batch_size, os.path.join(PARAM_PATH_TEMP_POLAR,PARAM_SUB_FOLDER_POLAR), PARAM_IMG_FOLDER, PARAM_MSK_FOLDER, data_gen_args)\n",
    "test_model = unet(PARAM_BETA1[PARAM_BETA_TEST_NUM], PARAM_BETA2[PARAM_BETA_TEST_NUM]) \n",
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected output\n",
    "<details>\n",
    "    <summary><b><font color=\"green\">Click here to expand</font></b></summary>\n",
    "    <code>\n",
    "Model: \"model_5\"\n",
    "__________________________________________________________________________________________________\n",
    " Layer (type)                   Output Shape         Param #     Connected to                     \n",
    "==================================================================================================\n",
    " input_6 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
    "                                )]                                                                \n",
    "                                                                                                  \n",
    " conv2d_120 (Conv2D)            (None, 256, 256, 64  1792        ['input_6[0][0]']                \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_121 (Conv2D)            (None, 256, 256, 64  36928       ['conv2d_120[0][0]']             \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " max_pooling2d_20 (MaxPooling2D  (None, 128, 128, 64  0          ['conv2d_121[0][0]']             \n",
    " )                              )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_122 (Conv2D)            (None, 128, 128, 12  73856       ['max_pooling2d_20[0][0]']       \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " conv2d_123 (Conv2D)            (None, 128, 128, 12  147584      ['conv2d_122[0][0]']             \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " max_pooling2d_21 (MaxPooling2D  (None, 64, 64, 128)  0          ['conv2d_123[0][0]']             \n",
    " )                                                                                                \n",
    "                                                                                                  \n",
    " conv2d_124 (Conv2D)            (None, 64, 64, 256)  295168      ['max_pooling2d_21[0][0]']       \n",
    "                                                                                                  \n",
    " conv2d_125 (Conv2D)            (None, 64, 64, 256)  590080      ['conv2d_124[0][0]']             \n",
    "                                                                                                  \n",
    " max_pooling2d_22 (MaxPooling2D  (None, 32, 32, 256)  0          ['conv2d_125[0][0]']             \n",
    " )                                                                                                \n",
    "                                                                                                  \n",
    " conv2d_126 (Conv2D)            (None, 32, 32, 512)  1180160     ['max_pooling2d_22[0][0]']       \n",
    "                                                                                                  \n",
    " conv2d_127 (Conv2D)            (None, 32, 32, 512)  2359808     ['conv2d_126[0][0]']             \n",
    "                                                                                                  \n",
    " dropout_10 (Dropout)           (None, 32, 32, 512)  0           ['conv2d_127[0][0]']             \n",
    "                                                                                                  \n",
    " max_pooling2d_23 (MaxPooling2D  (None, 16, 16, 512)  0          ['dropout_10[0][0]']             \n",
    " )                                                                                                \n",
    "                                                                                                  \n",
    " conv2d_128 (Conv2D)            (None, 16, 16, 1024  4719616     ['max_pooling2d_23[0][0]']       \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_129 (Conv2D)            (None, 16, 16, 1024  9438208     ['conv2d_128[0][0]']             \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " dropout_11 (Dropout)           (None, 16, 16, 1024  0           ['conv2d_129[0][0]']             \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " up_sampling2d_20 (UpSampling2D  (None, 32, 32, 1024  0          ['dropout_11[0][0]']             \n",
    " )                              )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_130 (Conv2D)            (None, 32, 32, 512)  2097664     ['up_sampling2d_20[0][0]']       \n",
    "                                                                                                  \n",
    " concatenate_20 (Concatenate)   (None, 32, 32, 1024  0           ['dropout_10[0][0]',             \n",
    "                                )                                 'conv2d_130[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_131 (Conv2D)            (None, 32, 32, 512)  4719104     ['concatenate_20[0][0]']         \n",
    "                                                                                                  \n",
    " conv2d_132 (Conv2D)            (None, 32, 32, 512)  2359808     ['conv2d_131[0][0]']             \n",
    "                                                                                                  \n",
    " up_sampling2d_21 (UpSampling2D  (None, 64, 64, 512)  0          ['conv2d_132[0][0]']             \n",
    " )                                                                                                \n",
    "                                                                                                  \n",
    " conv2d_133 (Conv2D)            (None, 64, 64, 256)  524544      ['up_sampling2d_21[0][0]']       \n",
    "                                                                                                  \n",
    " concatenate_21 (Concatenate)   (None, 64, 64, 512)  0           ['conv2d_125[0][0]',             \n",
    "                                                                  'conv2d_133[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_134 (Conv2D)            (None, 64, 64, 256)  1179904     ['concatenate_21[0][0]']         \n",
    "                                                                                                  \n",
    " conv2d_135 (Conv2D)            (None, 64, 64, 256)  590080      ['conv2d_134[0][0]']             \n",
    "                                                                                                  \n",
    " up_sampling2d_22 (UpSampling2D  (None, 128, 128, 25  0          ['conv2d_135[0][0]']             \n",
    " )                              6)                                                                \n",
    "                                                                                                  \n",
    " conv2d_136 (Conv2D)            (None, 128, 128, 12  131200      ['up_sampling2d_22[0][0]']       \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " concatenate_22 (Concatenate)   (None, 128, 128, 25  0           ['conv2d_123[0][0]',             \n",
    "                                6)                                'conv2d_136[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_137 (Conv2D)            (None, 128, 128, 12  295040      ['concatenate_22[0][0]']         \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " conv2d_138 (Conv2D)            (None, 128, 128, 12  147584      ['conv2d_137[0][0]']             \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " up_sampling2d_23 (UpSampling2D  (None, 256, 256, 12  0          ['conv2d_138[0][0]']             \n",
    " )                              8)                                                                \n",
    "                                                                                                  \n",
    " conv2d_139 (Conv2D)            (None, 256, 256, 64  32832       ['up_sampling2d_23[0][0]']       \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " concatenate_23 (Concatenate)   (None, 256, 256, 12  0           ['conv2d_121[0][0]',             \n",
    "                                8)                                'conv2d_139[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_140 (Conv2D)            (None, 256, 256, 64  73792       ['concatenate_23[0][0]']         \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_141 (Conv2D)            (None, 256, 256, 64  36928       ['conv2d_140[0][0]']             \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_142 (Conv2D)            (None, 256, 256, 9)  5193        ['conv2d_141[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_143 (Conv2D)            (None, 256, 256, 3)  30          ['conv2d_142[0][0]']             \n",
    "                                                                                                  \n",
    "==================================================================================================\n",
    "Total params: 31,036,903\n",
    "Trainable params: 31,036,903\n",
    "Non-trainable params: 0\n",
    "</code>\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint('unet_endoscopic.hdf5', monitor = 'loss', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 478 images belonging to 1 classes.\n",
      "Found 478 images belonging to 1 classes.\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa5ccf37ef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa5ccf37ef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function dice_coef_loss at 0x7fa6a46c1d40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function dice_coef_loss at 0x7fa6a46c1d40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-12 19:56:13.424168: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n",
      "2023-09-12 19:56:14.275536: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - ETA: 0s - loss: 0.7879 - accuracy: 0.5857 - dice_coef_loss: 0.7879\n",
      "Epoch 1: loss improved from inf to 0.78786, saving model to unet_endoscopic.hdf5\n",
      "500/500 [==============================] - 71s 130ms/step - loss: 0.7879 - accuracy: 0.5857 - dice_coef_loss: 0.7879\n",
      "Epoch 2/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7040 - accuracy: 0.8565 - dice_coef_loss: 0.7040\n",
      "Epoch 2: loss improved from 0.78786 to 0.70396, saving model to unet_endoscopic.hdf5\n",
      "500/500 [==============================] - 65s 131ms/step - loss: 0.7040 - accuracy: 0.8565 - dice_coef_loss: 0.7040\n",
      "Epoch 3/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6754 - accuracy: 0.8733 - dice_coef_loss: 0.6754\n",
      "Epoch 3: loss improved from 0.70396 to 0.67540, saving model to unet_endoscopic.hdf5\n",
      "500/500 [==============================] - 65s 131ms/step - loss: 0.6754 - accuracy: 0.8733 - dice_coef_loss: 0.6754\n",
      "Epoch 4/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6446 - accuracy: 0.8836 - dice_coef_loss: 0.6446\n",
      "Epoch 4: loss improved from 0.67540 to 0.64465, saving model to unet_endoscopic.hdf5\n",
      "500/500 [==============================] - 65s 131ms/step - loss: 0.6446 - accuracy: 0.8836 - dice_coef_loss: 0.6446\n",
      "Epoch 5/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6373 - accuracy: 0.8780 - dice_coef_loss: 0.6373\n",
      "Epoch 5: loss improved from 0.64465 to 0.63730, saving model to unet_endoscopic.hdf5\n",
      "500/500 [==============================] - 65s 131ms/step - loss: 0.6373 - accuracy: 0.8780 - dice_coef_loss: 0.6373\n",
      "Epoch 6/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6206 - accuracy: 0.8857 - dice_coef_loss: 0.6206\n",
      "Epoch 6: loss improved from 0.63730 to 0.62062, saving model to unet_endoscopic.hdf5\n",
      "500/500 [==============================] - 68s 135ms/step - loss: 0.6206 - accuracy: 0.8857 - dice_coef_loss: 0.6206\n",
      "Epoch 7/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6022 - accuracy: 0.8914 - dice_coef_loss: 0.6022\n",
      "Epoch 7: loss improved from 0.62062 to 0.60218, saving model to unet_endoscopic.hdf5\n",
      "500/500 [==============================] - 65s 131ms/step - loss: 0.6022 - accuracy: 0.8914 - dice_coef_loss: 0.6022\n",
      "Epoch 8/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5965 - accuracy: 0.8918 - dice_coef_loss: 0.5965\n",
      "Epoch 8: loss improved from 0.60218 to 0.59645, saving model to unet_endoscopic.hdf5\n",
      "500/500 [==============================] - 65s 131ms/step - loss: 0.5965 - accuracy: 0.8918 - dice_coef_loss: 0.5965\n",
      "Epoch 9/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5920 - accuracy: 0.9011 - dice_coef_loss: 0.5920\n",
      "Epoch 9: loss improved from 0.59645 to 0.59204, saving model to unet_endoscopic.hdf5\n",
      "500/500 [==============================] - 66s 131ms/step - loss: 0.5920 - accuracy: 0.9011 - dice_coef_loss: 0.5920\n",
      "Epoch 10/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5757 - accuracy: 0.9052 - dice_coef_loss: 0.5757\n",
      "Epoch 10: loss improved from 0.59204 to 0.57567, saving model to unet_endoscopic.hdf5\n",
      "500/500 [==============================] - 66s 131ms/step - loss: 0.5757 - accuracy: 0.9052 - dice_coef_loss: 0.5757\n",
      "Epoch 11/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5713 - accuracy: 0.9029 - dice_coef_loss: 0.5713\n",
      "Epoch 11: loss improved from 0.57567 to 0.57131, saving model to unet_endoscopic.hdf5\n",
      "500/500 [==============================] - 65s 131ms/step - loss: 0.5713 - accuracy: 0.9029 - dice_coef_loss: 0.5713\n",
      "Epoch 12/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5762 - accuracy: 0.9076 - dice_coef_loss: 0.5762\n",
      "Epoch 12: loss did not improve from 0.57131\n",
      "500/500 [==============================] - 65s 129ms/step - loss: 0.5762 - accuracy: 0.9076 - dice_coef_loss: 0.5762\n",
      "Epoch 13/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5606 - accuracy: 0.9084 - dice_coef_loss: 0.5606\n",
      "Epoch 13: loss improved from 0.57131 to 0.56055, saving model to unet_endoscopic.hdf5\n",
      "500/500 [==============================] - 65s 131ms/step - loss: 0.5606 - accuracy: 0.9084 - dice_coef_loss: 0.5606\n",
      "Epoch 14/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5572 - accuracy: 0.9075 - dice_coef_loss: 0.5572\n",
      "Epoch 14: loss improved from 0.56055 to 0.55720, saving model to unet_endoscopic.hdf5\n",
      "500/500 [==============================] - 65s 131ms/step - loss: 0.5572 - accuracy: 0.9075 - dice_coef_loss: 0.5572\n",
      "Epoch 15/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.5922 - accuracy: 0.9092 - dice_coef_loss: 0.5922\n",
      "Epoch 15: loss did not improve from 0.55720\n",
      "500/500 [==============================] - 65s 130ms/step - loss: 0.5922 - accuracy: 0.9092 - dice_coef_loss: 0.5922\n",
      "Epoch 16/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.6307 - accuracy: 0.9012 - dice_coef_loss: 0.6307\n",
      "Epoch 16: loss did not improve from 0.55720\n",
      "500/500 [==============================] - 65s 129ms/step - loss: 0.6307 - accuracy: 0.9012 - dice_coef_loss: 0.6307\n",
      "Epoch 17/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7888 - accuracy: 0.8882 - dice_coef_loss: 0.7888\n",
      "Epoch 17: loss did not improve from 0.55720\n",
      "500/500 [==============================] - 65s 129ms/step - loss: 0.7888 - accuracy: 0.8882 - dice_coef_loss: 0.7888\n",
      "Epoch 18/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.9124 - accuracy: 0.9020 - dice_coef_loss: 0.9124\n",
      "Epoch 18: loss did not improve from 0.55720\n",
      "500/500 [==============================] - 65s 129ms/step - loss: 0.9124 - accuracy: 0.9020 - dice_coef_loss: 0.9124\n",
      "Epoch 19/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.9588 - accuracy: 0.9074 - dice_coef_loss: 0.9588\n",
      "Epoch 19: loss did not improve from 0.55720\n",
      "500/500 [==============================] - 65s 129ms/step - loss: 0.9588 - accuracy: 0.9074 - dice_coef_loss: 0.9588\n",
      "Epoch 20/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.9498 - accuracy: 0.9009 - dice_coef_loss: 0.9498\n",
      "Epoch 20: loss did not improve from 0.55720\n",
      "500/500 [==============================] - 65s 129ms/step - loss: 0.9498 - accuracy: 0.9009 - dice_coef_loss: 0.9498\n"
     ]
    }
   ],
   "source": [
    "test_run = test_model.fit(test_gene, verbose = 1, steps_per_epoch = 500, epochs = 20, callbacks = [model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(test_run.history.keys())\n",
    "plt.plot(test_run.history['loss'])\n",
    "plt.plot(test_run.history['accuracy'])\n",
    "plt.title('Test Run')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss', 'accuracy'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAM_PATH_TEST = './test'\n",
    "image_name = '29.tif'\n",
    "img = io.imread(os.path.join(PARAM_PATH_TEST,image_name),as_gray = False)\n",
    "img = trans.resize(img,[256,256])\n",
    "img = np.reshape(img,(1,)+img.shape)\n",
    "\n",
    "results = test_model.predict(img,1,verbose=1)\n",
    "#saveResult(Path,results)\n",
    "img = results[0,:,:]\n",
    "print(results.shape)\n",
    "io.imsave(os.path.join(PARAM_PATH_TEST,\"result.png\"),img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Relocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following block, the code loads in one analysis file from previous research. \n",
    "\n",
    "### #File name postfix\n",
    "_C_ is the dice scores of the predictions generated by Unet C: this Unet C is trained using all 7404 images, in their cartesian form. The raw image was directly input into the Unet and the prediction was generated.\n",
    "\n",
    "_P_ is the dice scores of the predictions generated by Unet P: this Unet P is trained using all 7404 images but in their polar form. The raw images were transformed, and then input for prediction. The prediction is in polar space.\n",
    "\n",
    "_P2C_ is the dice scores of the predictions generated by the same Unet P as mentioned above, but the dice score is generated by transforming the prediction back to cartesian, and compared to their original label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#file_name = 'analysis_dice_back_Test_C.npy'\n",
    "file_name = 'analysis_dice_back_Test_P.npy'\n",
    "#file_name = 'analysis_dice_back_Test_P2C.npy'\n",
    "np_file = os.path.join(PARAM_PATH_SCORES, file_name)\n",
    "#load npy file\n",
    "img_score = np.load(np_file)\n",
    "#sort scores in descending order and store index\n",
    "sorted_score = np.flip(np.argsort(img_score))\n",
    "#print(sorted_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_score = pd.DataFrame(sorted_score)\n",
    "\n",
    "#fetch top polar dominant and non-polar dominant image\n",
    "num_polar = round(len(sorted_score)/2)\n",
    "num_cartesian = len(sorted_score) - num_polar\n",
    "dfPolar = sorted_score.head(num_polar)\n",
    "dfCartesian = sorted_score.tail(num_cartesian)\n",
    "print(\"Polar: \\n\", dfPolar)\n",
    "print(\"Cartesian: \\n\", dfCartesian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new directories for polar dominant images and cartesian dominant images based on sorted dice scores\n",
    "\n",
    "if os.path.exists(PARAM_PATH_TEMP_POLAR):#\n",
    "    shutil.rmtree(PARAM_PATH_TEMP_POLAR)\n",
    "os.makedirs(PARAM_PATH_TEMP_POLAR)\n",
    "this_folder = os.path.join(PARAM_PATH_TEMP_POLAR,PARAM_SUB_FOLDER_POLAR)#Creation of subfolder\n",
    "os.makedirs(os.path.join(this_folder,PARAM_IMG_FOLDER))\n",
    "os.makedirs(os.path.join(this_folder,PARAM_MSK_FOLDER))\n",
    "this_folder = os.path.join(PARAM_PATH_TEMP_POLAR,PARAM_SUB_FOLDER_CARTE)\n",
    "os.makedirs(os.path.join(this_folder,PARAM_IMG_FOLDER))\n",
    "os.makedirs(os.path.join(this_folder,PARAM_MSK_FOLDER))\n",
    "\n",
    "if os.path.exists(PARAM_PATH_TEMP_CARTE):\n",
    "    shutil.rmtree(PARAM_PATH_TEMP_CARTE)\n",
    "os.makedirs(PARAM_PATH_TEMP_CARTE)\n",
    "this_folder = os.path.join(PARAM_PATH_TEMP_CARTE,PARAM_SUB_FOLDER_POLAR)#Creation of subfolder\n",
    "os.makedirs(os.path.join(this_folder,PARAM_IMG_FOLDER))\n",
    "os.makedirs(os.path.join(this_folder,PARAM_MSK_FOLDER))\n",
    "this_folder = os.path.join(PARAM_PATH_TEMP_CARTE,PARAM_SUB_FOLDER_CARTE)\n",
    "os.makedirs(os.path.join(this_folder,PARAM_IMG_FOLDER))\n",
    "os.makedirs(os.path.join(this_folder,PARAM_MSK_FOLDER))\n",
    "\n",
    "for img in dfPolar[0]:\n",
    "    img_name = str(img) + \".tif\"\n",
    "    #Copy polar img and mask in\n",
    "    this_folder = os.path.join(PARAM_PATH_TEMP_POLAR,PARAM_SUB_FOLDER_POLAR)\n",
    "    src = os.path.join(PARAM_PATH_POLAR, PARAM_IMG_FOLDER, img_name)\n",
    "    shutil.copy2(src, os.path.join(this_folder,PARAM_IMG_FOLDER))\n",
    "    src = os.path.join(PARAM_PATH_POLAR, PARAM_MSK_FOLDER, img_name)\n",
    "    shutil.copy2(src, os.path.join(this_folder,PARAM_MSK_FOLDER))\n",
    "    #Copy cartesian img and mask in\n",
    "    this_folder = os.path.join(PARAM_PATH_TEMP_POLAR,PARAM_SUB_FOLDER_CARTE)\n",
    "    src = os.path.join(PARAM_PATH_CARTE, PARAM_IMG_FOLDER, img_name)\n",
    "    shutil.copy2(src, os.path.join(this_folder,PARAM_IMG_FOLDER))\n",
    "    src = os.path.join(PARAM_PATH_CARTE, PARAM_MSK_FOLDER, img_name)\n",
    "    shutil.copy2(src, os.path.join(this_folder,PARAM_MSK_FOLDER))\n",
    "    \n",
    "for img in dfCartesian[0]:\n",
    "    img_name = str(img) + \".tif\"\n",
    "    #Copy polar img and mask in\n",
    "    this_folder = os.path.join(PARAM_PATH_TEMP_CARTE,PARAM_SUB_FOLDER_POLAR)\n",
    "    src = os.path.join(PARAM_PATH_POLAR, PARAM_IMG_FOLDER, img_name)\n",
    "    shutil.copy2(src, os.path.join(this_folder,PARAM_IMG_FOLDER))\n",
    "    src = os.path.join(PARAM_PATH_POLAR, PARAM_MSK_FOLDER, img_name)\n",
    "    shutil.copy2(src, os.path.join(this_folder,PARAM_MSK_FOLDER))\n",
    "    #Copy cartesian img and mask in    \n",
    "    this_folder = os.path.join(PARAM_PATH_TEMP_CARTE,PARAM_SUB_FOLDER_CARTE)\n",
    "    src = os.path.join(PARAM_PATH_CARTE, PARAM_IMG_FOLDER, img_name)\n",
    "    shutil.copy2(src, os.path.join(this_folder,PARAM_IMG_FOLDER))\n",
    "    src = os.path.join(PARAM_PATH_CARTE, PARAM_MSK_FOLDER, img_name)\n",
    "    shutil.copy2(src, os.path.join(this_folder,PARAM_MSK_FOLDER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K fold Validation (obtain training & testing sets)\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits=PARAM_SPLIT_NUM)\n",
    "for train_index,test_index in kfold.split(dfPolar):\n",
    "    polar_train,polar_test=dfPolar.iloc[train_index, :],dfPolar.iloc[test_index, :]\n",
    "    cartesian_train,cartesian_test=dfCartesian.iloc[train_index, :],dfCartesian.iloc[test_index, :]\n",
    "    print(\"polar train: \", polar_train, \"polar test: \", polar_test)\n",
    "    print(\"cartesian train\" , cartesian_train, \"cartesian test\", cartesian_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy Code Below\n",
    "### written by Wenfan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from defines import *\n",
    "from model import *\n",
    "from data import *\n",
    "import sys\n",
    "\n",
    "from numpy import loadtxt\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "\n",
    "import glob\n",
    "import os \n",
    "import math\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data_jupyter'# main folder path\n",
    "\n",
    "D = 'all_images'\n",
    "L = 'all_labels'\n",
    "\n",
    "D_P_im = 'polar_im'\n",
    "D_C_im = 'car_im'\n",
    "D_P = 'polar_l'\n",
    "D_C = 'car_l'\n",
    "\n",
    "prev_number_of_D_P = -1\n",
    "prev_number_of_D_C = -1\n",
    "\n",
    "diff = math.inf\n",
    "\n",
    "model_P = unet(PARAM_BETA1[PARAM_BETA_TEST_NUM], PARAM_BETA2[PARAM_BETA_TEST_NUM])\n",
    "model_C = unet(PARAM_BETA1[PARAM_BETA_TEST_NUM], PARAM_BETA2[PARAM_BETA_TEST_NUM])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill in the weights here\n",
    "model_P.load_weights() \n",
    "model_C.load_weights() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "#change file name of D, L\n",
    "for count, filename in enumerate(os.listdir(path+'/'+D)): \n",
    "    dst = str(count) + \".png\"\n",
    "    src = path+'/'+D+'/'+filename\n",
    "    dst = path+'/'+D+'/'+dst\n",
    "\n",
    "    os.rename(src, dst) \n",
    "    \n",
    "for count, filename in enumerate(os.listdir(path+'/'+L)): \n",
    "    dst = str(count) + \".tif\"\n",
    "    src = path+'/'+L+'/'+filename\n",
    "    dst = path+'/'+L+'/'+dst\n",
    "\n",
    "    os.rename(src, dst) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dscore(im, im_name):\n",
    "    label = Image.open(os.path.join(L, im_name))\n",
    "    \n",
    "    pixelIm = im.load()\n",
    "    pixelLabel = label.load()\n",
    "    \n",
    "    upper = 0\n",
    "    lower = im.size[0] * im.size[1]\n",
    "    \n",
    "    for i in range(im.size[0]):\n",
    "        for j in range(im.size[1]):\n",
    "            if pixelIm[i,j] == pixelLabel[i,j]:\n",
    "                upper = upper + 1\n",
    "            \n",
    "    upper = upper * 2\n",
    "    \n",
    "    return upper / lower\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while (diff > 0): \n",
    "    #load model\n",
    "    #if count > 0:\n",
    "    #    model_P.load_weights('model_P_weights_' + (count - 1))\n",
    "    #    model_C.load_weights('model_C_weights_' + (count - 1))\n",
    "    \n",
    "    count = count + 1\n",
    "    \n",
    "    testGene_P, testGene_C = testGenerator(path,D,L)\n",
    "    \n",
    "    #perdict\n",
    "    results_P = model_P.predict(testGene_P, PARAM_N_TESTS, verbose=1)\n",
    "    results_C = model_C.predict(testGene_C, PARAM_N_TESTS, verbose=1)\n",
    "\n",
    "    np.save(PARAM_PATH_TEST_NPY_P, results_P)\n",
    "    saveResult(PARAM_PATH_TEST_RESULTS_P, results_P)\n",
    "    np.save(PARAM_PATH_TEST_NPY_C, results_C)\n",
    "    saveResult(PARAM_PATH_TEST_RESULTS_C, results_C)\n",
    "    \n",
    "    mergeIm(path, D, L, PARAM_PATH_TEST_RESULTS_P, path+'/'+D_P)\n",
    "    mergeIm(path, D, L, PARAM_PATH_TEST_RESULTS_C, path+'/'+D_C)\n",
    "    \n",
    "    #change file name of D_P, D_C\n",
    "    for count, filename in enumerate(os.listdir(path+'/'+D_P)): \n",
    "        dst = str(count) + \".tif\"\n",
    "        src = path+'/'+D_P+'/'+filenaLme\n",
    "        dst = path+'/'+D_P+'/'+dst\n",
    "\n",
    "        os.rename(src, dst) \n",
    "  \n",
    "    for count, filename in enumerate(os.listdir(path+'/'+D_C)): \n",
    "        dst = str(count) + \".tif\"\n",
    "        src = path+'/'+D_C+'/'+filename\n",
    "        dst = path+'/'+D_C+'/'+dst\n",
    "\n",
    "        os.rename(src, dst) \n",
    "    \n",
    "    #find the better one (based on L) and modify D_P, D_P_im, D_C, D_C_im\n",
    "    for file in os.listdir(D):\n",
    "        im_P = Image.open(path+'/'+D_P+'/'+file)\n",
    "        im_C = Image.open(path+'/'+D_C+'/'+file)\n",
    "        \n",
    "        if dscore(im_P, file) > dscore(im_C, file):\n",
    "            shutil.copyfile(path+'/'+D+'/'+file, path+'/'+D_P_im+'/'+file)\n",
    "            os.remove(path+'/'+D_C+'/'+file)\n",
    "        else:\n",
    "            shutil.copyfile(path+'/'+D+'/'+file, path+'/'+D_C_im+'/'+file)\n",
    "            os.remove(path+'/'+D_P+'/'+file)\n",
    "            \n",
    "    number_of_D_P = len(glob.glob(D_P))\n",
    "    number_of_D_C = len(glob.glob(D_C))\n",
    "\n",
    "    # file numbers difference\n",
    "    diff = Math.abs(prev_number_of_D_P - number_of_D_P + prev_number_of_D_C - number_of_D_C) / 2\n",
    "    \n",
    "    prev_number_of_D_P = number_of_D_P\n",
    "    prev_number_of_D_C = number_of_D_P\n",
    "    \n",
    "    #train model_P only on D_P, model_C only on D_C\n",
    "    myGene_P = trainGenerator(PARAM_BATCHES, \n",
    "                            path, \n",
    "                            D_P, \n",
    "                            D_P_im, \n",
    "                            PARAM_DATA_ARGS, \n",
    "                            save_to_dir = PARAM_AUG_FOLDER_P)\n",
    "    \n",
    "    myGene_C = trainGenerator(PARAM_BATCHES, \n",
    "                            path, \n",
    "                            D_C, \n",
    "                            D_C_im, \n",
    "                            PARAM_DATA_ARGS, \n",
    "                            save_to_dir = PARAM_AUG_FOLDER_C)\n",
    "    \n",
    "    model_checkpoint_P = ModelCheckpoint( PARAM_SAVED_MODEL, \n",
    "                                         monitor = PARAM_METRICS, \n",
    "                                         verbose = 1, \n",
    "                                         save_best_only = PARAM_SAVE_BEST_ONLY)\n",
    "    \n",
    "    model_P.fit_generator(myGene_P,\n",
    "                        steps_per_epoch = PARAM_EPOCH_STEPS,\n",
    "                        epochs = PARAM_N_EPOCHS,\n",
    "                        callbacks = [model_checkpoint])\n",
    "    model_C.fit_generator(myGene_C,\n",
    "                        steps_per_epoch = PARAM_EPOCH_STEPS,\n",
    "                        epochs = PARAM_N_EPOCHS,\n",
    "                        callbacks = [model_checkpoint])\n",
    "    \n",
    "    model_P.save_weights('model_P_weights_' + count)\n",
    "    model_C.save_weights('model_C_weights_' + count)\n",
    "    \n",
    "    shutil.rmtree(path+'/'+D_P)\n",
    "    shutil.rmtree(path+'/'+D_C)\n",
    "    shutil.rmtree(path+'/'+D_P_im)\n",
    "    shutil.rmtree(path+'/'+D_C_im)\n",
    "    \n",
    "\n",
    "save_model(model_P, 'model_P.h5')\n",
    "save_model(model_C, 'model_C.h5')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
