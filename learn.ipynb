{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Approach for Unet Training \n",
    "\n",
    "------\n",
    "\n",
    "## Overview\n",
    "\n",
    "\n",
    "\n",
    "The purpose of this learn.ipynb notebook is to investigate whether an image can exhibit a preference for being segmented more effectively using a UNet model trained on polar or cartesian-dominant images.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Structure\n",
    "```\n",
    "data\n",
    "└── endoscopic\n",
    "    ├── cartesian\n",
    "    │   ├── image\n",
    "    │   └── label\n",
    "    └── polar\n",
    "        ├── image\n",
    "        └── label\n",
    "```\n",
    "\n",
    "Inside of each end folder there are 956 images, named as `0.tif` to `955.tif`\n",
    "and I believe, for now, the naming of the images are one to one correctly matched, meaning the ``/data/endoscopic/**cartesian**/image/0.tif`` is transformed from `/data/endoscopic/**polar**/image/0.tif`\n",
    "\n",
    "Instead of putting a seperate set of images aside to be test set, we chose to use k-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from defines import *\n",
    "from model import *\n",
    "from data import *\n",
    "import sys\n",
    "\n",
    "from numpy import loadtxt\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from skimage.io import imread\n",
    "from skimage import img_as_ubyte\n",
    "from skimage.transform import resize\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import math\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import from files and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this if your computer has a cuda visible device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PARAM_SYSTEM_TIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test code for correct file structure setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize folder tree in current directory\n",
    "os.system(\"tree -d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count of files in data directories\n",
    "os.system(\"ls \" + os.path.join(PARAM_PATH_CARTE,PARAM_IMG_FOLDER) + \" | wc -l\")\n",
    "os.system(\"ls \" + os.path.join(PARAM_PATH_CARTE,PARAM_MSK_FOLDER) + \" | wc -l\")\n",
    "os.system(\"ls \" + os.path.join(PARAM_PATH_POLAR,PARAM_IMG_FOLDER) + \" | wc -l\")\n",
    "os.system(\"ls \" + os.path.join(PARAM_PATH_POLAR,PARAM_MSK_FOLDER) + \" | wc -l\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Expected Output:\n",
    "7404\\\n",
    "7404\\\n",
    "7404\\\n",
    "7404\\\n",
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Relocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following block, the code loads in one analysis file from previous research. \n",
    "\n",
    "### #File name postfix\n",
    "_C_ is the dice scores of the predictions generated by Unet C: this Unet C is trained using all 7404 images, in their cartesian form. The raw image was directly input into the Unet and the prediction was generated.\n",
    "\n",
    "_P_ is the dice scores of the predictions generated by Unet P: this Unet P is trained using all 7404 images but in their polar form. The raw images were transformed, and then input for prediction. The prediction is in polar space.\n",
    "\n",
    "_P2C_ is the dice scores of the predictions generated by the same Unet P as mentioned above, but the dice score is generated by transforming the prediction back to cartesian, and compared to their original label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name = 'analysis_dice_back_Test_C.npy'\n",
    "#file_name = 'analysis_dice_back_Test_P.npy'\n",
    "#file_name = 'analysis_dice_back_Test_P2C.npy'\n",
    "file_name = 'analysis_dice_back_Train_C.npy'\n",
    "\n",
    "np_file = os.path.join(PARAM_PATH_SCORES, file_name)\n",
    "#load npy file\n",
    "img_score = np.load(np_file)\n",
    "\n",
    "#sort scores in descending order and store index\n",
    "sorted_score = np.flip(np.argsort(img_score))\n",
    "\n",
    "#------DEBUG--------\n",
    "#print(len(sorted_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sorted_score` should be a list of length 7404, sorted by the method we chose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_score = pd.DataFrame(sorted_score)\n",
    "\n",
    "#fetch top polar dominant and non-polar dominant image\n",
    "num_polar = round(len(sorted_score)/2)\n",
    "num_cartesian = len(sorted_score) - num_polar\n",
    "dfPolar = sorted_score.head(num_polar)\n",
    "dfCartesian = sorted_score.tail(num_cartesian)\n",
    "#print(\"Polar: \\n\", dfPolar)\n",
    "#print(\"Cartesian: \\n\", dfCartesian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in `dfPolar` should be the best half of images (filename), which performs better than the other half, according to the data we used above. In `dfCartesian` there's the other half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filePrep import *\n",
    "\n",
    "K = 5\n",
    "\n",
    "checkNcreateTempFolder(PARAM_PATH_TEMP_POLAR, K)\n",
    "checkNcreateTempFolder(PARAM_PATH_TEMP_CARTE, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two lines creates the new temporary folder.\n",
    "Instead of making kfolds later, the kfolds is assigned now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = K, shuffle = True, random_state = 42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the KFold package to assign the paramters like n_splits and so.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for train_index,test_index in kf.split(dfPolar):\n",
    "    fillFolder(test_index, dfPolar, PARAM_PATH_POLAR, PARAM_PATH_CARTE, PARAM_PATH_TEMP_POLAR, i)\n",
    "    i += 1\n",
    "i = 0\n",
    "print('------------------------------------')\n",
    "for train_index,test_index in kf.split(dfCartesian):\n",
    "    fillFolder(test_index, dfCartesian, PARAM_PATH_POLAR, PARAM_PATH_CARTE, PARAM_PATH_TEMP_CARTE, i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we should have all `k-folds` set up. The next step is to write a training loop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the limitation of flow_from_directory, which, it does not allow the combination of multiple directories. And, the limitation of my knowledge of flow_from_dataframe. **I believe this is solvable using flow_from_dataframe** I decide to move training set into a separate temporary folder when training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2961 images belonging to 1 classes.\n",
      "Found 2961 images belonging to 1 classes.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f841c5e80e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f841c5e80e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6402 - accuracy: 0.4389 - dice_coef_loss: 0.6402\n",
      "Epoch 1: loss improved from inf to 0.64016, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 264ms/step - loss: 0.6402 - accuracy: 0.4389 - dice_coef_loss: 0.6402\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6135 - accuracy: 0.6664 - dice_coef_loss: 0.6135\n",
      "Epoch 2: loss improved from 0.64016 to 0.61351, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 0.6135 - accuracy: 0.6664 - dice_coef_loss: 0.6135\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5999 - accuracy: 0.7434 - dice_coef_loss: 0.5999\n",
      "Epoch 3: loss improved from 0.61351 to 0.59986, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 0.5999 - accuracy: 0.7434 - dice_coef_loss: 0.5999\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5876 - accuracy: 0.7619 - dice_coef_loss: 0.5876\n",
      "Epoch 4: loss improved from 0.59986 to 0.58756, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 0.5876 - accuracy: 0.7619 - dice_coef_loss: 0.5876\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5882 - accuracy: 0.7885 - dice_coef_loss: 0.5882\n",
      "Epoch 5: loss did not improve from 0.58756\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.5882 - accuracy: 0.7885 - dice_coef_loss: 0.5882\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5856 - accuracy: 0.7912 - dice_coef_loss: 0.5856\n",
      "Epoch 6: loss improved from 0.58756 to 0.58557, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 0.5856 - accuracy: 0.7912 - dice_coef_loss: 0.5856\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5909 - accuracy: 0.7993 - dice_coef_loss: 0.5909\n",
      "Epoch 7: loss did not improve from 0.58557\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.5909 - accuracy: 0.7993 - dice_coef_loss: 0.5909\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5744 - accuracy: 0.8089 - dice_coef_loss: 0.5748\n",
      "Epoch 8: loss improved from 0.58557 to 0.57439, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 28s 282ms/step - loss: 0.5744 - accuracy: 0.8089 - dice_coef_loss: 0.5748\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5736 - accuracy: 0.8034 - dice_coef_loss: 0.5736\n",
      "Epoch 9: loss improved from 0.57439 to 0.57357, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 0.5736 - accuracy: 0.8034 - dice_coef_loss: 0.5736\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5859 - accuracy: 0.8083 - dice_coef_loss: 0.5859\n",
      "Epoch 10: loss did not improve from 0.57357\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.5859 - accuracy: 0.8083 - dice_coef_loss: 0.5859\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5837 - accuracy: 0.8145 - dice_coef_loss: 0.5837\n",
      "Epoch 11: loss did not improve from 0.57357\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.5837 - accuracy: 0.8145 - dice_coef_loss: 0.5837\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5644 - accuracy: 0.8203 - dice_coef_loss: 0.5644\n",
      "Epoch 12: loss improved from 0.57357 to 0.56442, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 0.5644 - accuracy: 0.8203 - dice_coef_loss: 0.5644\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5705 - accuracy: 0.8205 - dice_coef_loss: 0.5705\n",
      "Epoch 13: loss did not improve from 0.56442\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5705 - accuracy: 0.8205 - dice_coef_loss: 0.5705\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5687 - accuracy: 0.8324 - dice_coef_loss: 0.5687\n",
      "Epoch 14: loss did not improve from 0.56442\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5687 - accuracy: 0.8324 - dice_coef_loss: 0.5687\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5771 - accuracy: 0.8143 - dice_coef_loss: 0.5768\n",
      "Epoch 15: loss did not improve from 0.56442\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.5771 - accuracy: 0.8143 - dice_coef_loss: 0.5768\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5704 - accuracy: 0.8312 - dice_coef_loss: 0.5704\n",
      "Epoch 16: loss did not improve from 0.56442\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5704 - accuracy: 0.8312 - dice_coef_loss: 0.5704\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5751 - accuracy: 0.8341 - dice_coef_loss: 0.5751\n",
      "Epoch 17: loss did not improve from 0.56442\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5751 - accuracy: 0.8341 - dice_coef_loss: 0.5751\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5687 - accuracy: 0.8292 - dice_coef_loss: 0.5687\n",
      "Epoch 18: loss did not improve from 0.56442\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5687 - accuracy: 0.8292 - dice_coef_loss: 0.5687\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5716 - accuracy: 0.8300 - dice_coef_loss: 0.5716\n",
      "Epoch 19: loss did not improve from 0.56442\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5716 - accuracy: 0.8300 - dice_coef_loss: 0.5716\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5621 - accuracy: 0.8298 - dice_coef_loss: 0.5621\n",
      "Epoch 20: loss improved from 0.56442 to 0.56214, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 0.5621 - accuracy: 0.8298 - dice_coef_loss: 0.5621\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5632 - accuracy: 0.8412 - dice_coef_loss: 0.5632\n",
      "Epoch 21: loss did not improve from 0.56214\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5632 - accuracy: 0.8412 - dice_coef_loss: 0.5632\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5587 - accuracy: 0.8350 - dice_coef_loss: 0.5587\n",
      "Epoch 22: loss improved from 0.56214 to 0.55871, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 0.5587 - accuracy: 0.8350 - dice_coef_loss: 0.5587\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5739 - accuracy: 0.8366 - dice_coef_loss: 0.5737\n",
      "Epoch 23: loss did not improve from 0.55871\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.5739 - accuracy: 0.8366 - dice_coef_loss: 0.5737\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5680 - accuracy: 0.8400 - dice_coef_loss: 0.5680\n",
      "Epoch 24: loss did not improve from 0.55871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5680 - accuracy: 0.8400 - dice_coef_loss: 0.5680\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5598 - accuracy: 0.8380 - dice_coef_loss: 0.5598\n",
      "Epoch 25: loss did not improve from 0.55871\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5598 - accuracy: 0.8380 - dice_coef_loss: 0.5598\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5598 - accuracy: 0.8400 - dice_coef_loss: 0.5598\n",
      "Epoch 26: loss did not improve from 0.55871\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5598 - accuracy: 0.8400 - dice_coef_loss: 0.5598\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5485 - accuracy: 0.8428 - dice_coef_loss: 0.5485\n",
      "Epoch 27: loss improved from 0.55871 to 0.54852, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 0.5485 - accuracy: 0.8428 - dice_coef_loss: 0.5485\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5615 - accuracy: 0.8475 - dice_coef_loss: 0.5615\n",
      "Epoch 28: loss did not improve from 0.54852\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5615 - accuracy: 0.8475 - dice_coef_loss: 0.5615\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5680 - accuracy: 0.8486 - dice_coef_loss: 0.5680\n",
      "Epoch 29: loss did not improve from 0.54852\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5680 - accuracy: 0.8486 - dice_coef_loss: 0.5680\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5604 - accuracy: 0.8421 - dice_coef_loss: 0.5598\n",
      "Epoch 30: loss did not improve from 0.54852\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.5604 - accuracy: 0.8421 - dice_coef_loss: 0.5598\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5566 - accuracy: 0.8536 - dice_coef_loss: 0.5566\n",
      "Epoch 31: loss did not improve from 0.54852\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5566 - accuracy: 0.8536 - dice_coef_loss: 0.5566\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5532 - accuracy: 0.8464 - dice_coef_loss: 0.5532\n",
      "Epoch 32: loss did not improve from 0.54852\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5532 - accuracy: 0.8464 - dice_coef_loss: 0.5532\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5611 - accuracy: 0.8460 - dice_coef_loss: 0.5611\n",
      "Epoch 33: loss did not improve from 0.54852\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5611 - accuracy: 0.8460 - dice_coef_loss: 0.5611\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5614 - accuracy: 0.8550 - dice_coef_loss: 0.5614\n",
      "Epoch 34: loss did not improve from 0.54852\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5614 - accuracy: 0.8550 - dice_coef_loss: 0.5614\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5615 - accuracy: 0.8454 - dice_coef_loss: 0.5615\n",
      "Epoch 35: loss did not improve from 0.54852\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5615 - accuracy: 0.8454 - dice_coef_loss: 0.5615\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5666 - accuracy: 0.8423 - dice_coef_loss: 0.5666\n",
      "Epoch 36: loss did not improve from 0.54852\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5666 - accuracy: 0.8423 - dice_coef_loss: 0.5666\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5568 - accuracy: 0.8485 - dice_coef_loss: 0.5568\n",
      "Epoch 37: loss did not improve from 0.54852\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5568 - accuracy: 0.8485 - dice_coef_loss: 0.5568\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5629 - accuracy: 0.8542 - dice_coef_loss: 0.5619\n",
      "Epoch 38: loss did not improve from 0.54852\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.5629 - accuracy: 0.8542 - dice_coef_loss: 0.5619\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5635 - accuracy: 0.8504 - dice_coef_loss: 0.5635\n",
      "Epoch 39: loss did not improve from 0.54852\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5635 - accuracy: 0.8504 - dice_coef_loss: 0.5635\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5594 - accuracy: 0.8552 - dice_coef_loss: 0.5594\n",
      "Epoch 40: loss did not improve from 0.54852\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5594 - accuracy: 0.8552 - dice_coef_loss: 0.5594\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5557 - accuracy: 0.8539 - dice_coef_loss: 0.5557\n",
      "Epoch 41: loss did not improve from 0.54852\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5557 - accuracy: 0.8539 - dice_coef_loss: 0.5557\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5590 - accuracy: 0.8494 - dice_coef_loss: 0.5590\n",
      "Epoch 42: loss did not improve from 0.54852\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5590 - accuracy: 0.8494 - dice_coef_loss: 0.5590\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5493 - accuracy: 0.8614 - dice_coef_loss: 0.5493\n",
      "Epoch 43: loss did not improve from 0.54852\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5493 - accuracy: 0.8614 - dice_coef_loss: 0.5493\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5475 - accuracy: 0.8646 - dice_coef_loss: 0.5475\n",
      "Epoch 44: loss improved from 0.54852 to 0.54750, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 0.5475 - accuracy: 0.8646 - dice_coef_loss: 0.5475\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5648 - accuracy: 0.8555 - dice_coef_loss: 0.5680\n",
      "Epoch 45: loss did not improve from 0.54750\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.5648 - accuracy: 0.8555 - dice_coef_loss: 0.5680\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5580 - accuracy: 0.8651 - dice_coef_loss: 0.5580\n",
      "Epoch 46: loss did not improve from 0.54750\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5580 - accuracy: 0.8651 - dice_coef_loss: 0.5580\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5468 - accuracy: 0.8523 - dice_coef_loss: 0.5468\n",
      "Epoch 47: loss improved from 0.54750 to 0.54683, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 0.5468 - accuracy: 0.8523 - dice_coef_loss: 0.5468\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5577 - accuracy: 0.8548 - dice_coef_loss: 0.5577\n",
      "Epoch 48: loss did not improve from 0.54683\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5577 - accuracy: 0.8548 - dice_coef_loss: 0.5577\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5521 - accuracy: 0.8641 - dice_coef_loss: 0.5521\n",
      "Epoch 49: loss did not improve from 0.54683\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5521 - accuracy: 0.8641 - dice_coef_loss: 0.5521\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5558 - accuracy: 0.8615 - dice_coef_loss: 0.5558\n",
      "Epoch 50: loss did not improve from 0.54683\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5558 - accuracy: 0.8615 - dice_coef_loss: 0.5558\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5473 - accuracy: 0.8641 - dice_coef_loss: 0.5473\n",
      "Epoch 51: loss did not improve from 0.54683\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5473 - accuracy: 0.8641 - dice_coef_loss: 0.5473\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5580 - accuracy: 0.8626 - dice_coef_loss: 0.5576\n",
      "Epoch 52: loss did not improve from 0.54683\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.5580 - accuracy: 0.8626 - dice_coef_loss: 0.5576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5533 - accuracy: 0.8574 - dice_coef_loss: 0.5533\n",
      "Epoch 53: loss did not improve from 0.54683\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5533 - accuracy: 0.8574 - dice_coef_loss: 0.5533\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5472 - accuracy: 0.8611 - dice_coef_loss: 0.5472\n",
      "Epoch 54: loss did not improve from 0.54683\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5472 - accuracy: 0.8611 - dice_coef_loss: 0.5472\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5621 - accuracy: 0.8709 - dice_coef_loss: 0.5621\n",
      "Epoch 55: loss did not improve from 0.54683\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5621 - accuracy: 0.8709 - dice_coef_loss: 0.5621\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5440 - accuracy: 0.8630 - dice_coef_loss: 0.5440\n",
      "Epoch 56: loss improved from 0.54683 to 0.54396, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 0.5440 - accuracy: 0.8630 - dice_coef_loss: 0.5440\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5532 - accuracy: 0.8686 - dice_coef_loss: 0.5532\n",
      "Epoch 57: loss did not improve from 0.54396\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5532 - accuracy: 0.8686 - dice_coef_loss: 0.5532\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5491 - accuracy: 0.8696 - dice_coef_loss: 0.5491\n",
      "Epoch 58: loss did not improve from 0.54396\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5491 - accuracy: 0.8696 - dice_coef_loss: 0.5491\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5493 - accuracy: 0.8617 - dice_coef_loss: 0.5493\n",
      "Epoch 59: loss did not improve from 0.54396\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5493 - accuracy: 0.8617 - dice_coef_loss: 0.5493\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5593 - accuracy: 0.8645 - dice_coef_loss: 0.5587\n",
      "Epoch 60: loss did not improve from 0.54396\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.5593 - accuracy: 0.8645 - dice_coef_loss: 0.5587\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5436 - accuracy: 0.8647 - dice_coef_loss: 0.5436\n",
      "Epoch 61: loss improved from 0.54396 to 0.54363, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.5436 - accuracy: 0.8647 - dice_coef_loss: 0.5436\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5448 - accuracy: 0.8693 - dice_coef_loss: 0.5448\n",
      "Epoch 62: loss did not improve from 0.54363\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5448 - accuracy: 0.8693 - dice_coef_loss: 0.5448\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5474 - accuracy: 0.8679 - dice_coef_loss: 0.5474\n",
      "Epoch 63: loss did not improve from 0.54363\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5474 - accuracy: 0.8679 - dice_coef_loss: 0.5474\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5428 - accuracy: 0.8725 - dice_coef_loss: 0.5428\n",
      "Epoch 64: loss improved from 0.54363 to 0.54284, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 0.5428 - accuracy: 0.8725 - dice_coef_loss: 0.5428\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5642 - accuracy: 0.8698 - dice_coef_loss: 0.5642\n",
      "Epoch 65: loss did not improve from 0.54284\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5642 - accuracy: 0.8698 - dice_coef_loss: 0.5642\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5491 - accuracy: 0.8736 - dice_coef_loss: 0.5491\n",
      "Epoch 66: loss did not improve from 0.54284\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5491 - accuracy: 0.8736 - dice_coef_loss: 0.5491\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5412 - accuracy: 0.8685 - dice_coef_loss: 0.5413\n",
      "Epoch 67: loss improved from 0.54284 to 0.54124, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.5412 - accuracy: 0.8685 - dice_coef_loss: 0.5413\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5526 - accuracy: 0.8632 - dice_coef_loss: 0.5526\n",
      "Epoch 68: loss did not improve from 0.54124\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5526 - accuracy: 0.8632 - dice_coef_loss: 0.5526\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5387 - accuracy: 0.8732 - dice_coef_loss: 0.5387\n",
      "Epoch 69: loss improved from 0.54124 to 0.53872, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.5387 - accuracy: 0.8732 - dice_coef_loss: 0.5387\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5574 - accuracy: 0.8671 - dice_coef_loss: 0.5574\n",
      "Epoch 70: loss did not improve from 0.53872\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5574 - accuracy: 0.8671 - dice_coef_loss: 0.5574\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5437 - accuracy: 0.8725 - dice_coef_loss: 0.5437\n",
      "Epoch 71: loss did not improve from 0.53872\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5437 - accuracy: 0.8725 - dice_coef_loss: 0.5437\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5517 - accuracy: 0.8723 - dice_coef_loss: 0.5517\n",
      "Epoch 72: loss did not improve from 0.53872\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5517 - accuracy: 0.8723 - dice_coef_loss: 0.5517\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5451 - accuracy: 0.8760 - dice_coef_loss: 0.5451\n",
      "Epoch 73: loss did not improve from 0.53872\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5451 - accuracy: 0.8760 - dice_coef_loss: 0.5451\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5519 - accuracy: 0.8732 - dice_coef_loss: 0.5519\n",
      "Epoch 74: loss did not improve from 0.53872\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5519 - accuracy: 0.8732 - dice_coef_loss: 0.5519\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5466 - accuracy: 0.8626 - dice_coef_loss: 0.5457\n",
      "Epoch 75: loss did not improve from 0.53872\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.5466 - accuracy: 0.8626 - dice_coef_loss: 0.5457\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5419 - accuracy: 0.8718 - dice_coef_loss: 0.5419\n",
      "Epoch 76: loss did not improve from 0.53872\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5419 - accuracy: 0.8718 - dice_coef_loss: 0.5419\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5505 - accuracy: 0.8752 - dice_coef_loss: 0.5505\n",
      "Epoch 77: loss did not improve from 0.53872\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5505 - accuracy: 0.8752 - dice_coef_loss: 0.5505\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5504 - accuracy: 0.8665 - dice_coef_loss: 0.5504\n",
      "Epoch 78: loss did not improve from 0.53872\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5504 - accuracy: 0.8665 - dice_coef_loss: 0.5504\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5538 - accuracy: 0.8771 - dice_coef_loss: 0.5538\n",
      "Epoch 79: loss did not improve from 0.53872\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5538 - accuracy: 0.8771 - dice_coef_loss: 0.5538\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5341 - accuracy: 0.8808 - dice_coef_loss: 0.5341\n",
      "Epoch 80: loss improved from 0.53872 to 0.53415, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.5341 - accuracy: 0.8808 - dice_coef_loss: 0.5341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5408 - accuracy: 0.8785 - dice_coef_loss: 0.5408\n",
      "Epoch 81: loss did not improve from 0.53415\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5408 - accuracy: 0.8785 - dice_coef_loss: 0.5408\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5419 - accuracy: 0.8679 - dice_coef_loss: 0.5415\n",
      "Epoch 82: loss did not improve from 0.53415\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.5419 - accuracy: 0.8679 - dice_coef_loss: 0.5415\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5308 - accuracy: 0.8767 - dice_coef_loss: 0.5308\n",
      "Epoch 83: loss improved from 0.53415 to 0.53082, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.5308 - accuracy: 0.8767 - dice_coef_loss: 0.5308\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5411 - accuracy: 0.8786 - dice_coef_loss: 0.5411\n",
      "Epoch 84: loss did not improve from 0.53082\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5411 - accuracy: 0.8786 - dice_coef_loss: 0.5411\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5453 - accuracy: 0.8752 - dice_coef_loss: 0.5453\n",
      "Epoch 85: loss did not improve from 0.53082\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5453 - accuracy: 0.8752 - dice_coef_loss: 0.5453\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5373 - accuracy: 0.8786 - dice_coef_loss: 0.5373\n",
      "Epoch 86: loss did not improve from 0.53082\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5373 - accuracy: 0.8786 - dice_coef_loss: 0.5373\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5462 - accuracy: 0.8729 - dice_coef_loss: 0.5462\n",
      "Epoch 87: loss did not improve from 0.53082\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5462 - accuracy: 0.8729 - dice_coef_loss: 0.5462\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5451 - accuracy: 0.8811 - dice_coef_loss: 0.5451\n",
      "Epoch 88: loss did not improve from 0.53082\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5451 - accuracy: 0.8811 - dice_coef_loss: 0.5451\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5600 - accuracy: 0.8775 - dice_coef_loss: 0.5594\n",
      "Epoch 89: loss did not improve from 0.53082\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.5600 - accuracy: 0.8775 - dice_coef_loss: 0.5594\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5418 - accuracy: 0.8736 - dice_coef_loss: 0.5418\n",
      "Epoch 90: loss did not improve from 0.53082\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5418 - accuracy: 0.8736 - dice_coef_loss: 0.5418\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5549 - accuracy: 0.8795 - dice_coef_loss: 0.5549\n",
      "Epoch 91: loss did not improve from 0.53082\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5549 - accuracy: 0.8795 - dice_coef_loss: 0.5549\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5329 - accuracy: 0.8779 - dice_coef_loss: 0.5329\n",
      "Epoch 92: loss did not improve from 0.53082\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5329 - accuracy: 0.8779 - dice_coef_loss: 0.5329\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5368 - accuracy: 0.8849 - dice_coef_loss: 0.5368\n",
      "Epoch 93: loss did not improve from 0.53082\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5368 - accuracy: 0.8849 - dice_coef_loss: 0.5368\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5289 - accuracy: 0.8801 - dice_coef_loss: 0.5289\n",
      "Epoch 94: loss improved from 0.53082 to 0.52887, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 0.5289 - accuracy: 0.8801 - dice_coef_loss: 0.5289\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5608 - accuracy: 0.8801 - dice_coef_loss: 0.5608\n",
      "Epoch 95: loss did not improve from 0.52887\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5608 - accuracy: 0.8801 - dice_coef_loss: 0.5608\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5402 - accuracy: 0.8795 - dice_coef_loss: 0.5402\n",
      "Epoch 96: loss did not improve from 0.52887\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5402 - accuracy: 0.8795 - dice_coef_loss: 0.5402\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5377 - accuracy: 0.8805 - dice_coef_loss: 0.5400\n",
      "Epoch 97: loss did not improve from 0.52887\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.5377 - accuracy: 0.8805 - dice_coef_loss: 0.5400\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5429 - accuracy: 0.8847 - dice_coef_loss: 0.5429\n",
      "Epoch 98: loss did not improve from 0.52887\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5429 - accuracy: 0.8847 - dice_coef_loss: 0.5429\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5417 - accuracy: 0.8798 - dice_coef_loss: 0.5417\n",
      "Epoch 99: loss did not improve from 0.52887\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5417 - accuracy: 0.8798 - dice_coef_loss: 0.5417\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5335 - accuracy: 0.8829 - dice_coef_loss: 0.5335\n",
      "Epoch 100: loss did not improve from 0.52887\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5335 - accuracy: 0.8829 - dice_coef_loss: 0.5335\n",
      "Found 2961 images belonging to 1 classes.\n",
      "Found 2961 images belonging to 1 classes.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f837f0ceef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f837f0ceef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6312 - accuracy: 0.5240 - dice_coef_loss: 0.6312\n",
      "Epoch 1: loss improved from inf to 0.63121, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 28s 267ms/step - loss: 0.6312 - accuracy: 0.5240 - dice_coef_loss: 0.6312\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6102 - accuracy: 0.7055 - dice_coef_loss: 0.6102\n",
      "Epoch 2: loss improved from 0.63121 to 0.61017, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.6102 - accuracy: 0.7055 - dice_coef_loss: 0.6102\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5999 - accuracy: 0.7581 - dice_coef_loss: 0.5999\n",
      "Epoch 3: loss improved from 0.61017 to 0.59995, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.5999 - accuracy: 0.7581 - dice_coef_loss: 0.5999\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5827 - accuracy: 0.7661 - dice_coef_loss: 0.5827\n",
      "Epoch 4: loss improved from 0.59995 to 0.58266, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.5827 - accuracy: 0.7661 - dice_coef_loss: 0.5827\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 0.5803 - accuracy: 0.7855 - dice_coef_loss: 0.5803\n",
      "Epoch 5: loss improved from 0.58266 to 0.58026, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.5803 - accuracy: 0.7855 - dice_coef_loss: 0.5803\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5822 - accuracy: 0.7864 - dice_coef_loss: 0.5822\n",
      "Epoch 6: loss did not improve from 0.58026\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5822 - accuracy: 0.7864 - dice_coef_loss: 0.5822\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5764 - accuracy: 0.8063 - dice_coef_loss: 0.5764\n",
      "Epoch 7: loss improved from 0.58026 to 0.57639, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.5764 - accuracy: 0.8063 - dice_coef_loss: 0.5764\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5798 - accuracy: 0.8024 - dice_coef_loss: 0.5787\n",
      "Epoch 8: loss did not improve from 0.57639\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.5798 - accuracy: 0.8024 - dice_coef_loss: 0.5787\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5729 - accuracy: 0.8092 - dice_coef_loss: 0.5729\n",
      "Epoch 9: loss improved from 0.57639 to 0.57288, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 0.5729 - accuracy: 0.8092 - dice_coef_loss: 0.5729\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5709 - accuracy: 0.8097 - dice_coef_loss: 0.5709\n",
      "Epoch 10: loss improved from 0.57288 to 0.57085, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.5709 - accuracy: 0.8097 - dice_coef_loss: 0.5709\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5780 - accuracy: 0.8192 - dice_coef_loss: 0.5780\n",
      "Epoch 11: loss did not improve from 0.57085\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5780 - accuracy: 0.8192 - dice_coef_loss: 0.5780\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5695 - accuracy: 0.8230 - dice_coef_loss: 0.5695\n",
      "Epoch 12: loss improved from 0.57085 to 0.56948, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 0.5695 - accuracy: 0.8230 - dice_coef_loss: 0.5695\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5762 - accuracy: 0.8166 - dice_coef_loss: 0.5762\n",
      "Epoch 13: loss did not improve from 0.56948\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.5762 - accuracy: 0.8166 - dice_coef_loss: 0.5762\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5589 - accuracy: 0.8273 - dice_coef_loss: 0.5589\n",
      "Epoch 14: loss improved from 0.56948 to 0.55889, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.5589 - accuracy: 0.8273 - dice_coef_loss: 0.5589\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5767 - accuracy: 0.8198 - dice_coef_loss: 0.5751\n",
      "Epoch 15: loss did not improve from 0.55889\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.5767 - accuracy: 0.8198 - dice_coef_loss: 0.5751\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5602 - accuracy: 0.8302 - dice_coef_loss: 0.5602\n",
      "Epoch 16: loss did not improve from 0.55889\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5602 - accuracy: 0.8302 - dice_coef_loss: 0.5602\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5665 - accuracy: 0.8353 - dice_coef_loss: 0.5665\n",
      "Epoch 17: loss did not improve from 0.55889\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 0.5665 - accuracy: 0.8353 - dice_coef_loss: 0.5665\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5606 - accuracy: 0.8272 - dice_coef_loss: 0.5606\n",
      "Epoch 18: loss did not improve from 0.55889\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 0.5606 - accuracy: 0.8272 - dice_coef_loss: 0.5606\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5735 - accuracy: 0.8315 - dice_coef_loss: 0.5735\n",
      "Epoch 19: loss did not improve from 0.55889\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.5735 - accuracy: 0.8315 - dice_coef_loss: 0.5735\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5663 - accuracy: 0.8391 - dice_coef_loss: 0.5663\n",
      "Epoch 20: loss did not improve from 0.55889\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 0.5663 - accuracy: 0.8391 - dice_coef_loss: 0.5663\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5684 - accuracy: 0.8363 - dice_coef_loss: 0.5684\n",
      "Epoch 21: loss did not improve from 0.55889\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 0.5684 - accuracy: 0.8363 - dice_coef_loss: 0.5684\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5588 - accuracy: 0.8414 - dice_coef_loss: 0.5588\n",
      "Epoch 22: loss improved from 0.55889 to 0.55879, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 0.5588 - accuracy: 0.8414 - dice_coef_loss: 0.5588\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5543 - accuracy: 0.8390 - dice_coef_loss: 0.5535\n",
      "Epoch 23: loss improved from 0.55879 to 0.55427, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 0.5543 - accuracy: 0.8390 - dice_coef_loss: 0.5535\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5488 - accuracy: 0.8373 - dice_coef_loss: 0.5488\n",
      "Epoch 24: loss improved from 0.55427 to 0.54881, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 28s 278ms/step - loss: 0.5488 - accuracy: 0.8373 - dice_coef_loss: 0.5488\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5688 - accuracy: 0.8358 - dice_coef_loss: 0.5688\n",
      "Epoch 25: loss did not improve from 0.54881\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 0.5688 - accuracy: 0.8358 - dice_coef_loss: 0.5688\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5700 - accuracy: 0.8502 - dice_coef_loss: 0.5700\n",
      "Epoch 26: loss did not improve from 0.54881\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.5700 - accuracy: 0.8502 - dice_coef_loss: 0.5700\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5534 - accuracy: 0.8428 - dice_coef_loss: 0.5534\n",
      "Epoch 27: loss did not improve from 0.54881\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.5534 - accuracy: 0.8428 - dice_coef_loss: 0.5534\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5608 - accuracy: 0.8474 - dice_coef_loss: 0.5608\n",
      "Epoch 28: loss did not improve from 0.54881\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.5608 - accuracy: 0.8474 - dice_coef_loss: 0.5608\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5555 - accuracy: 0.8502 - dice_coef_loss: 0.5555\n",
      "Epoch 29: loss did not improve from 0.54881\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 0.5555 - accuracy: 0.8502 - dice_coef_loss: 0.5555\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5681 - accuracy: 0.8410 - dice_coef_loss: 0.5670\n",
      "Epoch 30: loss did not improve from 0.54881\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5681 - accuracy: 0.8410 - dice_coef_loss: 0.5670\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5424 - accuracy: 0.8507 - dice_coef_loss: 0.5424\n",
      "Epoch 31: loss improved from 0.54881 to 0.54235, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 0.5424 - accuracy: 0.8507 - dice_coef_loss: 0.5424\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 0.5534 - accuracy: 0.8411 - dice_coef_loss: 0.5534\n",
      "Epoch 32: loss did not improve from 0.54235\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.5534 - accuracy: 0.8411 - dice_coef_loss: 0.5534\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5547 - accuracy: 0.8554 - dice_coef_loss: 0.5547\n",
      "Epoch 33: loss did not improve from 0.54235\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.5547 - accuracy: 0.8554 - dice_coef_loss: 0.5547\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5634 - accuracy: 0.8527 - dice_coef_loss: 0.5634\n",
      "Epoch 34: loss did not improve from 0.54235\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 0.5634 - accuracy: 0.8527 - dice_coef_loss: 0.5634\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5632 - accuracy: 0.8497 - dice_coef_loss: 0.5632\n",
      "Epoch 35: loss did not improve from 0.54235\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.5632 - accuracy: 0.8497 - dice_coef_loss: 0.5632\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5480 - accuracy: 0.8584 - dice_coef_loss: 0.5480\n",
      "Epoch 36: loss did not improve from 0.54235\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.5480 - accuracy: 0.8584 - dice_coef_loss: 0.5480\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5666 - accuracy: 0.8557 - dice_coef_loss: 0.5666\n",
      "Epoch 37: loss did not improve from 0.54235\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.5666 - accuracy: 0.8557 - dice_coef_loss: 0.5666\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5607 - accuracy: 0.8524 - dice_coef_loss: 0.5605\n",
      "Epoch 38: loss did not improve from 0.54235\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.5607 - accuracy: 0.8524 - dice_coef_loss: 0.5605\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5552 - accuracy: 0.8556 - dice_coef_loss: 0.5552\n",
      "Epoch 39: loss did not improve from 0.54235\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.5552 - accuracy: 0.8556 - dice_coef_loss: 0.5552\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5525 - accuracy: 0.8587 - dice_coef_loss: 0.5525\n",
      "Epoch 40: loss did not improve from 0.54235\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5525 - accuracy: 0.8587 - dice_coef_loss: 0.5525\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5606 - accuracy: 0.8567 - dice_coef_loss: 0.5606\n",
      "Epoch 41: loss did not improve from 0.54235\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5606 - accuracy: 0.8567 - dice_coef_loss: 0.5606\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5510 - accuracy: 0.8559 - dice_coef_loss: 0.5510\n",
      "Epoch 42: loss did not improve from 0.54235\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5510 - accuracy: 0.8559 - dice_coef_loss: 0.5510\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5529 - accuracy: 0.8562 - dice_coef_loss: 0.5529\n",
      "Epoch 43: loss did not improve from 0.54235\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5529 - accuracy: 0.8562 - dice_coef_loss: 0.5529\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5517 - accuracy: 0.8525 - dice_coef_loss: 0.5517\n",
      "Epoch 44: loss did not improve from 0.54235\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5517 - accuracy: 0.8525 - dice_coef_loss: 0.5517\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5600 - accuracy: 0.8639 - dice_coef_loss: 0.5605\n",
      "Epoch 45: loss did not improve from 0.54235\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.5600 - accuracy: 0.8639 - dice_coef_loss: 0.5605\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5439 - accuracy: 0.8641 - dice_coef_loss: 0.5439\n",
      "Epoch 46: loss did not improve from 0.54235\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5439 - accuracy: 0.8641 - dice_coef_loss: 0.5439\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5615 - accuracy: 0.8606 - dice_coef_loss: 0.5615\n",
      "Epoch 47: loss did not improve from 0.54235\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5615 - accuracy: 0.8606 - dice_coef_loss: 0.5615\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5502 - accuracy: 0.8657 - dice_coef_loss: 0.5502\n",
      "Epoch 48: loss did not improve from 0.54235\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5502 - accuracy: 0.8657 - dice_coef_loss: 0.5502\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5405 - accuracy: 0.8593 - dice_coef_loss: 0.5405\n",
      "Epoch 49: loss improved from 0.54235 to 0.54054, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.5405 - accuracy: 0.8593 - dice_coef_loss: 0.5405\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5629 - accuracy: 0.8570 - dice_coef_loss: 0.5629\n",
      "Epoch 50: loss did not improve from 0.54054\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5629 - accuracy: 0.8570 - dice_coef_loss: 0.5629\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5417 - accuracy: 0.8697 - dice_coef_loss: 0.5417\n",
      "Epoch 51: loss did not improve from 0.54054\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.5417 - accuracy: 0.8697 - dice_coef_loss: 0.5417\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5533 - accuracy: 0.8634 - dice_coef_loss: 0.5533\n",
      "Epoch 52: loss did not improve from 0.54054\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.5533 - accuracy: 0.8634 - dice_coef_loss: 0.5533\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5585 - accuracy: 0.8628 - dice_coef_loss: 0.5585\n",
      "Epoch 53: loss did not improve from 0.54054\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5585 - accuracy: 0.8628 - dice_coef_loss: 0.5585\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5386 - accuracy: 0.8631 - dice_coef_loss: 0.5386\n",
      "Epoch 54: loss improved from 0.54054 to 0.53864, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 0.5386 - accuracy: 0.8631 - dice_coef_loss: 0.5386\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5502 - accuracy: 0.8673 - dice_coef_loss: 0.5502\n",
      "Epoch 55: loss did not improve from 0.53864\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5502 - accuracy: 0.8673 - dice_coef_loss: 0.5502\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5512 - accuracy: 0.8566 - dice_coef_loss: 0.5512\n",
      "Epoch 56: loss did not improve from 0.53864\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5512 - accuracy: 0.8566 - dice_coef_loss: 0.5512\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5482 - accuracy: 0.8691 - dice_coef_loss: 0.5482\n",
      "Epoch 57: loss did not improve from 0.53864\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.5482 - accuracy: 0.8691 - dice_coef_loss: 0.5482\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5562 - accuracy: 0.8677 - dice_coef_loss: 0.5562\n",
      "Epoch 58: loss did not improve from 0.53864\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.5562 - accuracy: 0.8677 - dice_coef_loss: 0.5562\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5421 - accuracy: 0.8656 - dice_coef_loss: 0.5421\n",
      "Epoch 59: loss did not improve from 0.53864\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5421 - accuracy: 0.8656 - dice_coef_loss: 0.5421\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5473 - accuracy: 0.8641 - dice_coef_loss: 0.5471\n",
      "Epoch 60: loss did not improve from 0.53864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 26s 258ms/step - loss: 0.5473 - accuracy: 0.8641 - dice_coef_loss: 0.5471\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5423 - accuracy: 0.8719 - dice_coef_loss: 0.5423\n",
      "Epoch 61: loss did not improve from 0.53864\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5423 - accuracy: 0.8719 - dice_coef_loss: 0.5423\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5370 - accuracy: 0.8701 - dice_coef_loss: 0.5370\n",
      "Epoch 62: loss improved from 0.53864 to 0.53696, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.5370 - accuracy: 0.8701 - dice_coef_loss: 0.5370\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5520 - accuracy: 0.8684 - dice_coef_loss: 0.5520\n",
      "Epoch 63: loss did not improve from 0.53696\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5520 - accuracy: 0.8684 - dice_coef_loss: 0.5520\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5673 - accuracy: 0.8669 - dice_coef_loss: 0.5673\n",
      "Epoch 64: loss did not improve from 0.53696\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5673 - accuracy: 0.8669 - dice_coef_loss: 0.5673\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5498 - accuracy: 0.8736 - dice_coef_loss: 0.5498\n",
      "Epoch 65: loss did not improve from 0.53696\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5498 - accuracy: 0.8736 - dice_coef_loss: 0.5498\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5411 - accuracy: 0.8733 - dice_coef_loss: 0.5411\n",
      "Epoch 66: loss did not improve from 0.53696\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5411 - accuracy: 0.8733 - dice_coef_loss: 0.5411\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5372 - accuracy: 0.8682 - dice_coef_loss: 0.5363\n",
      "Epoch 67: loss did not improve from 0.53696\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.5372 - accuracy: 0.8682 - dice_coef_loss: 0.5363\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5442 - accuracy: 0.8730 - dice_coef_loss: 0.5442\n",
      "Epoch 68: loss did not improve from 0.53696\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5442 - accuracy: 0.8730 - dice_coef_loss: 0.5442\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5476 - accuracy: 0.8729 - dice_coef_loss: 0.5476\n",
      "Epoch 69: loss did not improve from 0.53696\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5476 - accuracy: 0.8729 - dice_coef_loss: 0.5476\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5450 - accuracy: 0.8643 - dice_coef_loss: 0.5450\n",
      "Epoch 70: loss did not improve from 0.53696\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5450 - accuracy: 0.8643 - dice_coef_loss: 0.5450\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5389 - accuracy: 0.8782 - dice_coef_loss: 0.5389\n",
      "Epoch 71: loss did not improve from 0.53696\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.5389 - accuracy: 0.8782 - dice_coef_loss: 0.5389\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5509 - accuracy: 0.8700 - dice_coef_loss: 0.5509\n",
      "Epoch 72: loss did not improve from 0.53696\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5509 - accuracy: 0.8700 - dice_coef_loss: 0.5509\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5468 - accuracy: 0.8701 - dice_coef_loss: 0.5468\n",
      "Epoch 73: loss did not improve from 0.53696\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.5468 - accuracy: 0.8701 - dice_coef_loss: 0.5468\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5422 - accuracy: 0.8693 - dice_coef_loss: 0.5422\n",
      "Epoch 74: loss did not improve from 0.53696\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5422 - accuracy: 0.8693 - dice_coef_loss: 0.5422\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5594 - accuracy: 0.8708 - dice_coef_loss: 0.5580\n",
      "Epoch 75: loss did not improve from 0.53696\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.5594 - accuracy: 0.8708 - dice_coef_loss: 0.5580\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5414 - accuracy: 0.8805 - dice_coef_loss: 0.5414\n",
      "Epoch 76: loss did not improve from 0.53696\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.5414 - accuracy: 0.8805 - dice_coef_loss: 0.5414\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5325 - accuracy: 0.8715 - dice_coef_loss: 0.5325\n",
      "Epoch 77: loss improved from 0.53696 to 0.53253, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.5325 - accuracy: 0.8715 - dice_coef_loss: 0.5325\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5430 - accuracy: 0.8755 - dice_coef_loss: 0.5430\n",
      "Epoch 78: loss did not improve from 0.53253\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5430 - accuracy: 0.8755 - dice_coef_loss: 0.5430\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5493 - accuracy: 0.8734 - dice_coef_loss: 0.5493\n",
      "Epoch 79: loss did not improve from 0.53253\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5493 - accuracy: 0.8734 - dice_coef_loss: 0.5493\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5383 - accuracy: 0.8775 - dice_coef_loss: 0.5383\n",
      "Epoch 80: loss did not improve from 0.53253\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.5383 - accuracy: 0.8775 - dice_coef_loss: 0.5383\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5380 - accuracy: 0.8790 - dice_coef_loss: 0.5380\n",
      "Epoch 81: loss did not improve from 0.53253\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5380 - accuracy: 0.8790 - dice_coef_loss: 0.5380\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5353 - accuracy: 0.8716 - dice_coef_loss: 0.5339\n",
      "Epoch 82: loss did not improve from 0.53253\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.5353 - accuracy: 0.8716 - dice_coef_loss: 0.5339\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5440 - accuracy: 0.8747 - dice_coef_loss: 0.5440\n",
      "Epoch 83: loss did not improve from 0.53253\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.5440 - accuracy: 0.8747 - dice_coef_loss: 0.5440\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5425 - accuracy: 0.8822 - dice_coef_loss: 0.5425\n",
      "Epoch 84: loss did not improve from 0.53253\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5425 - accuracy: 0.8822 - dice_coef_loss: 0.5425\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5368 - accuracy: 0.8718 - dice_coef_loss: 0.5368\n",
      "Epoch 85: loss did not improve from 0.53253\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5368 - accuracy: 0.8718 - dice_coef_loss: 0.5368\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5449 - accuracy: 0.8864 - dice_coef_loss: 0.5449\n",
      "Epoch 86: loss did not improve from 0.53253\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5449 - accuracy: 0.8864 - dice_coef_loss: 0.5449\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5474 - accuracy: 0.8757 - dice_coef_loss: 0.5474\n",
      "Epoch 87: loss did not improve from 0.53253\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.5474 - accuracy: 0.8757 - dice_coef_loss: 0.5474\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5444 - accuracy: 0.8806 - dice_coef_loss: 0.5444\n",
      "Epoch 88: loss did not improve from 0.53253\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5444 - accuracy: 0.8806 - dice_coef_loss: 0.5444\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 0.5425 - accuracy: 0.8774 - dice_coef_loss: 0.5421\n",
      "Epoch 89: loss did not improve from 0.53253\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.5425 - accuracy: 0.8774 - dice_coef_loss: 0.5421\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5401 - accuracy: 0.8804 - dice_coef_loss: 0.5401\n",
      "Epoch 90: loss did not improve from 0.53253\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5401 - accuracy: 0.8804 - dice_coef_loss: 0.5401\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5311 - accuracy: 0.8818 - dice_coef_loss: 0.5311\n",
      "Epoch 91: loss improved from 0.53253 to 0.53111, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.5311 - accuracy: 0.8818 - dice_coef_loss: 0.5311\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5413 - accuracy: 0.8811 - dice_coef_loss: 0.5413\n",
      "Epoch 92: loss did not improve from 0.53111\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5413 - accuracy: 0.8811 - dice_coef_loss: 0.5413\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5410 - accuracy: 0.8813 - dice_coef_loss: 0.5410\n",
      "Epoch 93: loss did not improve from 0.53111\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.5410 - accuracy: 0.8813 - dice_coef_loss: 0.5410\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5363 - accuracy: 0.8809 - dice_coef_loss: 0.5363\n",
      "Epoch 94: loss did not improve from 0.53111\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.5363 - accuracy: 0.8809 - dice_coef_loss: 0.5363\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5405 - accuracy: 0.8850 - dice_coef_loss: 0.5405\n",
      "Epoch 95: loss did not improve from 0.53111\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.5405 - accuracy: 0.8850 - dice_coef_loss: 0.5405\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5526 - accuracy: 0.8705 - dice_coef_loss: 0.5526\n",
      "Epoch 96: loss did not improve from 0.53111\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5526 - accuracy: 0.8705 - dice_coef_loss: 0.5526\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5353 - accuracy: 0.8799 - dice_coef_loss: 0.5388\n",
      "Epoch 97: loss did not improve from 0.53111\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.5353 - accuracy: 0.8799 - dice_coef_loss: 0.5388\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5425 - accuracy: 0.8792 - dice_coef_loss: 0.5425\n",
      "Epoch 98: loss did not improve from 0.53111\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5425 - accuracy: 0.8792 - dice_coef_loss: 0.5425\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5450 - accuracy: 0.8822 - dice_coef_loss: 0.5450\n",
      "Epoch 99: loss did not improve from 0.53111\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.5450 - accuracy: 0.8822 - dice_coef_loss: 0.5450\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5422 - accuracy: 0.8861 - dice_coef_loss: 0.5422\n",
      "Epoch 100: loss did not improve from 0.53111\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.5422 - accuracy: 0.8861 - dice_coef_loss: 0.5422\n",
      "Found 2962 images belonging to 1 classes.\n",
      "Found 2962 images belonging to 1 classes.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f83a4ff93b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f83a4ff93b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6587 - accuracy: 0.7302 - dice_coef_loss: 0.6587\n",
      "Epoch 1: loss improved from inf to 0.65871, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.6587 - accuracy: 0.7302 - dice_coef_loss: 0.6587\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6044 - accuracy: 0.7918 - dice_coef_loss: 0.6044\n",
      "Epoch 2: loss improved from 0.65871 to 0.60442, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.6044 - accuracy: 0.7918 - dice_coef_loss: 0.6044\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5539 - accuracy: 0.8165 - dice_coef_loss: 0.5539\n",
      "Epoch 3: loss improved from 0.60442 to 0.55385, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.5539 - accuracy: 0.8165 - dice_coef_loss: 0.5539\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5512 - accuracy: 0.8235 - dice_coef_loss: 0.5512\n",
      "Epoch 4: loss improved from 0.55385 to 0.55119, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.5512 - accuracy: 0.8235 - dice_coef_loss: 0.5512\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5418 - accuracy: 0.8328 - dice_coef_loss: 0.5418\n",
      "Epoch 5: loss improved from 0.55119 to 0.54183, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.5418 - accuracy: 0.8328 - dice_coef_loss: 0.5418\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5323 - accuracy: 0.8387 - dice_coef_loss: 0.5323\n",
      "Epoch 6: loss improved from 0.54183 to 0.53228, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.5323 - accuracy: 0.8387 - dice_coef_loss: 0.5323\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5252 - accuracy: 0.8446 - dice_coef_loss: 0.5252\n",
      "Epoch 7: loss improved from 0.53228 to 0.52522, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.5252 - accuracy: 0.8446 - dice_coef_loss: 0.5252\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5117 - accuracy: 0.8487 - dice_coef_loss: 0.5114\n",
      "Epoch 8: loss improved from 0.52522 to 0.51166, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 28s 283ms/step - loss: 0.5117 - accuracy: 0.8487 - dice_coef_loss: 0.5114\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5194 - accuracy: 0.8408 - dice_coef_loss: 0.5194\n",
      "Epoch 9: loss did not improve from 0.51166\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.5194 - accuracy: 0.8408 - dice_coef_loss: 0.5194\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5177 - accuracy: 0.8505 - dice_coef_loss: 0.5177\n",
      "Epoch 10: loss did not improve from 0.51166\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.5177 - accuracy: 0.8505 - dice_coef_loss: 0.5177\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5014 - accuracy: 0.8523 - dice_coef_loss: 0.5014\n",
      "Epoch 11: loss improved from 0.51166 to 0.50140, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.5014 - accuracy: 0.8523 - dice_coef_loss: 0.5014\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4972 - accuracy: 0.8510 - dice_coef_loss: 0.4972\n",
      "Epoch 12: loss improved from 0.50140 to 0.49721, saving model to ./temp/polar_Dom/checkpoint.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 27s 266ms/step - loss: 0.4972 - accuracy: 0.8510 - dice_coef_loss: 0.4972\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5078 - accuracy: 0.8511 - dice_coef_loss: 0.5078\n",
      "Epoch 13: loss did not improve from 0.49721\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.5078 - accuracy: 0.8511 - dice_coef_loss: 0.5078\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4883 - accuracy: 0.8589 - dice_coef_loss: 0.4883\n",
      "Epoch 14: loss improved from 0.49721 to 0.48826, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.4883 - accuracy: 0.8589 - dice_coef_loss: 0.4883\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5062 - accuracy: 0.8494 - dice_coef_loss: 0.5062\n",
      "Epoch 15: loss did not improve from 0.48826\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.5062 - accuracy: 0.8494 - dice_coef_loss: 0.5062\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4925 - accuracy: 0.8586 - dice_coef_loss: 0.4925\n",
      "Epoch 16: loss did not improve from 0.48826\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4925 - accuracy: 0.8586 - dice_coef_loss: 0.4925\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5002 - accuracy: 0.8508 - dice_coef_loss: 0.5002\n",
      "Epoch 17: loss did not improve from 0.48826\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.5002 - accuracy: 0.8508 - dice_coef_loss: 0.5002\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4881 - accuracy: 0.8582 - dice_coef_loss: 0.4881\n",
      "Epoch 18: loss improved from 0.48826 to 0.48810, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4881 - accuracy: 0.8582 - dice_coef_loss: 0.4881\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4828 - accuracy: 0.8587 - dice_coef_loss: 0.4828\n",
      "Epoch 19: loss improved from 0.48810 to 0.48282, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.4828 - accuracy: 0.8587 - dice_coef_loss: 0.4828\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4905 - accuracy: 0.8591 - dice_coef_loss: 0.4905\n",
      "Epoch 20: loss did not improve from 0.48282\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4905 - accuracy: 0.8591 - dice_coef_loss: 0.4905\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4877 - accuracy: 0.8617 - dice_coef_loss: 0.4877\n",
      "Epoch 21: loss did not improve from 0.48282\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4877 - accuracy: 0.8617 - dice_coef_loss: 0.4877\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4829 - accuracy: 0.8649 - dice_coef_loss: 0.4829\n",
      "Epoch 22: loss did not improve from 0.48282\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4829 - accuracy: 0.8649 - dice_coef_loss: 0.4829\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4883 - accuracy: 0.8635 - dice_coef_loss: 0.4887\n",
      "Epoch 23: loss did not improve from 0.48282\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4883 - accuracy: 0.8635 - dice_coef_loss: 0.4887\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4886 - accuracy: 0.8566 - dice_coef_loss: 0.4886\n",
      "Epoch 24: loss did not improve from 0.48282\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4886 - accuracy: 0.8566 - dice_coef_loss: 0.4886\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4696 - accuracy: 0.8681 - dice_coef_loss: 0.4696\n",
      "Epoch 25: loss improved from 0.48282 to 0.46961, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.4696 - accuracy: 0.8681 - dice_coef_loss: 0.4696\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4792 - accuracy: 0.8642 - dice_coef_loss: 0.4792\n",
      "Epoch 26: loss did not improve from 0.46961\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4792 - accuracy: 0.8642 - dice_coef_loss: 0.4792\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4833 - accuracy: 0.8643 - dice_coef_loss: 0.4833\n",
      "Epoch 27: loss did not improve from 0.46961\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4833 - accuracy: 0.8643 - dice_coef_loss: 0.4833\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4753 - accuracy: 0.8687 - dice_coef_loss: 0.4753\n",
      "Epoch 28: loss did not improve from 0.46961\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4753 - accuracy: 0.8687 - dice_coef_loss: 0.4753\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4721 - accuracy: 0.8745 - dice_coef_loss: 0.4721\n",
      "Epoch 29: loss did not improve from 0.46961\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4721 - accuracy: 0.8745 - dice_coef_loss: 0.4721\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4744 - accuracy: 0.8638 - dice_coef_loss: 0.4750\n",
      "Epoch 30: loss did not improve from 0.46961\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4744 - accuracy: 0.8638 - dice_coef_loss: 0.4750\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4742 - accuracy: 0.8652 - dice_coef_loss: 0.4742\n",
      "Epoch 31: loss did not improve from 0.46961\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4742 - accuracy: 0.8652 - dice_coef_loss: 0.4742\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4717 - accuracy: 0.8702 - dice_coef_loss: 0.4717\n",
      "Epoch 32: loss did not improve from 0.46961\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4717 - accuracy: 0.8702 - dice_coef_loss: 0.4717\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4609 - accuracy: 0.8755 - dice_coef_loss: 0.4609\n",
      "Epoch 33: loss improved from 0.46961 to 0.46090, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4609 - accuracy: 0.8755 - dice_coef_loss: 0.4609\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4714 - accuracy: 0.8683 - dice_coef_loss: 0.4714\n",
      "Epoch 34: loss did not improve from 0.46090\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4714 - accuracy: 0.8683 - dice_coef_loss: 0.4714\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4757 - accuracy: 0.8672 - dice_coef_loss: 0.4757\n",
      "Epoch 35: loss did not improve from 0.46090\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4757 - accuracy: 0.8672 - dice_coef_loss: 0.4757\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4654 - accuracy: 0.8727 - dice_coef_loss: 0.4654\n",
      "Epoch 36: loss did not improve from 0.46090\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4654 - accuracy: 0.8727 - dice_coef_loss: 0.4654\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4665 - accuracy: 0.8734 - dice_coef_loss: 0.4665\n",
      "Epoch 37: loss did not improve from 0.46090\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4665 - accuracy: 0.8734 - dice_coef_loss: 0.4665\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4657 - accuracy: 0.8786 - dice_coef_loss: 0.4661\n",
      "Epoch 38: loss did not improve from 0.46090\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4657 - accuracy: 0.8786 - dice_coef_loss: 0.4661\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4759 - accuracy: 0.8731 - dice_coef_loss: 0.4759\n",
      "Epoch 39: loss did not improve from 0.46090\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4759 - accuracy: 0.8731 - dice_coef_loss: 0.4759\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4588 - accuracy: 0.8771 - dice_coef_loss: 0.4588\n",
      "Epoch 40: loss improved from 0.46090 to 0.45880, saving model to ./temp/polar_Dom/checkpoint.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 27s 266ms/step - loss: 0.4588 - accuracy: 0.8771 - dice_coef_loss: 0.4588\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4630 - accuracy: 0.8703 - dice_coef_loss: 0.4630\n",
      "Epoch 41: loss did not improve from 0.45880\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4630 - accuracy: 0.8703 - dice_coef_loss: 0.4630\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4593 - accuracy: 0.8734 - dice_coef_loss: 0.4593\n",
      "Epoch 42: loss did not improve from 0.45880\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4593 - accuracy: 0.8734 - dice_coef_loss: 0.4593\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4628 - accuracy: 0.8708 - dice_coef_loss: 0.4628\n",
      "Epoch 43: loss did not improve from 0.45880\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4628 - accuracy: 0.8708 - dice_coef_loss: 0.4628\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4639 - accuracy: 0.8804 - dice_coef_loss: 0.4639\n",
      "Epoch 44: loss did not improve from 0.45880\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4639 - accuracy: 0.8804 - dice_coef_loss: 0.4639\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4525 - accuracy: 0.8769 - dice_coef_loss: 0.4530\n",
      "Epoch 45: loss improved from 0.45880 to 0.45246, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.4525 - accuracy: 0.8769 - dice_coef_loss: 0.4530\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4470 - accuracy: 0.8795 - dice_coef_loss: 0.4470\n",
      "Epoch 46: loss improved from 0.45246 to 0.44704, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4470 - accuracy: 0.8795 - dice_coef_loss: 0.4470\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4568 - accuracy: 0.8800 - dice_coef_loss: 0.4568\n",
      "Epoch 47: loss did not improve from 0.44704\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4568 - accuracy: 0.8800 - dice_coef_loss: 0.4568\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4712 - accuracy: 0.8709 - dice_coef_loss: 0.4712\n",
      "Epoch 48: loss did not improve from 0.44704\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4712 - accuracy: 0.8709 - dice_coef_loss: 0.4712\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4513 - accuracy: 0.8796 - dice_coef_loss: 0.4513\n",
      "Epoch 49: loss did not improve from 0.44704\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4513 - accuracy: 0.8796 - dice_coef_loss: 0.4513\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4663 - accuracy: 0.8774 - dice_coef_loss: 0.4663\n",
      "Epoch 50: loss did not improve from 0.44704\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4663 - accuracy: 0.8774 - dice_coef_loss: 0.4663\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4419 - accuracy: 0.8878 - dice_coef_loss: 0.4419\n",
      "Epoch 51: loss improved from 0.44704 to 0.44194, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4419 - accuracy: 0.8878 - dice_coef_loss: 0.4419\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4532 - accuracy: 0.8807 - dice_coef_loss: 0.4537\n",
      "Epoch 52: loss did not improve from 0.44194\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4532 - accuracy: 0.8807 - dice_coef_loss: 0.4537\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4607 - accuracy: 0.8774 - dice_coef_loss: 0.4607\n",
      "Epoch 53: loss did not improve from 0.44194\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4607 - accuracy: 0.8774 - dice_coef_loss: 0.4607\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4556 - accuracy: 0.8772 - dice_coef_loss: 0.4556\n",
      "Epoch 54: loss did not improve from 0.44194\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4556 - accuracy: 0.8772 - dice_coef_loss: 0.4556\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4439 - accuracy: 0.8859 - dice_coef_loss: 0.4439\n",
      "Epoch 55: loss did not improve from 0.44194\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4439 - accuracy: 0.8859 - dice_coef_loss: 0.4439\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4396 - accuracy: 0.8870 - dice_coef_loss: 0.4396\n",
      "Epoch 56: loss improved from 0.44194 to 0.43961, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4396 - accuracy: 0.8870 - dice_coef_loss: 0.4396\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4439 - accuracy: 0.8831 - dice_coef_loss: 0.4439\n",
      "Epoch 57: loss did not improve from 0.43961\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4439 - accuracy: 0.8831 - dice_coef_loss: 0.4439\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4485 - accuracy: 0.8818 - dice_coef_loss: 0.4485\n",
      "Epoch 58: loss did not improve from 0.43961\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4485 - accuracy: 0.8818 - dice_coef_loss: 0.4485\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4454 - accuracy: 0.8879 - dice_coef_loss: 0.4454\n",
      "Epoch 59: loss did not improve from 0.43961\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4454 - accuracy: 0.8879 - dice_coef_loss: 0.4454\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4516 - accuracy: 0.8789 - dice_coef_loss: 0.4517\n",
      "Epoch 60: loss did not improve from 0.43961\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4516 - accuracy: 0.8789 - dice_coef_loss: 0.4517\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4392 - accuracy: 0.8821 - dice_coef_loss: 0.4392\n",
      "Epoch 61: loss improved from 0.43961 to 0.43917, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.4392 - accuracy: 0.8821 - dice_coef_loss: 0.4392\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4454 - accuracy: 0.8797 - dice_coef_loss: 0.4454\n",
      "Epoch 62: loss did not improve from 0.43917\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4454 - accuracy: 0.8797 - dice_coef_loss: 0.4454\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4527 - accuracy: 0.8849 - dice_coef_loss: 0.4527\n",
      "Epoch 63: loss did not improve from 0.43917\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4527 - accuracy: 0.8849 - dice_coef_loss: 0.4527\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4421 - accuracy: 0.8904 - dice_coef_loss: 0.4421\n",
      "Epoch 64: loss did not improve from 0.43917\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4421 - accuracy: 0.8904 - dice_coef_loss: 0.4421\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4428 - accuracy: 0.8854 - dice_coef_loss: 0.4428\n",
      "Epoch 65: loss did not improve from 0.43917\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4428 - accuracy: 0.8854 - dice_coef_loss: 0.4428\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4432 - accuracy: 0.8875 - dice_coef_loss: 0.4432\n",
      "Epoch 66: loss did not improve from 0.43917\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4432 - accuracy: 0.8875 - dice_coef_loss: 0.4432\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4381 - accuracy: 0.8825 - dice_coef_loss: 0.4381\n",
      "Epoch 67: loss improved from 0.43917 to 0.43814, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 0.4381 - accuracy: 0.8825 - dice_coef_loss: 0.4381\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 0.4390 - accuracy: 0.8819 - dice_coef_loss: 0.4390\n",
      "Epoch 68: loss did not improve from 0.43814\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4390 - accuracy: 0.8819 - dice_coef_loss: 0.4390\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4375 - accuracy: 0.8878 - dice_coef_loss: 0.4375\n",
      "Epoch 69: loss improved from 0.43814 to 0.43754, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.4375 - accuracy: 0.8878 - dice_coef_loss: 0.4375\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4491 - accuracy: 0.8812 - dice_coef_loss: 0.4491\n",
      "Epoch 70: loss did not improve from 0.43754\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4491 - accuracy: 0.8812 - dice_coef_loss: 0.4491\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4365 - accuracy: 0.8895 - dice_coef_loss: 0.4365\n",
      "Epoch 71: loss improved from 0.43754 to 0.43649, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.4365 - accuracy: 0.8895 - dice_coef_loss: 0.4365\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4370 - accuracy: 0.8893 - dice_coef_loss: 0.4370\n",
      "Epoch 72: loss did not improve from 0.43649\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4370 - accuracy: 0.8893 - dice_coef_loss: 0.4370\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4406 - accuracy: 0.8843 - dice_coef_loss: 0.4406\n",
      "Epoch 73: loss did not improve from 0.43649\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4406 - accuracy: 0.8843 - dice_coef_loss: 0.4406\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4313 - accuracy: 0.8923 - dice_coef_loss: 0.4313\n",
      "Epoch 74: loss improved from 0.43649 to 0.43125, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.4313 - accuracy: 0.8923 - dice_coef_loss: 0.4313\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4384 - accuracy: 0.8849 - dice_coef_loss: 0.4381\n",
      "Epoch 75: loss did not improve from 0.43125\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4384 - accuracy: 0.8849 - dice_coef_loss: 0.4381\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4269 - accuracy: 0.8912 - dice_coef_loss: 0.4269\n",
      "Epoch 76: loss improved from 0.43125 to 0.42692, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4269 - accuracy: 0.8912 - dice_coef_loss: 0.4269\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4454 - accuracy: 0.8854 - dice_coef_loss: 0.4454\n",
      "Epoch 77: loss did not improve from 0.42692\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4454 - accuracy: 0.8854 - dice_coef_loss: 0.4454\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4381 - accuracy: 0.8850 - dice_coef_loss: 0.4381\n",
      "Epoch 78: loss did not improve from 0.42692\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4381 - accuracy: 0.8850 - dice_coef_loss: 0.4381\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4337 - accuracy: 0.8912 - dice_coef_loss: 0.4337\n",
      "Epoch 79: loss did not improve from 0.42692\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4337 - accuracy: 0.8912 - dice_coef_loss: 0.4337\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4220 - accuracy: 0.8943 - dice_coef_loss: 0.4220\n",
      "Epoch 80: loss improved from 0.42692 to 0.42202, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4220 - accuracy: 0.8943 - dice_coef_loss: 0.4220\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4299 - accuracy: 0.8911 - dice_coef_loss: 0.4299\n",
      "Epoch 81: loss did not improve from 0.42202\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4299 - accuracy: 0.8911 - dice_coef_loss: 0.4299\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4321 - accuracy: 0.8881 - dice_coef_loss: 0.4318\n",
      "Epoch 82: loss did not improve from 0.42202\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4321 - accuracy: 0.8881 - dice_coef_loss: 0.4318\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4363 - accuracy: 0.8875 - dice_coef_loss: 0.4363\n",
      "Epoch 83: loss did not improve from 0.42202\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4363 - accuracy: 0.8875 - dice_coef_loss: 0.4363\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4287 - accuracy: 0.8923 - dice_coef_loss: 0.4287\n",
      "Epoch 84: loss did not improve from 0.42202\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4287 - accuracy: 0.8923 - dice_coef_loss: 0.4287\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4321 - accuracy: 0.8910 - dice_coef_loss: 0.4321\n",
      "Epoch 85: loss did not improve from 0.42202\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4321 - accuracy: 0.8910 - dice_coef_loss: 0.4321\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4272 - accuracy: 0.8953 - dice_coef_loss: 0.4272\n",
      "Epoch 86: loss did not improve from 0.42202\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4272 - accuracy: 0.8953 - dice_coef_loss: 0.4272\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4294 - accuracy: 0.8923 - dice_coef_loss: 0.4294\n",
      "Epoch 87: loss did not improve from 0.42202\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4294 - accuracy: 0.8923 - dice_coef_loss: 0.4294\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4239 - accuracy: 0.8903 - dice_coef_loss: 0.4239\n",
      "Epoch 88: loss did not improve from 0.42202\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4239 - accuracy: 0.8903 - dice_coef_loss: 0.4239\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4270 - accuracy: 0.8911 - dice_coef_loss: 0.4270\n",
      "Epoch 89: loss did not improve from 0.42202\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4270 - accuracy: 0.8911 - dice_coef_loss: 0.4270\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4260 - accuracy: 0.8929 - dice_coef_loss: 0.4260\n",
      "Epoch 90: loss did not improve from 0.42202\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4260 - accuracy: 0.8929 - dice_coef_loss: 0.4260\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4344 - accuracy: 0.8903 - dice_coef_loss: 0.4344\n",
      "Epoch 91: loss did not improve from 0.42202\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4344 - accuracy: 0.8903 - dice_coef_loss: 0.4344\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4196 - accuracy: 0.8934 - dice_coef_loss: 0.4196\n",
      "Epoch 92: loss improved from 0.42202 to 0.41962, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4196 - accuracy: 0.8934 - dice_coef_loss: 0.4196\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4275 - accuracy: 0.8898 - dice_coef_loss: 0.4275\n",
      "Epoch 93: loss did not improve from 0.41962\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4275 - accuracy: 0.8898 - dice_coef_loss: 0.4275\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4243 - accuracy: 0.8928 - dice_coef_loss: 0.4243\n",
      "Epoch 94: loss did not improve from 0.41962\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4243 - accuracy: 0.8928 - dice_coef_loss: 0.4243\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4288 - accuracy: 0.8951 - dice_coef_loss: 0.4288\n",
      "Epoch 95: loss did not improve from 0.41962\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4288 - accuracy: 0.8951 - dice_coef_loss: 0.4288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4273 - accuracy: 0.8923 - dice_coef_loss: 0.4273\n",
      "Epoch 96: loss did not improve from 0.41962\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4273 - accuracy: 0.8923 - dice_coef_loss: 0.4273\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4220 - accuracy: 0.8964 - dice_coef_loss: 0.4220\n",
      "Epoch 97: loss did not improve from 0.41962\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4220 - accuracy: 0.8964 - dice_coef_loss: 0.4220\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4240 - accuracy: 0.8950 - dice_coef_loss: 0.4240\n",
      "Epoch 98: loss did not improve from 0.41962\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4240 - accuracy: 0.8950 - dice_coef_loss: 0.4240\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4295 - accuracy: 0.8936 - dice_coef_loss: 0.4295\n",
      "Epoch 99: loss did not improve from 0.41962\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4295 - accuracy: 0.8936 - dice_coef_loss: 0.4295\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4246 - accuracy: 0.8909 - dice_coef_loss: 0.4246\n",
      "Epoch 100: loss did not improve from 0.41962\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4246 - accuracy: 0.8909 - dice_coef_loss: 0.4246\n",
      "Found 2962 images belonging to 1 classes.\n",
      "Found 2962 images belonging to 1 classes.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f83b4381dd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f83b4381dd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6717 - accuracy: 0.6497 - dice_coef_loss: 0.6717\n",
      "Epoch 1: loss improved from inf to 0.67170, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.6717 - accuracy: 0.6497 - dice_coef_loss: 0.6717\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6023 - accuracy: 0.7774 - dice_coef_loss: 0.6023\n",
      "Epoch 2: loss improved from 0.67170 to 0.60229, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.6023 - accuracy: 0.7774 - dice_coef_loss: 0.6023\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5610 - accuracy: 0.8171 - dice_coef_loss: 0.5610\n",
      "Epoch 3: loss improved from 0.60229 to 0.56098, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.5610 - accuracy: 0.8171 - dice_coef_loss: 0.5610\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5484 - accuracy: 0.8217 - dice_coef_loss: 0.5484\n",
      "Epoch 4: loss improved from 0.56098 to 0.54842, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.5484 - accuracy: 0.8217 - dice_coef_loss: 0.5484\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5512 - accuracy: 0.8258 - dice_coef_loss: 0.5512\n",
      "Epoch 5: loss did not improve from 0.54842\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.5512 - accuracy: 0.8258 - dice_coef_loss: 0.5512\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5284 - accuracy: 0.8407 - dice_coef_loss: 0.5284\n",
      "Epoch 6: loss improved from 0.54842 to 0.52845, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.5284 - accuracy: 0.8407 - dice_coef_loss: 0.5284\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5214 - accuracy: 0.8356 - dice_coef_loss: 0.5214\n",
      "Epoch 7: loss improved from 0.52845 to 0.52137, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.5214 - accuracy: 0.8356 - dice_coef_loss: 0.5214\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5197 - accuracy: 0.8435 - dice_coef_loss: 0.5197\n",
      "Epoch 8: loss improved from 0.52137 to 0.51974, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.5197 - accuracy: 0.8435 - dice_coef_loss: 0.5197\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5199 - accuracy: 0.8423 - dice_coef_loss: 0.5199\n",
      "Epoch 9: loss did not improve from 0.51974\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.5199 - accuracy: 0.8423 - dice_coef_loss: 0.5199\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5086 - accuracy: 0.8456 - dice_coef_loss: 0.5086\n",
      "Epoch 10: loss improved from 0.51974 to 0.50860, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 0.5086 - accuracy: 0.8456 - dice_coef_loss: 0.5086\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5044 - accuracy: 0.8480 - dice_coef_loss: 0.5044\n",
      "Epoch 11: loss improved from 0.50860 to 0.50436, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 0.5044 - accuracy: 0.8480 - dice_coef_loss: 0.5044\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5104 - accuracy: 0.8471 - dice_coef_loss: 0.5104\n",
      "Epoch 12: loss did not improve from 0.50436\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.5104 - accuracy: 0.8471 - dice_coef_loss: 0.5104\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5054 - accuracy: 0.8495 - dice_coef_loss: 0.5054\n",
      "Epoch 13: loss did not improve from 0.50436\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.5054 - accuracy: 0.8495 - dice_coef_loss: 0.5054\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4991 - accuracy: 0.8514 - dice_coef_loss: 0.4991\n",
      "Epoch 14: loss improved from 0.50436 to 0.49911, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4991 - accuracy: 0.8514 - dice_coef_loss: 0.4991\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5004 - accuracy: 0.8530 - dice_coef_loss: 0.5000\n",
      "Epoch 15: loss did not improve from 0.49911\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.5004 - accuracy: 0.8530 - dice_coef_loss: 0.5000\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4965 - accuracy: 0.8552 - dice_coef_loss: 0.4965\n",
      "Epoch 16: loss improved from 0.49911 to 0.49653, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4965 - accuracy: 0.8552 - dice_coef_loss: 0.4965\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4957 - accuracy: 0.8546 - dice_coef_loss: 0.4957\n",
      "Epoch 17: loss improved from 0.49653 to 0.49570, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4957 - accuracy: 0.8546 - dice_coef_loss: 0.4957\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4940 - accuracy: 0.8541 - dice_coef_loss: 0.4940\n",
      "Epoch 18: loss improved from 0.49570 to 0.49404, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 0.4940 - accuracy: 0.8541 - dice_coef_loss: 0.4940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4964 - accuracy: 0.8582 - dice_coef_loss: 0.4964\n",
      "Epoch 19: loss did not improve from 0.49404\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.4964 - accuracy: 0.8582 - dice_coef_loss: 0.4964\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4810 - accuracy: 0.8601 - dice_coef_loss: 0.4810\n",
      "Epoch 20: loss improved from 0.49404 to 0.48101, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4810 - accuracy: 0.8601 - dice_coef_loss: 0.4810\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4813 - accuracy: 0.8637 - dice_coef_loss: 0.4813\n",
      "Epoch 21: loss did not improve from 0.48101\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4813 - accuracy: 0.8637 - dice_coef_loss: 0.4813\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4860 - accuracy: 0.8630 - dice_coef_loss: 0.4860\n",
      "Epoch 22: loss did not improve from 0.48101\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4860 - accuracy: 0.8630 - dice_coef_loss: 0.4860\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4813 - accuracy: 0.8640 - dice_coef_loss: 0.4810\n",
      "Epoch 23: loss did not improve from 0.48101\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4813 - accuracy: 0.8640 - dice_coef_loss: 0.4810\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4840 - accuracy: 0.8615 - dice_coef_loss: 0.4840\n",
      "Epoch 24: loss did not improve from 0.48101\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.4840 - accuracy: 0.8615 - dice_coef_loss: 0.4840\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4702 - accuracy: 0.8707 - dice_coef_loss: 0.4702\n",
      "Epoch 25: loss improved from 0.48101 to 0.47024, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4702 - accuracy: 0.8707 - dice_coef_loss: 0.4702\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4752 - accuracy: 0.8691 - dice_coef_loss: 0.4752\n",
      "Epoch 26: loss did not improve from 0.47024\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.4752 - accuracy: 0.8691 - dice_coef_loss: 0.4752\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4815 - accuracy: 0.8589 - dice_coef_loss: 0.4815\n",
      "Epoch 27: loss did not improve from 0.47024\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.4815 - accuracy: 0.8589 - dice_coef_loss: 0.4815\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4774 - accuracy: 0.8681 - dice_coef_loss: 0.4774\n",
      "Epoch 28: loss did not improve from 0.47024\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.4774 - accuracy: 0.8681 - dice_coef_loss: 0.4774\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4812 - accuracy: 0.8649 - dice_coef_loss: 0.4812\n",
      "Epoch 29: loss did not improve from 0.47024\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4812 - accuracy: 0.8649 - dice_coef_loss: 0.4812\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4749 - accuracy: 0.8720 - dice_coef_loss: 0.4748\n",
      "Epoch 30: loss did not improve from 0.47024\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4749 - accuracy: 0.8720 - dice_coef_loss: 0.4748\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4653 - accuracy: 0.8696 - dice_coef_loss: 0.4653\n",
      "Epoch 31: loss improved from 0.47024 to 0.46534, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4653 - accuracy: 0.8696 - dice_coef_loss: 0.4653\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4765 - accuracy: 0.8643 - dice_coef_loss: 0.4765\n",
      "Epoch 32: loss did not improve from 0.46534\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4765 - accuracy: 0.8643 - dice_coef_loss: 0.4765\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4747 - accuracy: 0.8635 - dice_coef_loss: 0.4747\n",
      "Epoch 33: loss did not improve from 0.46534\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.4747 - accuracy: 0.8635 - dice_coef_loss: 0.4747\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4786 - accuracy: 0.8731 - dice_coef_loss: 0.4786\n",
      "Epoch 34: loss did not improve from 0.46534\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4786 - accuracy: 0.8731 - dice_coef_loss: 0.4786\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4667 - accuracy: 0.8760 - dice_coef_loss: 0.4667\n",
      "Epoch 35: loss did not improve from 0.46534\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4667 - accuracy: 0.8760 - dice_coef_loss: 0.4667\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4650 - accuracy: 0.8672 - dice_coef_loss: 0.4650\n",
      "Epoch 36: loss improved from 0.46534 to 0.46498, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4650 - accuracy: 0.8672 - dice_coef_loss: 0.4650\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4688 - accuracy: 0.8763 - dice_coef_loss: 0.4688\n",
      "Epoch 37: loss did not improve from 0.46498\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4688 - accuracy: 0.8763 - dice_coef_loss: 0.4688\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4655 - accuracy: 0.8684 - dice_coef_loss: 0.4658\n",
      "Epoch 38: loss did not improve from 0.46498\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4655 - accuracy: 0.8684 - dice_coef_loss: 0.4658\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4667 - accuracy: 0.8740 - dice_coef_loss: 0.4667\n",
      "Epoch 39: loss did not improve from 0.46498\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4667 - accuracy: 0.8740 - dice_coef_loss: 0.4667\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4651 - accuracy: 0.8740 - dice_coef_loss: 0.4651\n",
      "Epoch 40: loss did not improve from 0.46498\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.4651 - accuracy: 0.8740 - dice_coef_loss: 0.4651\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4681 - accuracy: 0.8758 - dice_coef_loss: 0.4681\n",
      "Epoch 41: loss did not improve from 0.46498\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4681 - accuracy: 0.8758 - dice_coef_loss: 0.4681\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4585 - accuracy: 0.8788 - dice_coef_loss: 0.4585\n",
      "Epoch 42: loss improved from 0.46498 to 0.45853, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4585 - accuracy: 0.8788 - dice_coef_loss: 0.4585\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4557 - accuracy: 0.8743 - dice_coef_loss: 0.4557\n",
      "Epoch 43: loss improved from 0.45853 to 0.45567, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4557 - accuracy: 0.8743 - dice_coef_loss: 0.4557\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4667 - accuracy: 0.8767 - dice_coef_loss: 0.4667\n",
      "Epoch 44: loss did not improve from 0.45567\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4667 - accuracy: 0.8767 - dice_coef_loss: 0.4667\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4624 - accuracy: 0.8764 - dice_coef_loss: 0.4623\n",
      "Epoch 45: loss did not improve from 0.45567\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4624 - accuracy: 0.8764 - dice_coef_loss: 0.4623\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4630 - accuracy: 0.8835 - dice_coef_loss: 0.4630\n",
      "Epoch 46: loss did not improve from 0.45567\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4630 - accuracy: 0.8835 - dice_coef_loss: 0.4630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4609 - accuracy: 0.8761 - dice_coef_loss: 0.4609\n",
      "Epoch 47: loss did not improve from 0.45567\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4609 - accuracy: 0.8761 - dice_coef_loss: 0.4609\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4535 - accuracy: 0.8781 - dice_coef_loss: 0.4535\n",
      "Epoch 48: loss improved from 0.45567 to 0.45349, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4535 - accuracy: 0.8781 - dice_coef_loss: 0.4535\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4557 - accuracy: 0.8798 - dice_coef_loss: 0.4557\n",
      "Epoch 49: loss did not improve from 0.45349\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.4557 - accuracy: 0.8798 - dice_coef_loss: 0.4557\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4546 - accuracy: 0.8771 - dice_coef_loss: 0.4546\n",
      "Epoch 50: loss did not improve from 0.45349\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.4546 - accuracy: 0.8771 - dice_coef_loss: 0.4546\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4519 - accuracy: 0.8823 - dice_coef_loss: 0.4519\n",
      "Epoch 51: loss improved from 0.45349 to 0.45190, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4519 - accuracy: 0.8823 - dice_coef_loss: 0.4519\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4517 - accuracy: 0.8767 - dice_coef_loss: 0.4517\n",
      "Epoch 52: loss improved from 0.45190 to 0.45172, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.4517 - accuracy: 0.8767 - dice_coef_loss: 0.4517\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4517 - accuracy: 0.8816 - dice_coef_loss: 0.4517\n",
      "Epoch 53: loss improved from 0.45172 to 0.45166, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4517 - accuracy: 0.8816 - dice_coef_loss: 0.4517\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4526 - accuracy: 0.8798 - dice_coef_loss: 0.4526\n",
      "Epoch 54: loss did not improve from 0.45166\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.4526 - accuracy: 0.8798 - dice_coef_loss: 0.4526\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4515 - accuracy: 0.8838 - dice_coef_loss: 0.4515\n",
      "Epoch 55: loss improved from 0.45166 to 0.45147, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4515 - accuracy: 0.8838 - dice_coef_loss: 0.4515\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4539 - accuracy: 0.8763 - dice_coef_loss: 0.4539\n",
      "Epoch 56: loss did not improve from 0.45147\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.4539 - accuracy: 0.8763 - dice_coef_loss: 0.4539\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4503 - accuracy: 0.8825 - dice_coef_loss: 0.4503\n",
      "Epoch 57: loss improved from 0.45147 to 0.45027, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4503 - accuracy: 0.8825 - dice_coef_loss: 0.4503\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4464 - accuracy: 0.8873 - dice_coef_loss: 0.4464\n",
      "Epoch 58: loss improved from 0.45027 to 0.44641, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4464 - accuracy: 0.8873 - dice_coef_loss: 0.4464\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4483 - accuracy: 0.8819 - dice_coef_loss: 0.4483\n",
      "Epoch 59: loss did not improve from 0.44641\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.4483 - accuracy: 0.8819 - dice_coef_loss: 0.4483\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4519 - accuracy: 0.8819 - dice_coef_loss: 0.4520\n",
      "Epoch 60: loss did not improve from 0.44641\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4519 - accuracy: 0.8819 - dice_coef_loss: 0.4520\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4395 - accuracy: 0.8820 - dice_coef_loss: 0.4395\n",
      "Epoch 61: loss improved from 0.44641 to 0.43952, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4395 - accuracy: 0.8820 - dice_coef_loss: 0.4395\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4448 - accuracy: 0.8849 - dice_coef_loss: 0.4448\n",
      "Epoch 62: loss did not improve from 0.43952\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.4448 - accuracy: 0.8849 - dice_coef_loss: 0.4448\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4502 - accuracy: 0.8822 - dice_coef_loss: 0.4502\n",
      "Epoch 63: loss did not improve from 0.43952\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.4502 - accuracy: 0.8822 - dice_coef_loss: 0.4502\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4436 - accuracy: 0.8900 - dice_coef_loss: 0.4436\n",
      "Epoch 64: loss did not improve from 0.43952\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.4436 - accuracy: 0.8900 - dice_coef_loss: 0.4436\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4324 - accuracy: 0.8894 - dice_coef_loss: 0.4324\n",
      "Epoch 65: loss improved from 0.43952 to 0.43244, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4324 - accuracy: 0.8894 - dice_coef_loss: 0.4324\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4490 - accuracy: 0.8842 - dice_coef_loss: 0.4490\n",
      "Epoch 66: loss did not improve from 0.43244\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.4490 - accuracy: 0.8842 - dice_coef_loss: 0.4490\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4450 - accuracy: 0.8847 - dice_coef_loss: 0.4452\n",
      "Epoch 67: loss did not improve from 0.43244\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4450 - accuracy: 0.8847 - dice_coef_loss: 0.4452\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4436 - accuracy: 0.8854 - dice_coef_loss: 0.4436\n",
      "Epoch 68: loss did not improve from 0.43244\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.4436 - accuracy: 0.8854 - dice_coef_loss: 0.4436\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4424 - accuracy: 0.8867 - dice_coef_loss: 0.4424\n",
      "Epoch 69: loss did not improve from 0.43244\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.4424 - accuracy: 0.8867 - dice_coef_loss: 0.4424\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4496 - accuracy: 0.8827 - dice_coef_loss: 0.4496\n",
      "Epoch 70: loss did not improve from 0.43244\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.4496 - accuracy: 0.8827 - dice_coef_loss: 0.4496\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4338 - accuracy: 0.8872 - dice_coef_loss: 0.4338\n",
      "Epoch 71: loss did not improve from 0.43244\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.4338 - accuracy: 0.8872 - dice_coef_loss: 0.4338\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4406 - accuracy: 0.8871 - dice_coef_loss: 0.4406\n",
      "Epoch 72: loss did not improve from 0.43244\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.4406 - accuracy: 0.8871 - dice_coef_loss: 0.4406\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4318 - accuracy: 0.8930 - dice_coef_loss: 0.4318\n",
      "Epoch 73: loss improved from 0.43244 to 0.43180, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4318 - accuracy: 0.8930 - dice_coef_loss: 0.4318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4363 - accuracy: 0.8876 - dice_coef_loss: 0.4363\n",
      "Epoch 74: loss did not improve from 0.43180\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4363 - accuracy: 0.8876 - dice_coef_loss: 0.4363\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4330 - accuracy: 0.8933 - dice_coef_loss: 0.4330\n",
      "Epoch 75: loss did not improve from 0.43180\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4330 - accuracy: 0.8933 - dice_coef_loss: 0.4330\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4341 - accuracy: 0.8890 - dice_coef_loss: 0.4341\n",
      "Epoch 76: loss did not improve from 0.43180\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4341 - accuracy: 0.8890 - dice_coef_loss: 0.4341\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4397 - accuracy: 0.8880 - dice_coef_loss: 0.4397\n",
      "Epoch 77: loss did not improve from 0.43180\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.4397 - accuracy: 0.8880 - dice_coef_loss: 0.4397\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4377 - accuracy: 0.8881 - dice_coef_loss: 0.4377\n",
      "Epoch 78: loss did not improve from 0.43180\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.4377 - accuracy: 0.8881 - dice_coef_loss: 0.4377\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4385 - accuracy: 0.8830 - dice_coef_loss: 0.4385\n",
      "Epoch 79: loss did not improve from 0.43180\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.4385 - accuracy: 0.8830 - dice_coef_loss: 0.4385\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4318 - accuracy: 0.8890 - dice_coef_loss: 0.4318\n",
      "Epoch 80: loss did not improve from 0.43180\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4318 - accuracy: 0.8890 - dice_coef_loss: 0.4318\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4303 - accuracy: 0.8927 - dice_coef_loss: 0.4303\n",
      "Epoch 81: loss improved from 0.43180 to 0.43030, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4303 - accuracy: 0.8927 - dice_coef_loss: 0.4303\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4257 - accuracy: 0.8918 - dice_coef_loss: 0.4254\n",
      "Epoch 82: loss improved from 0.43030 to 0.42569, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.4257 - accuracy: 0.8918 - dice_coef_loss: 0.4254\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4319 - accuracy: 0.8922 - dice_coef_loss: 0.4319\n",
      "Epoch 83: loss did not improve from 0.42569\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4319 - accuracy: 0.8922 - dice_coef_loss: 0.4319\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4333 - accuracy: 0.8912 - dice_coef_loss: 0.4333\n",
      "Epoch 84: loss did not improve from 0.42569\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4333 - accuracy: 0.8912 - dice_coef_loss: 0.4333\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4331 - accuracy: 0.8909 - dice_coef_loss: 0.4331\n",
      "Epoch 85: loss did not improve from 0.42569\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4331 - accuracy: 0.8909 - dice_coef_loss: 0.4331\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4302 - accuracy: 0.8930 - dice_coef_loss: 0.4302\n",
      "Epoch 86: loss did not improve from 0.42569\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.4302 - accuracy: 0.8930 - dice_coef_loss: 0.4302\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4234 - accuracy: 0.8900 - dice_coef_loss: 0.4234\n",
      "Epoch 87: loss improved from 0.42569 to 0.42340, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4234 - accuracy: 0.8900 - dice_coef_loss: 0.4234\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4314 - accuracy: 0.8883 - dice_coef_loss: 0.4314\n",
      "Epoch 88: loss did not improve from 0.42340\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4314 - accuracy: 0.8883 - dice_coef_loss: 0.4314\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4322 - accuracy: 0.8951 - dice_coef_loss: 0.4320\n",
      "Epoch 89: loss did not improve from 0.42340\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4322 - accuracy: 0.8951 - dice_coef_loss: 0.4320\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4319 - accuracy: 0.8903 - dice_coef_loss: 0.4319\n",
      "Epoch 90: loss did not improve from 0.42340\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4319 - accuracy: 0.8903 - dice_coef_loss: 0.4319\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4321 - accuracy: 0.8965 - dice_coef_loss: 0.4321\n",
      "Epoch 91: loss did not improve from 0.42340\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4321 - accuracy: 0.8965 - dice_coef_loss: 0.4321\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4297 - accuracy: 0.8913 - dice_coef_loss: 0.4297\n",
      "Epoch 92: loss did not improve from 0.42340\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4297 - accuracy: 0.8913 - dice_coef_loss: 0.4297\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4275 - accuracy: 0.8925 - dice_coef_loss: 0.4275\n",
      "Epoch 93: loss did not improve from 0.42340\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.4275 - accuracy: 0.8925 - dice_coef_loss: 0.4275\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4161 - accuracy: 0.8950 - dice_coef_loss: 0.4161\n",
      "Epoch 94: loss improved from 0.42340 to 0.41610, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4161 - accuracy: 0.8950 - dice_coef_loss: 0.4161\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4209 - accuracy: 0.8953 - dice_coef_loss: 0.4209\n",
      "Epoch 95: loss did not improve from 0.41610\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.4209 - accuracy: 0.8953 - dice_coef_loss: 0.4209\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4230 - accuracy: 0.8946 - dice_coef_loss: 0.4230\n",
      "Epoch 96: loss did not improve from 0.41610\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4230 - accuracy: 0.8946 - dice_coef_loss: 0.4230\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4172 - accuracy: 0.8947 - dice_coef_loss: 0.4170\n",
      "Epoch 97: loss did not improve from 0.41610\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4172 - accuracy: 0.8947 - dice_coef_loss: 0.4170\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4267 - accuracy: 0.8937 - dice_coef_loss: 0.4267\n",
      "Epoch 98: loss did not improve from 0.41610\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4267 - accuracy: 0.8937 - dice_coef_loss: 0.4267\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4205 - accuracy: 0.8997 - dice_coef_loss: 0.4205\n",
      "Epoch 99: loss did not improve from 0.41610\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.4205 - accuracy: 0.8997 - dice_coef_loss: 0.4205\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4246 - accuracy: 0.8937 - dice_coef_loss: 0.4246\n",
      "Epoch 100: loss did not improve from 0.41610\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4246 - accuracy: 0.8937 - dice_coef_loss: 0.4246\n",
      "Found 2962 images belonging to 1 classes.\n",
      "Found 2962 images belonging to 1 classes.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f83b59ae3b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f83b59ae3b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6861 - accuracy: 0.6190 - dice_coef_loss: 0.6861\n",
      "Epoch 1: loss improved from inf to 0.68612, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 28s 267ms/step - loss: 0.6861 - accuracy: 0.6190 - dice_coef_loss: 0.6861\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6192 - accuracy: 0.7528 - dice_coef_loss: 0.6192\n",
      "Epoch 2: loss improved from 0.68612 to 0.61918, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.6192 - accuracy: 0.7528 - dice_coef_loss: 0.6192\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5727 - accuracy: 0.7968 - dice_coef_loss: 0.5727\n",
      "Epoch 3: loss improved from 0.61918 to 0.57269, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.5727 - accuracy: 0.7968 - dice_coef_loss: 0.5727\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5495 - accuracy: 0.8237 - dice_coef_loss: 0.5495\n",
      "Epoch 4: loss improved from 0.57269 to 0.54945, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.5495 - accuracy: 0.8237 - dice_coef_loss: 0.5495\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5491 - accuracy: 0.8363 - dice_coef_loss: 0.5491\n",
      "Epoch 5: loss improved from 0.54945 to 0.54905, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 0.5491 - accuracy: 0.8363 - dice_coef_loss: 0.5491\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5377 - accuracy: 0.8363 - dice_coef_loss: 0.5377\n",
      "Epoch 6: loss improved from 0.54905 to 0.53772, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.5377 - accuracy: 0.8363 - dice_coef_loss: 0.5377\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5335 - accuracy: 0.8338 - dice_coef_loss: 0.5335\n",
      "Epoch 7: loss improved from 0.53772 to 0.53351, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.5335 - accuracy: 0.8338 - dice_coef_loss: 0.5335\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5144 - accuracy: 0.8430 - dice_coef_loss: 0.5151\n",
      "Epoch 8: loss improved from 0.53351 to 0.51442, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.5144 - accuracy: 0.8430 - dice_coef_loss: 0.5151\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5232 - accuracy: 0.8416 - dice_coef_loss: 0.5232\n",
      "Epoch 9: loss did not improve from 0.51442\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.5232 - accuracy: 0.8416 - dice_coef_loss: 0.5232\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5123 - accuracy: 0.8448 - dice_coef_loss: 0.5123\n",
      "Epoch 10: loss improved from 0.51442 to 0.51228, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.5123 - accuracy: 0.8448 - dice_coef_loss: 0.5123\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4964 - accuracy: 0.8537 - dice_coef_loss: 0.4964\n",
      "Epoch 11: loss improved from 0.51228 to 0.49636, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 0.4964 - accuracy: 0.8537 - dice_coef_loss: 0.4964\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5090 - accuracy: 0.8446 - dice_coef_loss: 0.5090\n",
      "Epoch 12: loss did not improve from 0.49636\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.5090 - accuracy: 0.8446 - dice_coef_loss: 0.5090\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5015 - accuracy: 0.8579 - dice_coef_loss: 0.5015\n",
      "Epoch 13: loss did not improve from 0.49636\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.5015 - accuracy: 0.8579 - dice_coef_loss: 0.5015\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5006 - accuracy: 0.8554 - dice_coef_loss: 0.5006\n",
      "Epoch 14: loss did not improve from 0.49636\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.5006 - accuracy: 0.8554 - dice_coef_loss: 0.5006\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5046 - accuracy: 0.8534 - dice_coef_loss: 0.5049\n",
      "Epoch 15: loss did not improve from 0.49636\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.5046 - accuracy: 0.8534 - dice_coef_loss: 0.5049\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4942 - accuracy: 0.8542 - dice_coef_loss: 0.4942\n",
      "Epoch 16: loss improved from 0.49636 to 0.49422, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4942 - accuracy: 0.8542 - dice_coef_loss: 0.4942\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4985 - accuracy: 0.8596 - dice_coef_loss: 0.4985\n",
      "Epoch 17: loss did not improve from 0.49422\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4985 - accuracy: 0.8596 - dice_coef_loss: 0.4985\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4980 - accuracy: 0.8586 - dice_coef_loss: 0.4980\n",
      "Epoch 18: loss did not improve from 0.49422\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4980 - accuracy: 0.8586 - dice_coef_loss: 0.4980\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4949 - accuracy: 0.8604 - dice_coef_loss: 0.4949\n",
      "Epoch 19: loss did not improve from 0.49422\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4949 - accuracy: 0.8604 - dice_coef_loss: 0.4949\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4823 - accuracy: 0.8604 - dice_coef_loss: 0.4823\n",
      "Epoch 20: loss improved from 0.49422 to 0.48231, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.4823 - accuracy: 0.8604 - dice_coef_loss: 0.4823\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4814 - accuracy: 0.8648 - dice_coef_loss: 0.4814\n",
      "Epoch 21: loss improved from 0.48231 to 0.48139, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 0.4814 - accuracy: 0.8648 - dice_coef_loss: 0.4814\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4721 - accuracy: 0.8682 - dice_coef_loss: 0.4721\n",
      "Epoch 22: loss improved from 0.48139 to 0.47205, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.4721 - accuracy: 0.8682 - dice_coef_loss: 0.4721\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4889 - accuracy: 0.8637 - dice_coef_loss: 0.4894\n",
      "Epoch 23: loss did not improve from 0.47205\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.4889 - accuracy: 0.8637 - dice_coef_loss: 0.4894\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4820 - accuracy: 0.8692 - dice_coef_loss: 0.4820\n",
      "Epoch 24: loss did not improve from 0.47205\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4820 - accuracy: 0.8692 - dice_coef_loss: 0.4820\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4700 - accuracy: 0.8696 - dice_coef_loss: 0.4700\n",
      "Epoch 25: loss improved from 0.47205 to 0.47001, saving model to ./temp/polar_Dom/checkpoint.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 27s 266ms/step - loss: 0.4700 - accuracy: 0.8696 - dice_coef_loss: 0.4700\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4799 - accuracy: 0.8684 - dice_coef_loss: 0.4799\n",
      "Epoch 26: loss did not improve from 0.47001\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4799 - accuracy: 0.8684 - dice_coef_loss: 0.4799\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4746 - accuracy: 0.8690 - dice_coef_loss: 0.4746\n",
      "Epoch 27: loss did not improve from 0.47001\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4746 - accuracy: 0.8690 - dice_coef_loss: 0.4746\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4803 - accuracy: 0.8643 - dice_coef_loss: 0.4803\n",
      "Epoch 28: loss did not improve from 0.47001\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4803 - accuracy: 0.8643 - dice_coef_loss: 0.4803\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4765 - accuracy: 0.8681 - dice_coef_loss: 0.4765\n",
      "Epoch 29: loss did not improve from 0.47001\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4765 - accuracy: 0.8681 - dice_coef_loss: 0.4765\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4691 - accuracy: 0.8712 - dice_coef_loss: 0.4689\n",
      "Epoch 30: loss improved from 0.47001 to 0.46907, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 26s 265ms/step - loss: 0.4691 - accuracy: 0.8712 - dice_coef_loss: 0.4689\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4652 - accuracy: 0.8733 - dice_coef_loss: 0.4652\n",
      "Epoch 31: loss improved from 0.46907 to 0.46518, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4652 - accuracy: 0.8733 - dice_coef_loss: 0.4652\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4590 - accuracy: 0.8774 - dice_coef_loss: 0.4590\n",
      "Epoch 32: loss improved from 0.46518 to 0.45902, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.4590 - accuracy: 0.8774 - dice_coef_loss: 0.4590\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4657 - accuracy: 0.8709 - dice_coef_loss: 0.4657\n",
      "Epoch 33: loss did not improve from 0.45902\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4657 - accuracy: 0.8709 - dice_coef_loss: 0.4657\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4736 - accuracy: 0.8722 - dice_coef_loss: 0.4736\n",
      "Epoch 34: loss did not improve from 0.45902\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4736 - accuracy: 0.8722 - dice_coef_loss: 0.4736\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4746 - accuracy: 0.8658 - dice_coef_loss: 0.4746\n",
      "Epoch 35: loss did not improve from 0.45902\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4746 - accuracy: 0.8658 - dice_coef_loss: 0.4746\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4645 - accuracy: 0.8763 - dice_coef_loss: 0.4645\n",
      "Epoch 36: loss did not improve from 0.45902\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4645 - accuracy: 0.8763 - dice_coef_loss: 0.4645\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4769 - accuracy: 0.8698 - dice_coef_loss: 0.4769\n",
      "Epoch 37: loss did not improve from 0.45902\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4769 - accuracy: 0.8698 - dice_coef_loss: 0.4769\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4738 - accuracy: 0.8719 - dice_coef_loss: 0.4735\n",
      "Epoch 38: loss did not improve from 0.45902\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.4738 - accuracy: 0.8719 - dice_coef_loss: 0.4735\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4675 - accuracy: 0.8780 - dice_coef_loss: 0.4675\n",
      "Epoch 39: loss did not improve from 0.45902\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4675 - accuracy: 0.8780 - dice_coef_loss: 0.4675\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4594 - accuracy: 0.8768 - dice_coef_loss: 0.4594\n",
      "Epoch 40: loss did not improve from 0.45902\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4594 - accuracy: 0.8768 - dice_coef_loss: 0.4594\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4623 - accuracy: 0.8724 - dice_coef_loss: 0.4623\n",
      "Epoch 41: loss did not improve from 0.45902\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4623 - accuracy: 0.8724 - dice_coef_loss: 0.4623\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4546 - accuracy: 0.8759 - dice_coef_loss: 0.4546\n",
      "Epoch 42: loss improved from 0.45902 to 0.45456, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.4546 - accuracy: 0.8759 - dice_coef_loss: 0.4546\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4679 - accuracy: 0.8716 - dice_coef_loss: 0.4679\n",
      "Epoch 43: loss did not improve from 0.45456\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4679 - accuracy: 0.8716 - dice_coef_loss: 0.4679\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4606 - accuracy: 0.8857 - dice_coef_loss: 0.4606\n",
      "Epoch 44: loss did not improve from 0.45456\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4606 - accuracy: 0.8857 - dice_coef_loss: 0.4606\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4639 - accuracy: 0.8742 - dice_coef_loss: 0.4639\n",
      "Epoch 45: loss did not improve from 0.45456\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.4639 - accuracy: 0.8742 - dice_coef_loss: 0.4639\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4558 - accuracy: 0.8787 - dice_coef_loss: 0.4558\n",
      "Epoch 46: loss did not improve from 0.45456\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4558 - accuracy: 0.8787 - dice_coef_loss: 0.4558\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4597 - accuracy: 0.8723 - dice_coef_loss: 0.4597\n",
      "Epoch 47: loss did not improve from 0.45456\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4597 - accuracy: 0.8723 - dice_coef_loss: 0.4597\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4519 - accuracy: 0.8820 - dice_coef_loss: 0.4519\n",
      "Epoch 48: loss improved from 0.45456 to 0.45185, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.4519 - accuracy: 0.8820 - dice_coef_loss: 0.4519\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4513 - accuracy: 0.8851 - dice_coef_loss: 0.4513\n",
      "Epoch 49: loss improved from 0.45185 to 0.45126, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.4513 - accuracy: 0.8851 - dice_coef_loss: 0.4513\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4539 - accuracy: 0.8811 - dice_coef_loss: 0.4539\n",
      "Epoch 50: loss did not improve from 0.45126\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4539 - accuracy: 0.8811 - dice_coef_loss: 0.4539\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4529 - accuracy: 0.8827 - dice_coef_loss: 0.4529\n",
      "Epoch 51: loss did not improve from 0.45126\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4529 - accuracy: 0.8827 - dice_coef_loss: 0.4529\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4564 - accuracy: 0.8808 - dice_coef_loss: 0.4562\n",
      "Epoch 52: loss did not improve from 0.45126\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.4564 - accuracy: 0.8808 - dice_coef_loss: 0.4562\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 0.4605 - accuracy: 0.8757 - dice_coef_loss: 0.4605\n",
      "Epoch 53: loss did not improve from 0.45126\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4605 - accuracy: 0.8757 - dice_coef_loss: 0.4605\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4434 - accuracy: 0.8855 - dice_coef_loss: 0.4434\n",
      "Epoch 54: loss improved from 0.45126 to 0.44344, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.4434 - accuracy: 0.8855 - dice_coef_loss: 0.4434\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4399 - accuracy: 0.8866 - dice_coef_loss: 0.4399\n",
      "Epoch 55: loss improved from 0.44344 to 0.43989, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4399 - accuracy: 0.8866 - dice_coef_loss: 0.4399\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4516 - accuracy: 0.8803 - dice_coef_loss: 0.4516\n",
      "Epoch 56: loss did not improve from 0.43989\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4516 - accuracy: 0.8803 - dice_coef_loss: 0.4516\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4540 - accuracy: 0.8838 - dice_coef_loss: 0.4540\n",
      "Epoch 57: loss did not improve from 0.43989\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4540 - accuracy: 0.8838 - dice_coef_loss: 0.4540\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4436 - accuracy: 0.8888 - dice_coef_loss: 0.4436\n",
      "Epoch 58: loss did not improve from 0.43989\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4436 - accuracy: 0.8888 - dice_coef_loss: 0.4436\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4459 - accuracy: 0.8848 - dice_coef_loss: 0.4459\n",
      "Epoch 59: loss did not improve from 0.43989\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4459 - accuracy: 0.8848 - dice_coef_loss: 0.4459\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4574 - accuracy: 0.8799 - dice_coef_loss: 0.4572\n",
      "Epoch 60: loss did not improve from 0.43989\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.4574 - accuracy: 0.8799 - dice_coef_loss: 0.4572\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4487 - accuracy: 0.8841 - dice_coef_loss: 0.4487\n",
      "Epoch 61: loss did not improve from 0.43989\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4487 - accuracy: 0.8841 - dice_coef_loss: 0.4487\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4378 - accuracy: 0.8874 - dice_coef_loss: 0.4378\n",
      "Epoch 62: loss improved from 0.43989 to 0.43780, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4378 - accuracy: 0.8874 - dice_coef_loss: 0.4378\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4431 - accuracy: 0.8845 - dice_coef_loss: 0.4431\n",
      "Epoch 63: loss did not improve from 0.43780\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4431 - accuracy: 0.8845 - dice_coef_loss: 0.4431\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4405 - accuracy: 0.8909 - dice_coef_loss: 0.4405\n",
      "Epoch 64: loss did not improve from 0.43780\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4405 - accuracy: 0.8909 - dice_coef_loss: 0.4405\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4427 - accuracy: 0.8897 - dice_coef_loss: 0.4427\n",
      "Epoch 65: loss did not improve from 0.43780\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4427 - accuracy: 0.8897 - dice_coef_loss: 0.4427\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4496 - accuracy: 0.8802 - dice_coef_loss: 0.4496\n",
      "Epoch 66: loss did not improve from 0.43780\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4496 - accuracy: 0.8802 - dice_coef_loss: 0.4496\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4391 - accuracy: 0.8838 - dice_coef_loss: 0.4393\n",
      "Epoch 67: loss did not improve from 0.43780\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.4391 - accuracy: 0.8838 - dice_coef_loss: 0.4393\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4457 - accuracy: 0.8852 - dice_coef_loss: 0.4457\n",
      "Epoch 68: loss did not improve from 0.43780\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4457 - accuracy: 0.8852 - dice_coef_loss: 0.4457\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4366 - accuracy: 0.8825 - dice_coef_loss: 0.4366\n",
      "Epoch 69: loss improved from 0.43780 to 0.43664, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4366 - accuracy: 0.8825 - dice_coef_loss: 0.4366\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4461 - accuracy: 0.8849 - dice_coef_loss: 0.4461\n",
      "Epoch 70: loss did not improve from 0.43664\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4461 - accuracy: 0.8849 - dice_coef_loss: 0.4461\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4358 - accuracy: 0.8850 - dice_coef_loss: 0.4358\n",
      "Epoch 71: loss improved from 0.43664 to 0.43581, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.4358 - accuracy: 0.8850 - dice_coef_loss: 0.4358\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4360 - accuracy: 0.8919 - dice_coef_loss: 0.4360\n",
      "Epoch 72: loss did not improve from 0.43581\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4360 - accuracy: 0.8919 - dice_coef_loss: 0.4360\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4424 - accuracy: 0.8848 - dice_coef_loss: 0.4424\n",
      "Epoch 73: loss did not improve from 0.43581\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4424 - accuracy: 0.8848 - dice_coef_loss: 0.4424\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4381 - accuracy: 0.8892 - dice_coef_loss: 0.4381\n",
      "Epoch 74: loss did not improve from 0.43581\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4381 - accuracy: 0.8892 - dice_coef_loss: 0.4381\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4399 - accuracy: 0.8873 - dice_coef_loss: 0.4396\n",
      "Epoch 75: loss did not improve from 0.43581\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4399 - accuracy: 0.8873 - dice_coef_loss: 0.4396\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4389 - accuracy: 0.8908 - dice_coef_loss: 0.4389\n",
      "Epoch 76: loss did not improve from 0.43581\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4389 - accuracy: 0.8908 - dice_coef_loss: 0.4389\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4357 - accuracy: 0.8874 - dice_coef_loss: 0.4357\n",
      "Epoch 77: loss improved from 0.43581 to 0.43574, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.4357 - accuracy: 0.8874 - dice_coef_loss: 0.4357\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4381 - accuracy: 0.8850 - dice_coef_loss: 0.4381\n",
      "Epoch 78: loss did not improve from 0.43574\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4381 - accuracy: 0.8850 - dice_coef_loss: 0.4381\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4310 - accuracy: 0.8936 - dice_coef_loss: 0.4310\n",
      "Epoch 79: loss improved from 0.43574 to 0.43101, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.4310 - accuracy: 0.8936 - dice_coef_loss: 0.4310\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4273 - accuracy: 0.8938 - dice_coef_loss: 0.4273\n",
      "Epoch 80: loss improved from 0.43101 to 0.42728, saving model to ./temp/polar_Dom/checkpoint.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 27s 266ms/step - loss: 0.4273 - accuracy: 0.8938 - dice_coef_loss: 0.4273\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4362 - accuracy: 0.8861 - dice_coef_loss: 0.4362\n",
      "Epoch 81: loss did not improve from 0.42728\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4362 - accuracy: 0.8861 - dice_coef_loss: 0.4362\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4342 - accuracy: 0.8861 - dice_coef_loss: 0.4343\n",
      "Epoch 82: loss did not improve from 0.42728\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.4342 - accuracy: 0.8861 - dice_coef_loss: 0.4343\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4268 - accuracy: 0.8934 - dice_coef_loss: 0.4268\n",
      "Epoch 83: loss improved from 0.42728 to 0.42684, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.4268 - accuracy: 0.8934 - dice_coef_loss: 0.4268\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4329 - accuracy: 0.8910 - dice_coef_loss: 0.4329\n",
      "Epoch 84: loss did not improve from 0.42684\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4329 - accuracy: 0.8910 - dice_coef_loss: 0.4329\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4314 - accuracy: 0.8911 - dice_coef_loss: 0.4314\n",
      "Epoch 85: loss did not improve from 0.42684\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4314 - accuracy: 0.8911 - dice_coef_loss: 0.4314\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4336 - accuracy: 0.8918 - dice_coef_loss: 0.4336\n",
      "Epoch 86: loss did not improve from 0.42684\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4336 - accuracy: 0.8918 - dice_coef_loss: 0.4336\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4239 - accuracy: 0.8922 - dice_coef_loss: 0.4239\n",
      "Epoch 87: loss improved from 0.42684 to 0.42386, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.4239 - accuracy: 0.8922 - dice_coef_loss: 0.4239\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4254 - accuracy: 0.8940 - dice_coef_loss: 0.4254\n",
      "Epoch 88: loss did not improve from 0.42386\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4254 - accuracy: 0.8940 - dice_coef_loss: 0.4254\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4337 - accuracy: 0.8927 - dice_coef_loss: 0.4334\n",
      "Epoch 89: loss did not improve from 0.42386\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.4337 - accuracy: 0.8927 - dice_coef_loss: 0.4334\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4294 - accuracy: 0.8935 - dice_coef_loss: 0.4294\n",
      "Epoch 90: loss did not improve from 0.42386\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4294 - accuracy: 0.8935 - dice_coef_loss: 0.4294\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4279 - accuracy: 0.8909 - dice_coef_loss: 0.4279\n",
      "Epoch 91: loss did not improve from 0.42386\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4279 - accuracy: 0.8909 - dice_coef_loss: 0.4279\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4255 - accuracy: 0.8978 - dice_coef_loss: 0.4255\n",
      "Epoch 92: loss did not improve from 0.42386\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4255 - accuracy: 0.8978 - dice_coef_loss: 0.4255\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4229 - accuracy: 0.8920 - dice_coef_loss: 0.4229\n",
      "Epoch 93: loss improved from 0.42386 to 0.42294, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.4229 - accuracy: 0.8920 - dice_coef_loss: 0.4229\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4311 - accuracy: 0.8946 - dice_coef_loss: 0.4311\n",
      "Epoch 94: loss did not improve from 0.42294\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4311 - accuracy: 0.8946 - dice_coef_loss: 0.4311\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4223 - accuracy: 0.8943 - dice_coef_loss: 0.4223\n",
      "Epoch 95: loss improved from 0.42294 to 0.42232, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4223 - accuracy: 0.8943 - dice_coef_loss: 0.4223\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4223 - accuracy: 0.8949 - dice_coef_loss: 0.4223\n",
      "Epoch 96: loss improved from 0.42232 to 0.42229, saving model to ./temp/polar_Dom/checkpoint.hdf5\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4223 - accuracy: 0.8949 - dice_coef_loss: 0.4223\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4225 - accuracy: 0.8975 - dice_coef_loss: 0.4224\n",
      "Epoch 97: loss did not improve from 0.42229\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.4225 - accuracy: 0.8975 - dice_coef_loss: 0.4224\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4249 - accuracy: 0.8952 - dice_coef_loss: 0.4249\n",
      "Epoch 98: loss did not improve from 0.42229\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4249 - accuracy: 0.8952 - dice_coef_loss: 0.4249\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4270 - accuracy: 0.8962 - dice_coef_loss: 0.4270\n",
      "Epoch 99: loss did not improve from 0.42229\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.4270 - accuracy: 0.8962 - dice_coef_loss: 0.4270\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4227 - accuracy: 0.8939 - dice_coef_loss: 0.4227\n",
      "Epoch 100: loss did not improve from 0.42229\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4227 - accuracy: 0.8939 - dice_coef_loss: 0.4227\n"
     ]
    }
   ],
   "source": [
    "working_mother_folder = PARAM_PATH_TEMP_POLAR\n",
    "batch_size = 4\n",
    "PARAM_BETA_TEST_NUM = 6\n",
    "data_gen_args = dict(rotation_range = 80,      # TODO: improve the data augmentation\n",
    "                width_shift_range =0.02,\n",
    "                height_shift_range =0.02,\n",
    "                shear_range = 0.35,\n",
    "                zoom_range = 0.075,\n",
    "                horizontal_flip = True,\n",
    "                fill_mode = 'nearest',\n",
    "                rescale = 1./255)\n",
    "score = []\n",
    "for i in range(K):\n",
    "    working_test_folder_i = os.path.join(working_mother_folder, str(i), PARAM_SUB_FOLDER_POLAR)\n",
    "    temp_folder_path = os.path.join(working_mother_folder,'temp')\n",
    "    os.mkdir(temp_folder_path)\n",
    "    for j in range(K):\n",
    "        if i != j:\n",
    "            for subfolder_name in ['image','label']:\n",
    "                subfolder_path = os.path.join(working_mother_folder,str(j),'polar',subfolder_name)\n",
    "                temp_subfolder_path = os.path.join(temp_folder_path,subfolder_name)\n",
    "                for root, dirs, files in os.walk(subfolder_path):\n",
    "                    for file in files:\n",
    "                        src_file = os.path.join(root, file)\n",
    "                        dest_file = os.path.join(temp_subfolder_path,os.path.relpath(src_file, subfolder_path))\n",
    "                        os.makedirs(os.path.dirname(dest_file), exist_ok=True)\n",
    "                        shutil.copy(src_file, dest_file)\n",
    "    test_gene = trainGenerator(batch_size, temp_folder_path, PARAM_IMG_FOLDER, PARAM_MSK_FOLDER, data_gen_args)\n",
    "    model = unet(PARAM_BETA1[PARAM_BETA_TEST_NUM], PARAM_BETA2[PARAM_BETA_TEST_NUM]) \n",
    "    model_checkpoint = ModelCheckpoint(os.path.join(working_mother_folder,'checkpoint.hdf5'), monitor = 'loss', verbose=1, save_best_only=True)\n",
    "    test_run = model.fit(test_gene, verbose = 1, steps_per_epoch = 100, epochs = 100, callbacks = [model_checkpoint])\n",
    "    score.append(test_run)\n",
    "    shutil.rmtree(temp_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for single_run in score:\n",
    "    plt.plot(test_run.history['loss'])\n",
    "    plt.plot(test_run.history['accuracy'])\n",
    "    plt.title('Test Run')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['loss', 'accuracy'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuiling's K-fold function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K fold Validation (obtain training & testing sets)\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits=PARAM_SPLIT_NUM)\n",
    "for train_index,test_index in kfold.split(dfPolar):\n",
    "    polar_train,polar_test=dfPolar.iloc[train_index, :],dfPolar.iloc[test_index, :]\n",
    "    cartesian_train,cartesian_test=dfCartesian.iloc[train_index, :],dfCartesian.iloc[test_index, :]\n",
    "    #print(\"polar train: \", polar_train, \"polar test: \", polar_test)\n",
    "    #print(\"cartesian train\" , cartesian_train, \"cartesian test\", cartesian_test)\n",
    "    batch_size = 3\n",
    "    PARAM_BETA_TEST_NUM = 6\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "    data_gen_args = dict(rotation_range = 80,      # TODO: improve the data augmentation\n",
    "                width_shift_range =0.02,\n",
    "                height_shift_range =0.02,\n",
    "                shear_range = 0.35,\n",
    "                zoom_range = 0.075,\n",
    "                horizontal_flip = True,\n",
    "                fill_mode = 'nearest',\n",
    "                rescale = 1./255)\n",
    "    print('-------------------------------------------------------------')\n",
    "    test_model = unet(PARAM_BETA1[PARAM_BETA_TEST_NUM], PARAM_BETA2[PARAM_BETA_TEST_NUM]) \n",
    "    test_run = test_model.fit(polar_train, polar_test, verbose = 1, steps_per_epoch = 50, epochs = 5, callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training test\n",
    "\n",
    "This part is used to see if we can train a model using the current configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Superparameters (temporary) for a test run of model training test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "PARAM_BETA_TEST_NUM = 6\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "data_gen_args = dict(rotation_range = 80,      # TODO: improve the data augmentation\n",
    "                width_shift_range =0.02,\n",
    "                height_shift_range =0.02,\n",
    "                shear_range = 0.35,\n",
    "                zoom_range = 0.075,\n",
    "                horizontal_flip = True,\n",
    "                fill_mode = 'nearest',\n",
    "                rescale = 1./255)\n",
    "test_gene = trainGenerator(batch_size, PARAM_PATH_CARTE, PARAM_IMG_FOLDER, PARAM_MSK_FOLDER, data_gen_args)\n",
    "test_model = unet(PARAM_BETA1[PARAM_BETA_TEST_NUM], PARAM_BETA2[PARAM_BETA_TEST_NUM]) \n",
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected output\n",
    "<details>\n",
    "    <summary><b><font color=\"green\">Click here to expand</font></b></summary>\n",
    "    <code>\n",
    "Model: \"model_5\"\n",
    "__________________________________________________________________________________________________\n",
    " Layer (type)                   Output Shape         Param #     Connected to                     \n",
    "==================================================================================================\n",
    " input_6 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
    "                                )]                                                                \n",
    "                                                                                                  \n",
    " conv2d_120 (Conv2D)            (None, 256, 256, 64  1792        ['input_6[0][0]']                \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_121 (Conv2D)            (None, 256, 256, 64  36928       ['conv2d_120[0][0]']             \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " max_pooling2d_20 (MaxPooling2D  (None, 128, 128, 64  0          ['conv2d_121[0][0]']             \n",
    " )                              )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_122 (Conv2D)            (None, 128, 128, 12  73856       ['max_pooling2d_20[0][0]']       \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " conv2d_123 (Conv2D)            (None, 128, 128, 12  147584      ['conv2d_122[0][0]']             \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " max_pooling2d_21 (MaxPooling2D  (None, 64, 64, 128)  0          ['conv2d_123[0][0]']             \n",
    " )                                                                                                \n",
    "                                                                                                  \n",
    " conv2d_124 (Conv2D)            (None, 64, 64, 256)  295168      ['max_pooling2d_21[0][0]']       \n",
    "                                                                                                  \n",
    " conv2d_125 (Conv2D)            (None, 64, 64, 256)  590080      ['conv2d_124[0][0]']             \n",
    "                                                                                                  \n",
    " max_pooling2d_22 (MaxPooling2D  (None, 32, 32, 256)  0          ['conv2d_125[0][0]']             \n",
    " )                                                                                                \n",
    "                                                                                                  \n",
    " conv2d_126 (Conv2D)            (None, 32, 32, 512)  1180160     ['max_pooling2d_22[0][0]']       \n",
    "                                                                                                  \n",
    " conv2d_127 (Conv2D)            (None, 32, 32, 512)  2359808     ['conv2d_126[0][0]']             \n",
    "                                                                                                  \n",
    " dropout_10 (Dropout)           (None, 32, 32, 512)  0           ['conv2d_127[0][0]']             \n",
    "                                                                                                  \n",
    " max_pooling2d_23 (MaxPooling2D  (None, 16, 16, 512)  0          ['dropout_10[0][0]']             \n",
    " )                                                                                                \n",
    "                                                                                                  \n",
    " conv2d_128 (Conv2D)            (None, 16, 16, 1024  4719616     ['max_pooling2d_23[0][0]']       \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_129 (Conv2D)            (None, 16, 16, 1024  9438208     ['conv2d_128[0][0]']             \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " dropout_11 (Dropout)           (None, 16, 16, 1024  0           ['conv2d_129[0][0]']             \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " up_sampling2d_20 (UpSampling2D  (None, 32, 32, 1024  0          ['dropout_11[0][0]']             \n",
    " )                              )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_130 (Conv2D)            (None, 32, 32, 512)  2097664     ['up_sampling2d_20[0][0]']       \n",
    "                                                                                                  \n",
    " concatenate_20 (Concatenate)   (None, 32, 32, 1024  0           ['dropout_10[0][0]',             \n",
    "                                )                                 'conv2d_130[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_131 (Conv2D)            (None, 32, 32, 512)  4719104     ['concatenate_20[0][0]']         \n",
    "                                                                                                  \n",
    " conv2d_132 (Conv2D)            (None, 32, 32, 512)  2359808     ['conv2d_131[0][0]']             \n",
    "                                                                                                  \n",
    " up_sampling2d_21 (UpSampling2D  (None, 64, 64, 512)  0          ['conv2d_132[0][0]']             \n",
    " )                                                                                                \n",
    "                                                                                                  \n",
    " conv2d_133 (Conv2D)            (None, 64, 64, 256)  524544      ['up_sampling2d_21[0][0]']       \n",
    "                                                                                                  \n",
    " concatenate_21 (Concatenate)   (None, 64, 64, 512)  0           ['conv2d_125[0][0]',             \n",
    "                                                                  'conv2d_133[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_134 (Conv2D)            (None, 64, 64, 256)  1179904     ['concatenate_21[0][0]']         \n",
    "                                                                                                  \n",
    " conv2d_135 (Conv2D)            (None, 64, 64, 256)  590080      ['conv2d_134[0][0]']             \n",
    "                                                                                                  \n",
    " up_sampling2d_22 (UpSampling2D  (None, 128, 128, 25  0          ['conv2d_135[0][0]']             \n",
    " )                              6)                                                                \n",
    "                                                                                                  \n",
    " conv2d_136 (Conv2D)            (None, 128, 128, 12  131200      ['up_sampling2d_22[0][0]']       \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " concatenate_22 (Concatenate)   (None, 128, 128, 25  0           ['conv2d_123[0][0]',             \n",
    "                                6)                                'conv2d_136[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_137 (Conv2D)            (None, 128, 128, 12  295040      ['concatenate_22[0][0]']         \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " conv2d_138 (Conv2D)            (None, 128, 128, 12  147584      ['conv2d_137[0][0]']             \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " up_sampling2d_23 (UpSampling2D  (None, 256, 256, 12  0          ['conv2d_138[0][0]']             \n",
    " )                              8)                                                                \n",
    "                                                                                                  \n",
    " conv2d_139 (Conv2D)            (None, 256, 256, 64  32832       ['up_sampling2d_23[0][0]']       \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " concatenate_23 (Concatenate)   (None, 256, 256, 12  0           ['conv2d_121[0][0]',             \n",
    "                                8)                                'conv2d_139[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_140 (Conv2D)            (None, 256, 256, 64  73792       ['concatenate_23[0][0]']         \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_141 (Conv2D)            (None, 256, 256, 64  36928       ['conv2d_140[0][0]']             \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_142 (Conv2D)            (None, 256, 256, 9)  5193        ['conv2d_141[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_143 (Conv2D)            (None, 256, 256, 3)  30          ['conv2d_142[0][0]']             \n",
    "                                                                                                  \n",
    "==================================================================================================\n",
    "Total params: 31,036,903\n",
    "Trainable params: 31,036,903\n",
    "Non-trainable params: 0\n",
    "</code>\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint('unet_endoscopic.hdf5', monitor = 'loss', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item1, item2 in test_gene:\n",
    "    print(item1.shape)\n",
    "    print(item2.shape)\n",
    "    print('----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_run = test_model.fit(test_gene, verbose = 1, steps_per_epoch = 100, epochs = 100, callbacks = [model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(test_run.history.keys())\n",
    "plt.plot(test_run.history['loss'])\n",
    "plt.plot(test_run.history['accuracy'])\n",
    "plt.title('Test Run')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss', 'accuracy'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAM_PATH_TEST = './test'\n",
    "image_name = '14.tif'\n",
    "img = io.imread(os.path.join(PARAM_PATH_TEST,image_name),as_gray = False)\n",
    "img = trans.resize(img,[256,256])\n",
    "img = np.reshape(img,(1,)+img.shape)\n",
    "\n",
    "results = test_model.predict(img,1,verbose=1)\n",
    "#saveResult(Path,results)\n",
    "img = results[0,:,:]\n",
    "print(results.shape)\n",
    "io.imsave(os.path.join(PARAM_PATH_TEST,\"result.png\"),img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
