{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Approach for Unet Training \n",
    "\n",
    "------\n",
    "\n",
    "## Overview\n",
    "\n",
    "\n",
    "\n",
    "The purpose of this learn.ipynb notebook is to investigate whether an image can exhibit a preference for being segmented more effectively using a UNet model trained on polar or cartesian-dominant images.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Structure\n",
    "```\n",
    "data\n",
    "└── endoscopic\n",
    "    ├── cartesian\n",
    "    │   ├── image\n",
    "    │   └── label\n",
    "    └── polar\n",
    "        ├── image\n",
    "        └── label\n",
    "```\n",
    "\n",
    "Inside of each end folder there are 956 images, named as `0.tif` to `955.tif`\n",
    "and I believe, for now, the naming of the images are one to one correctly matched, meaning the ``/data/endoscopic/**cartesian**/image/0.tif`` is transformed from `/data/endoscopic/**polar**/image/0.tif`\n",
    "\n",
    "Instead of putting a seperate set of images aside to be test set, we chose to use k-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import from files and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from defines import *\n",
    "from model import *\n",
    "from data import *\n",
    "import sys\n",
    "\n",
    "from numpy import loadtxt\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import math\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this if your computer has a cuda visible device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PARAM_SYSTEM_TIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test code for correct file structure setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize folder tree in current directory\n",
    "os.system(\"tree -d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count of files in data directories\n",
    "os.system(\"ls \" + os.path.join(PARAM_PATH_CARTE,PARAM_IMG_FOLDER) + \" | wc -l\")\n",
    "os.system(\"ls \" + os.path.join(PARAM_PATH_CARTE,PARAM_MSK_FOLDER) + \" | wc -l\")\n",
    "os.system(\"ls \" + os.path.join(PARAM_PATH_POLAR,PARAM_IMG_FOLDER) + \" | wc -l\")\n",
    "os.system(\"ls \" + os.path.join(PARAM_PATH_POLAR,PARAM_MSK_FOLDER) + \" | wc -l\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output: \n",
    "956\n",
    "956\n",
    "956\n",
    "956\n",
    "**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Relocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following block, the code loads in one analysis file from previous research. \n",
    "\n",
    "### #File name postfix\n",
    "_C_ is the dice scores of the predictions generated by Unet C: this Unet C is trained using all 7404 images, in their cartesian form. The raw image was directly input into the Unet and the prediction was generated.\n",
    "\n",
    "_P_ is the dice scores of the predictions generated by Unet P: this Unet P is trained using all 7404 images but in their polar form. The raw images were transformed, and then input for prediction. The prediction is in polar space.\n",
    "\n",
    "_P2C_ is the dice scores of the predictions generated by the same Unet P as mentioned above, but the dice score is generated by transforming the prediction back to cartesian, and compared to their original label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#file_name = 'analysis_dice_back_Test_C.npy'\n",
    "file_name = 'analysis_dice_back_Test_P.npy'\n",
    "#file_name = 'analysis_dice_back_Test_P2C.npy'\n",
    "np_file = os.path.join(PARAM_PATH_SCORES, file_name)\n",
    "#load npy file\n",
    "img_score = np.load(np_file)\n",
    "#sort scores in descending order and store index\n",
    "sorted_score = np.flip(np.argsort(img_score))\n",
    "#print(sorted_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_score = pd.DataFrame(sorted_score)\n",
    "\n",
    "#fetch top polar dominant and non-polar dominant image\n",
    "num_polar = round(len(sorted_score)/2)\n",
    "num_cartesian = len(sorted_score) - num_polar\n",
    "dfPolar = sorted_score.head(num_polar)\n",
    "dfCartesian = sorted_score.tail(num_cartesian)\n",
    "print(\"Polar: \\n\", dfPolar)\n",
    "print(\"Cartesian: \\n\", dfCartesian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new directories for polar dominant images and cartesian dominant images based on sorted dice scores\n",
    "\n",
    "if os.path.exists(PARAM_PATH_TEMP_POLAR):#\n",
    "    shutil.rmtree(PARAM_PATH_TEMP_POLAR)\n",
    "os.makedirs(PARAM_PATH_TEMP_POLAR)\n",
    "this_folder = os.path.join(PARAM_PATH_TEMP_POLAR,PARAM_SUB_FOLDER_POLAR)#Creation of subfolder\n",
    "os.makedirs(os.path.join(this_folder,PARAM_IMG_FOLDER))\n",
    "os.makedirs(os.path.join(this_folder,PARAM_MSK_FOLDER))\n",
    "this_folder = os.path.join(PARAM_PATH_TEMP_POLAR,PARAM_SUB_FOLDER_CARTE)\n",
    "os.makedirs(os.path.join(this_folder,PARAM_IMG_FOLDER))\n",
    "os.makedirs(os.path.join(this_folder,PARAM_MSK_FOLDER))\n",
    "\n",
    "if os.path.exists(PARAM_PATH_TEMP_CARTE):\n",
    "    shutil.rmtree(PARAM_PATH_TEMP_CARTE)\n",
    "os.makedirs(PARAM_PATH_TEMP_CARTE)\n",
    "this_folder = os.path.join(PARAM_PATH_TEMP_CARTE,PARAM_SUB_FOLDER_POLAR)#Creation of subfolder\n",
    "os.makedirs(os.path.join(this_folder,PARAM_IMG_FOLDER))\n",
    "os.makedirs(os.path.join(this_folder,PARAM_MSK_FOLDER))\n",
    "this_folder = os.path.join(PARAM_PATH_TEMP_CARTE,PARAM_SUB_FOLDER_CARTE)\n",
    "os.makedirs(os.path.join(this_folder,PARAM_IMG_FOLDER))\n",
    "os.makedirs(os.path.join(this_folder,PARAM_MSK_FOLDER))\n",
    "\n",
    "for img in dfPolar[0]:\n",
    "    img_name = str(img) + \".tif\"\n",
    "    #Copy polar img and mask in\n",
    "    this_folder = os.path.join(PARAM_PATH_TEMP_POLAR,PARAM_SUB_FOLDER_POLAR)\n",
    "    src = os.path.join(PARAM_PATH_POLAR, PARAM_IMG_FOLDER, img_name)\n",
    "    shutil.copy2(src, os.path.join(this_folder,PARAM_IMG_FOLDER))\n",
    "    src = os.path.join(PARAM_PATH_POLAR, PARAM_MSK_FOLDER, img_name)\n",
    "    shutil.copy2(src, os.path.join(this_folder,PARAM_MSK_FOLDER))\n",
    "    #Copy cartesian img and mask in\n",
    "    this_folder = os.path.join(PARAM_PATH_TEMP_POLAR,PARAM_SUB_FOLDER_CARTE)\n",
    "    src = os.path.join(PARAM_PATH_CARTE, PARAM_IMG_FOLDER, img_name)\n",
    "    shutil.copy2(src, os.path.join(this_folder,PARAM_IMG_FOLDER))\n",
    "    src = os.path.join(PARAM_PATH_CARTE, PARAM_MSK_FOLDER, img_name)\n",
    "    shutil.copy2(src, os.path.join(this_folder,PARAM_MSK_FOLDER))\n",
    "    \n",
    "for img in dfCartesian[0]:\n",
    "    img_name = str(img) + \".tif\"\n",
    "    #Copy polar img and mask in\n",
    "    this_folder = os.path.join(PARAM_PATH_TEMP_CARTE,PARAM_SUB_FOLDER_POLAR)\n",
    "    src = os.path.join(PARAM_PATH_POLAR, PARAM_IMG_FOLDER, img_name)\n",
    "    shutil.copy2(src, os.path.join(this_folder,PARAM_IMG_FOLDER))\n",
    "    src = os.path.join(PARAM_PATH_POLAR, PARAM_MSK_FOLDER, img_name)\n",
    "    shutil.copy2(src, os.path.join(this_folder,PARAM_MSK_FOLDER))\n",
    "    #Copy cartesian img and mask in    \n",
    "    this_folder = os.path.join(PARAM_PATH_TEMP_CARTE,PARAM_SUB_FOLDER_CARTE)\n",
    "    src = os.path.join(PARAM_PATH_CARTE, PARAM_IMG_FOLDER, img_name)\n",
    "    shutil.copy2(src, os.path.join(this_folder,PARAM_IMG_FOLDER))\n",
    "    src = os.path.join(PARAM_PATH_CARTE, PARAM_MSK_FOLDER, img_name)\n",
    "    shutil.copy2(src, os.path.join(this_folder,PARAM_MSK_FOLDER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K fold Validation (obtain training & testing sets)\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits=PARAM_SPLIT_NUM)\n",
    "for train_index,test_index in kfold.split(dfPolar):\n",
    "    polar_train,polar_test=dfPolar.iloc[train_index, :],dfPolar.iloc[test_index, :]\n",
    "    cartesian_train,cartesian_test=dfCartesian.iloc[train_index, :],dfCartesian.iloc[test_index, :]\n",
    "    print(\"polar train: \", polar_train, \"polar test: \", polar_test)\n",
    "    print(\"cartesian train\" , cartesian_train, \"cartesian test\", cartesian_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training test\n",
    "\n",
    "This part is used to see if we can train a model using the current configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Superparameters (temporary) for a test run of model training test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 256, 256, 64  1792        ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 256, 256, 64  36928       ['conv2d_24[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 128, 128, 64  0          ['conv2d_25[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 128, 128, 12  73856       ['max_pooling2d_4[0][0]']        \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_26[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 64, 64, 128)  0          ['conv2d_27[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 64, 64, 256)  295168      ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_28[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 256)  0          ['conv2d_29[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 32, 32, 512)  1180160     ['max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_30[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 32, 32, 512)  0           ['conv2d_31[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 512)  0          ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 16, 16, 1024  4719616     ['max_pooling2d_7[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 16, 16, 1024  9438208     ['conv2d_32[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 16, 16, 1024  0           ['conv2d_33[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSampling2D)  (None, 32, 32, 1024  0          ['dropout_3[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 32, 32, 512)  2097664     ['up_sampling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 32, 32, 1024  0           ['dropout_2[0][0]',              \n",
      "                                )                                 'conv2d_34[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 32, 32, 512)  4719104     ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_35[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_5 (UpSampling2D)  (None, 64, 64, 512)  0          ['conv2d_36[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 64, 64, 256)  524544      ['up_sampling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 64, 64, 512)  0           ['conv2d_29[0][0]',              \n",
      "                                                                  'conv2d_37[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 64, 64, 256)  1179904     ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_38[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_6 (UpSampling2D)  (None, 128, 128, 25  0          ['conv2d_39[0][0]']              \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 128, 128, 12  131200      ['up_sampling2d_6[0][0]']        \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 128, 128, 25  0           ['conv2d_27[0][0]',              \n",
      "                                6)                                'conv2d_40[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 128, 128, 12  295040      ['concatenate_6[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_41[0][0]']              \n",
      "                                8)                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " up_sampling2d_7 (UpSampling2D)  (None, 256, 256, 12  0          ['conv2d_42[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 256, 256, 64  32832       ['up_sampling2d_7[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 256, 256, 12  0           ['conv2d_25[0][0]',              \n",
      "                                8)                                'conv2d_43[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 256, 256, 64  73792       ['concatenate_7[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 256, 256, 64  36928       ['conv2d_44[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 256, 256, 2)  1154        ['conv2d_45[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 256, 256, 1)  3           ['conv2d_46[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,032,837\n",
      "Trainable params: 31,032,837\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "PARAM_BETA_TEST_NUM = 6\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "data_gen_args = dict(rotation_range = 80,      # TODO: improve the data augmentation\n",
    "                width_shift_range =0.02,\n",
    "                height_shift_range =0.02,\n",
    "                shear_range = 0.35,\n",
    "                zoom_range = 0.075,\n",
    "                horizontal_flip = True,\n",
    "                fill_mode = 'nearest',\n",
    "                rescale = 1./255)\n",
    "test_gene = trainGenerator(batch_size, PARAM_PATH_CARTE, PARAM_IMG_FOLDER, PARAM_MSK_FOLDER, data_gen_args)\n",
    "test_model = unet(PARAM_BETA1[PARAM_BETA_TEST_NUM], PARAM_BETA2[PARAM_BETA_TEST_NUM]) \n",
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected output\n",
    "<details>\n",
    "    <summary><b><font color=\"green\">Click here to expand</font></b></summary>\n",
    "    <code>\n",
    "Model: \"model_5\"\n",
    "__________________________________________________________________________________________________\n",
    " Layer (type)                   Output Shape         Param #     Connected to                     \n",
    "==================================================================================================\n",
    " input_6 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
    "                                )]                                                                \n",
    "                                                                                                  \n",
    " conv2d_120 (Conv2D)            (None, 256, 256, 64  1792        ['input_6[0][0]']                \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_121 (Conv2D)            (None, 256, 256, 64  36928       ['conv2d_120[0][0]']             \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " max_pooling2d_20 (MaxPooling2D  (None, 128, 128, 64  0          ['conv2d_121[0][0]']             \n",
    " )                              )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_122 (Conv2D)            (None, 128, 128, 12  73856       ['max_pooling2d_20[0][0]']       \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " conv2d_123 (Conv2D)            (None, 128, 128, 12  147584      ['conv2d_122[0][0]']             \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " max_pooling2d_21 (MaxPooling2D  (None, 64, 64, 128)  0          ['conv2d_123[0][0]']             \n",
    " )                                                                                                \n",
    "                                                                                                  \n",
    " conv2d_124 (Conv2D)            (None, 64, 64, 256)  295168      ['max_pooling2d_21[0][0]']       \n",
    "                                                                                                  \n",
    " conv2d_125 (Conv2D)            (None, 64, 64, 256)  590080      ['conv2d_124[0][0]']             \n",
    "                                                                                                  \n",
    " max_pooling2d_22 (MaxPooling2D  (None, 32, 32, 256)  0          ['conv2d_125[0][0]']             \n",
    " )                                                                                                \n",
    "                                                                                                  \n",
    " conv2d_126 (Conv2D)            (None, 32, 32, 512)  1180160     ['max_pooling2d_22[0][0]']       \n",
    "                                                                                                  \n",
    " conv2d_127 (Conv2D)            (None, 32, 32, 512)  2359808     ['conv2d_126[0][0]']             \n",
    "                                                                                                  \n",
    " dropout_10 (Dropout)           (None, 32, 32, 512)  0           ['conv2d_127[0][0]']             \n",
    "                                                                                                  \n",
    " max_pooling2d_23 (MaxPooling2D  (None, 16, 16, 512)  0          ['dropout_10[0][0]']             \n",
    " )                                                                                                \n",
    "                                                                                                  \n",
    " conv2d_128 (Conv2D)            (None, 16, 16, 1024  4719616     ['max_pooling2d_23[0][0]']       \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_129 (Conv2D)            (None, 16, 16, 1024  9438208     ['conv2d_128[0][0]']             \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " dropout_11 (Dropout)           (None, 16, 16, 1024  0           ['conv2d_129[0][0]']             \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " up_sampling2d_20 (UpSampling2D  (None, 32, 32, 1024  0          ['dropout_11[0][0]']             \n",
    " )                              )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_130 (Conv2D)            (None, 32, 32, 512)  2097664     ['up_sampling2d_20[0][0]']       \n",
    "                                                                                                  \n",
    " concatenate_20 (Concatenate)   (None, 32, 32, 1024  0           ['dropout_10[0][0]',             \n",
    "                                )                                 'conv2d_130[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_131 (Conv2D)            (None, 32, 32, 512)  4719104     ['concatenate_20[0][0]']         \n",
    "                                                                                                  \n",
    " conv2d_132 (Conv2D)            (None, 32, 32, 512)  2359808     ['conv2d_131[0][0]']             \n",
    "                                                                                                  \n",
    " up_sampling2d_21 (UpSampling2D  (None, 64, 64, 512)  0          ['conv2d_132[0][0]']             \n",
    " )                                                                                                \n",
    "                                                                                                  \n",
    " conv2d_133 (Conv2D)            (None, 64, 64, 256)  524544      ['up_sampling2d_21[0][0]']       \n",
    "                                                                                                  \n",
    " concatenate_21 (Concatenate)   (None, 64, 64, 512)  0           ['conv2d_125[0][0]',             \n",
    "                                                                  'conv2d_133[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_134 (Conv2D)            (None, 64, 64, 256)  1179904     ['concatenate_21[0][0]']         \n",
    "                                                                                                  \n",
    " conv2d_135 (Conv2D)            (None, 64, 64, 256)  590080      ['conv2d_134[0][0]']             \n",
    "                                                                                                  \n",
    " up_sampling2d_22 (UpSampling2D  (None, 128, 128, 25  0          ['conv2d_135[0][0]']             \n",
    " )                              6)                                                                \n",
    "                                                                                                  \n",
    " conv2d_136 (Conv2D)            (None, 128, 128, 12  131200      ['up_sampling2d_22[0][0]']       \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " concatenate_22 (Concatenate)   (None, 128, 128, 25  0           ['conv2d_123[0][0]',             \n",
    "                                6)                                'conv2d_136[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_137 (Conv2D)            (None, 128, 128, 12  295040      ['concatenate_22[0][0]']         \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " conv2d_138 (Conv2D)            (None, 128, 128, 12  147584      ['conv2d_137[0][0]']             \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " up_sampling2d_23 (UpSampling2D  (None, 256, 256, 12  0          ['conv2d_138[0][0]']             \n",
    " )                              8)                                                                \n",
    "                                                                                                  \n",
    " conv2d_139 (Conv2D)            (None, 256, 256, 64  32832       ['up_sampling2d_23[0][0]']       \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " concatenate_23 (Concatenate)   (None, 256, 256, 12  0           ['conv2d_121[0][0]',             \n",
    "                                8)                                'conv2d_139[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_140 (Conv2D)            (None, 256, 256, 64  73792       ['concatenate_23[0][0]']         \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_141 (Conv2D)            (None, 256, 256, 64  36928       ['conv2d_140[0][0]']             \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_142 (Conv2D)            (None, 256, 256, 9)  5193        ['conv2d_141[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_143 (Conv2D)            (None, 256, 256, 3)  30          ['conv2d_142[0][0]']             \n",
    "                                                                                                  \n",
    "==================================================================================================\n",
    "Total params: 31,036,903\n",
    "Trainable params: 31,036,903\n",
    "Non-trainable params: 0\n",
    "</code>\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint('unet_endoscopic.hdf5', monitor = 'loss', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7404 images belonging to 1 classes.\n",
      "Found 7404 images belonging to 1 classes.\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fb0c82728c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fb0c82728c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function dice_coef_loss at 0x7fb1a439ed40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function dice_coef_loss at 0x7fb1a439ed40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-16 17:02:47.343864: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n",
      "2023-09-16 17:02:47.796039: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 0.7849 - accuracy: 0.5490 - dice_coef_loss: 0.7849\n",
      "Epoch 1: loss improved from inf to 0.78486, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 24s 184ms/step - loss: 0.7849 - accuracy: 0.5490 - dice_coef_loss: 0.7849\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7118 - accuracy: 0.7430 - dice_coef_loss: 0.7118\n",
      "Epoch 2: loss improved from 0.78486 to 0.71178, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 0.7118 - accuracy: 0.7430 - dice_coef_loss: 0.7118\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7001 - accuracy: 0.8121 - dice_coef_loss: 0.7001\n",
      "Epoch 3: loss improved from 0.71178 to 0.70006, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 0.7001 - accuracy: 0.8121 - dice_coef_loss: 0.7001\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6510 - accuracy: 0.8256 - dice_coef_loss: 0.6510\n",
      "Epoch 4: loss improved from 0.70006 to 0.65104, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 0.6510 - accuracy: 0.8256 - dice_coef_loss: 0.6510\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6589 - accuracy: 0.8375 - dice_coef_loss: 0.6589\n",
      "Epoch 5: loss did not improve from 0.65104\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.6589 - accuracy: 0.8375 - dice_coef_loss: 0.6589\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6189 - accuracy: 0.8549 - dice_coef_loss: 0.6189\n",
      "Epoch 6: loss improved from 0.65104 to 0.61887, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 0.6189 - accuracy: 0.8549 - dice_coef_loss: 0.6189\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6203 - accuracy: 0.8474 - dice_coef_loss: 0.6203\n",
      "Epoch 7: loss did not improve from 0.61887\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.6203 - accuracy: 0.8474 - dice_coef_loss: 0.6203\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6157 - accuracy: 0.8714 - dice_coef_loss: 0.6157\n",
      "Epoch 8: loss improved from 0.61887 to 0.61565, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 0.6157 - accuracy: 0.8714 - dice_coef_loss: 0.6157\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6236 - accuracy: 0.8471 - dice_coef_loss: 0.6236\n",
      "Epoch 9: loss did not improve from 0.61565\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.6236 - accuracy: 0.8471 - dice_coef_loss: 0.6236\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5872 - accuracy: 0.8669 - dice_coef_loss: 0.5872\n",
      "Epoch 10: loss improved from 0.61565 to 0.58724, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 0.5872 - accuracy: 0.8669 - dice_coef_loss: 0.5872\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6013 - accuracy: 0.8617 - dice_coef_loss: 0.6013\n",
      "Epoch 11: loss did not improve from 0.58724\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.6013 - accuracy: 0.8617 - dice_coef_loss: 0.6013\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5958 - accuracy: 0.8870 - dice_coef_loss: 0.5958\n",
      "Epoch 12: loss did not improve from 0.58724\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5958 - accuracy: 0.8870 - dice_coef_loss: 0.5958\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5913 - accuracy: 0.8835 - dice_coef_loss: 0.5913\n",
      "Epoch 13: loss did not improve from 0.58724\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5913 - accuracy: 0.8835 - dice_coef_loss: 0.5913\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5813 - accuracy: 0.8977 - dice_coef_loss: 0.5813\n",
      "Epoch 14: loss improved from 0.58724 to 0.58132, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 0.5813 - accuracy: 0.8977 - dice_coef_loss: 0.5813\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5666 - accuracy: 0.8841 - dice_coef_loss: 0.5666\n",
      "Epoch 15: loss improved from 0.58132 to 0.56662, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 0.5666 - accuracy: 0.8841 - dice_coef_loss: 0.5666\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5790 - accuracy: 0.8976 - dice_coef_loss: 0.5790\n",
      "Epoch 16: loss did not improve from 0.56662\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5790 - accuracy: 0.8976 - dice_coef_loss: 0.5790\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5897 - accuracy: 0.8823 - dice_coef_loss: 0.5897\n",
      "Epoch 17: loss did not improve from 0.56662\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5897 - accuracy: 0.8823 - dice_coef_loss: 0.5897\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5871 - accuracy: 0.8762 - dice_coef_loss: 0.5871\n",
      "Epoch 18: loss did not improve from 0.56662\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5871 - accuracy: 0.8762 - dice_coef_loss: 0.5871\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5702 - accuracy: 0.8884 - dice_coef_loss: 0.5702\n",
      "Epoch 19: loss did not improve from 0.56662\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5702 - accuracy: 0.8884 - dice_coef_loss: 0.5702\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5603 - accuracy: 0.8983 - dice_coef_loss: 0.5603\n",
      "Epoch 20: loss improved from 0.56662 to 0.56031, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 0.5603 - accuracy: 0.8983 - dice_coef_loss: 0.5603\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5768 - accuracy: 0.9067 - dice_coef_loss: 0.5768\n",
      "Epoch 21: loss did not improve from 0.56031\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5768 - accuracy: 0.9067 - dice_coef_loss: 0.5768\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5365 - accuracy: 0.9070 - dice_coef_loss: 0.5365\n",
      "Epoch 22: loss improved from 0.56031 to 0.53651, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 0.5365 - accuracy: 0.9070 - dice_coef_loss: 0.5365\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5702 - accuracy: 0.8951 - dice_coef_loss: 0.5702\n",
      "Epoch 23: loss did not improve from 0.53651\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5702 - accuracy: 0.8951 - dice_coef_loss: 0.5702\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5290 - accuracy: 0.9091 - dice_coef_loss: 0.5290\n",
      "Epoch 24: loss improved from 0.53651 to 0.52897, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 0.5290 - accuracy: 0.9091 - dice_coef_loss: 0.5290\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5663 - accuracy: 0.9003 - dice_coef_loss: 0.5663\n",
      "Epoch 25: loss did not improve from 0.52897\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5663 - accuracy: 0.9003 - dice_coef_loss: 0.5663\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5448 - accuracy: 0.9092 - dice_coef_loss: 0.5448\n",
      "Epoch 26: loss did not improve from 0.52897\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5448 - accuracy: 0.9092 - dice_coef_loss: 0.5448\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5616 - accuracy: 0.8944 - dice_coef_loss: 0.5616\n",
      "Epoch 27: loss did not improve from 0.52897\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 0.5616 - accuracy: 0.8944 - dice_coef_loss: 0.5616\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 0.5175 - accuracy: 0.9101 - dice_coef_loss: 0.5175\n",
      "Epoch 28: loss improved from 0.52897 to 0.51747, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 0.5175 - accuracy: 0.9101 - dice_coef_loss: 0.5175\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5211 - accuracy: 0.9189 - dice_coef_loss: 0.5211\n",
      "Epoch 29: loss did not improve from 0.51747\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5211 - accuracy: 0.9189 - dice_coef_loss: 0.5211\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5407 - accuracy: 0.8961 - dice_coef_loss: 0.5407\n",
      "Epoch 30: loss did not improve from 0.51747\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5407 - accuracy: 0.8961 - dice_coef_loss: 0.5407\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5413 - accuracy: 0.9036 - dice_coef_loss: 0.5413\n",
      "Epoch 31: loss did not improve from 0.51747\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5413 - accuracy: 0.9036 - dice_coef_loss: 0.5413\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5322 - accuracy: 0.9085 - dice_coef_loss: 0.5322\n",
      "Epoch 32: loss did not improve from 0.51747\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5322 - accuracy: 0.9085 - dice_coef_loss: 0.5322\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5542 - accuracy: 0.8987 - dice_coef_loss: 0.5542\n",
      "Epoch 33: loss did not improve from 0.51747\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5542 - accuracy: 0.8987 - dice_coef_loss: 0.5542\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5380 - accuracy: 0.9094 - dice_coef_loss: 0.5380\n",
      "Epoch 34: loss did not improve from 0.51747\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 0.5380 - accuracy: 0.9094 - dice_coef_loss: 0.5380\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5304 - accuracy: 0.8956 - dice_coef_loss: 0.5304\n",
      "Epoch 35: loss did not improve from 0.51747\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5304 - accuracy: 0.8956 - dice_coef_loss: 0.5304\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5528 - accuracy: 0.8998 - dice_coef_loss: 0.5528\n",
      "Epoch 36: loss did not improve from 0.51747\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5528 - accuracy: 0.8998 - dice_coef_loss: 0.5528\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5505 - accuracy: 0.9072 - dice_coef_loss: 0.5505\n",
      "Epoch 37: loss did not improve from 0.51747\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5505 - accuracy: 0.9072 - dice_coef_loss: 0.5505\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5234 - accuracy: 0.9085 - dice_coef_loss: 0.5234\n",
      "Epoch 38: loss did not improve from 0.51747\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5234 - accuracy: 0.9085 - dice_coef_loss: 0.5234\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5310 - accuracy: 0.9061 - dice_coef_loss: 0.5310\n",
      "Epoch 39: loss did not improve from 0.51747\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5310 - accuracy: 0.9061 - dice_coef_loss: 0.5310\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5235 - accuracy: 0.9170 - dice_coef_loss: 0.5235\n",
      "Epoch 40: loss did not improve from 0.51747\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5235 - accuracy: 0.9170 - dice_coef_loss: 0.5235\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5310 - accuracy: 0.9023 - dice_coef_loss: 0.5310\n",
      "Epoch 41: loss did not improve from 0.51747\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5310 - accuracy: 0.9023 - dice_coef_loss: 0.5310\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5166 - accuracy: 0.9159 - dice_coef_loss: 0.5166\n",
      "Epoch 42: loss improved from 0.51747 to 0.51656, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 0.5166 - accuracy: 0.9159 - dice_coef_loss: 0.5166\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5267 - accuracy: 0.9188 - dice_coef_loss: 0.5267\n",
      "Epoch 43: loss did not improve from 0.51656\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5267 - accuracy: 0.9188 - dice_coef_loss: 0.5267\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5067 - accuracy: 0.9191 - dice_coef_loss: 0.5067\n",
      "Epoch 44: loss improved from 0.51656 to 0.50673, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 0.5067 - accuracy: 0.9191 - dice_coef_loss: 0.5067\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4998 - accuracy: 0.9234 - dice_coef_loss: 0.4998\n",
      "Epoch 45: loss improved from 0.50673 to 0.49976, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 0.4998 - accuracy: 0.9234 - dice_coef_loss: 0.4998\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5171 - accuracy: 0.9138 - dice_coef_loss: 0.5171\n",
      "Epoch 46: loss did not improve from 0.49976\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 0.5171 - accuracy: 0.9138 - dice_coef_loss: 0.5171\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5228 - accuracy: 0.9156 - dice_coef_loss: 0.5228\n",
      "Epoch 47: loss did not improve from 0.49976\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5228 - accuracy: 0.9156 - dice_coef_loss: 0.5228\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5301 - accuracy: 0.9248 - dice_coef_loss: 0.5301\n",
      "Epoch 48: loss did not improve from 0.49976\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5301 - accuracy: 0.9248 - dice_coef_loss: 0.5301\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5237 - accuracy: 0.9241 - dice_coef_loss: 0.5237\n",
      "Epoch 49: loss did not improve from 0.49976\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5237 - accuracy: 0.9241 - dice_coef_loss: 0.5237\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5343 - accuracy: 0.9160 - dice_coef_loss: 0.5343\n",
      "Epoch 50: loss did not improve from 0.49976\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5343 - accuracy: 0.9160 - dice_coef_loss: 0.5343\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5000 - accuracy: 0.9197 - dice_coef_loss: 0.5000\n",
      "Epoch 51: loss did not improve from 0.49976\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5000 - accuracy: 0.9197 - dice_coef_loss: 0.5000\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5134 - accuracy: 0.9187 - dice_coef_loss: 0.5134\n",
      "Epoch 52: loss did not improve from 0.49976\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5134 - accuracy: 0.9187 - dice_coef_loss: 0.5134\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4891 - accuracy: 0.9241 - dice_coef_loss: 0.4891\n",
      "Epoch 53: loss improved from 0.49976 to 0.48906, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 0.4891 - accuracy: 0.9241 - dice_coef_loss: 0.4891\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5092 - accuracy: 0.9177 - dice_coef_loss: 0.5092\n",
      "Epoch 54: loss did not improve from 0.48906\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5092 - accuracy: 0.9177 - dice_coef_loss: 0.5092\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4826 - accuracy: 0.9313 - dice_coef_loss: 0.4826\n",
      "Epoch 55: loss improved from 0.48906 to 0.48260, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 0.4826 - accuracy: 0.9313 - dice_coef_loss: 0.4826\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 0.5023 - accuracy: 0.9198 - dice_coef_loss: 0.5023\n",
      "Epoch 56: loss did not improve from 0.48260\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5023 - accuracy: 0.9198 - dice_coef_loss: 0.5023\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4811 - accuracy: 0.9213 - dice_coef_loss: 0.4811\n",
      "Epoch 57: loss improved from 0.48260 to 0.48114, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 22s 220ms/step - loss: 0.4811 - accuracy: 0.9213 - dice_coef_loss: 0.4811\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4920 - accuracy: 0.9265 - dice_coef_loss: 0.4920\n",
      "Epoch 58: loss did not improve from 0.48114\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4920 - accuracy: 0.9265 - dice_coef_loss: 0.4920\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5004 - accuracy: 0.9169 - dice_coef_loss: 0.5004\n",
      "Epoch 59: loss did not improve from 0.48114\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5004 - accuracy: 0.9169 - dice_coef_loss: 0.5004\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5266 - accuracy: 0.9026 - dice_coef_loss: 0.5266\n",
      "Epoch 60: loss did not improve from 0.48114\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5266 - accuracy: 0.9026 - dice_coef_loss: 0.5266\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4859 - accuracy: 0.9255 - dice_coef_loss: 0.4859\n",
      "Epoch 61: loss did not improve from 0.48114\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4859 - accuracy: 0.9255 - dice_coef_loss: 0.4859\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5176 - accuracy: 0.9229 - dice_coef_loss: 0.5176\n",
      "Epoch 62: loss did not improve from 0.48114\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5176 - accuracy: 0.9229 - dice_coef_loss: 0.5176\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5056 - accuracy: 0.9282 - dice_coef_loss: 0.5056\n",
      "Epoch 63: loss did not improve from 0.48114\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5056 - accuracy: 0.9282 - dice_coef_loss: 0.5056\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5117 - accuracy: 0.9242 - dice_coef_loss: 0.5117\n",
      "Epoch 64: loss did not improve from 0.48114\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5117 - accuracy: 0.9242 - dice_coef_loss: 0.5117\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4923 - accuracy: 0.9249 - dice_coef_loss: 0.4923\n",
      "Epoch 65: loss did not improve from 0.48114\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4923 - accuracy: 0.9249 - dice_coef_loss: 0.4923\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4962 - accuracy: 0.9299 - dice_coef_loss: 0.4962\n",
      "Epoch 66: loss did not improve from 0.48114\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4962 - accuracy: 0.9299 - dice_coef_loss: 0.4962\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5179 - accuracy: 0.9218 - dice_coef_loss: 0.5179\n",
      "Epoch 67: loss did not improve from 0.48114\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5179 - accuracy: 0.9218 - dice_coef_loss: 0.5179\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4996 - accuracy: 0.9236 - dice_coef_loss: 0.4996\n",
      "Epoch 68: loss did not improve from 0.48114\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4996 - accuracy: 0.9236 - dice_coef_loss: 0.4996\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4981 - accuracy: 0.9117 - dice_coef_loss: 0.4981\n",
      "Epoch 69: loss did not improve from 0.48114\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4981 - accuracy: 0.9117 - dice_coef_loss: 0.4981\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4856 - accuracy: 0.9306 - dice_coef_loss: 0.4856\n",
      "Epoch 70: loss did not improve from 0.48114\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4856 - accuracy: 0.9306 - dice_coef_loss: 0.4856\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4919 - accuracy: 0.9236 - dice_coef_loss: 0.4919\n",
      "Epoch 71: loss did not improve from 0.48114\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4919 - accuracy: 0.9236 - dice_coef_loss: 0.4919\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5162 - accuracy: 0.9167 - dice_coef_loss: 0.5162\n",
      "Epoch 72: loss did not improve from 0.48114\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5162 - accuracy: 0.9167 - dice_coef_loss: 0.5162\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4913 - accuracy: 0.9282 - dice_coef_loss: 0.4913\n",
      "Epoch 73: loss did not improve from 0.48114\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4913 - accuracy: 0.9282 - dice_coef_loss: 0.4913\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4802 - accuracy: 0.9277 - dice_coef_loss: 0.4802\n",
      "Epoch 74: loss improved from 0.48114 to 0.48025, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 0.4802 - accuracy: 0.9277 - dice_coef_loss: 0.4802\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4742 - accuracy: 0.9240 - dice_coef_loss: 0.4742\n",
      "Epoch 75: loss improved from 0.48025 to 0.47417, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 0.4742 - accuracy: 0.9240 - dice_coef_loss: 0.4742\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4749 - accuracy: 0.9313 - dice_coef_loss: 0.4749\n",
      "Epoch 76: loss did not improve from 0.47417\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4749 - accuracy: 0.9313 - dice_coef_loss: 0.4749\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4918 - accuracy: 0.9244 - dice_coef_loss: 0.4918\n",
      "Epoch 77: loss did not improve from 0.47417\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4918 - accuracy: 0.9244 - dice_coef_loss: 0.4918\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5071 - accuracy: 0.9252 - dice_coef_loss: 0.5071\n",
      "Epoch 78: loss did not improve from 0.47417\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5071 - accuracy: 0.9252 - dice_coef_loss: 0.5071\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4763 - accuracy: 0.9333 - dice_coef_loss: 0.4763\n",
      "Epoch 79: loss did not improve from 0.47417\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4763 - accuracy: 0.9333 - dice_coef_loss: 0.4763\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5066 - accuracy: 0.9244 - dice_coef_loss: 0.5066\n",
      "Epoch 80: loss did not improve from 0.47417\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5066 - accuracy: 0.9244 - dice_coef_loss: 0.5066\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5077 - accuracy: 0.9222 - dice_coef_loss: 0.5077\n",
      "Epoch 81: loss did not improve from 0.47417\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5077 - accuracy: 0.9222 - dice_coef_loss: 0.5077\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4750 - accuracy: 0.9323 - dice_coef_loss: 0.4750\n",
      "Epoch 82: loss did not improve from 0.47417\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4750 - accuracy: 0.9323 - dice_coef_loss: 0.4750\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4869 - accuracy: 0.9216 - dice_coef_loss: 0.4869\n",
      "Epoch 83: loss did not improve from 0.47417\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4869 - accuracy: 0.9216 - dice_coef_loss: 0.4869\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4901 - accuracy: 0.9314 - dice_coef_loss: 0.4901\n",
      "Epoch 84: loss did not improve from 0.47417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4901 - accuracy: 0.9314 - dice_coef_loss: 0.4901\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4665 - accuracy: 0.9330 - dice_coef_loss: 0.4665\n",
      "Epoch 85: loss improved from 0.47417 to 0.46650, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 0.4665 - accuracy: 0.9330 - dice_coef_loss: 0.4665\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4693 - accuracy: 0.9351 - dice_coef_loss: 0.4693\n",
      "Epoch 86: loss did not improve from 0.46650\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4693 - accuracy: 0.9351 - dice_coef_loss: 0.4693\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4832 - accuracy: 0.9308 - dice_coef_loss: 0.4832\n",
      "Epoch 87: loss did not improve from 0.46650\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4832 - accuracy: 0.9308 - dice_coef_loss: 0.4832\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4761 - accuracy: 0.9265 - dice_coef_loss: 0.4761\n",
      "Epoch 88: loss did not improve from 0.46650\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4761 - accuracy: 0.9265 - dice_coef_loss: 0.4761\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4731 - accuracy: 0.9338 - dice_coef_loss: 0.4731\n",
      "Epoch 89: loss did not improve from 0.46650\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4731 - accuracy: 0.9338 - dice_coef_loss: 0.4731\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4805 - accuracy: 0.9364 - dice_coef_loss: 0.4805\n",
      "Epoch 90: loss did not improve from 0.46650\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4805 - accuracy: 0.9364 - dice_coef_loss: 0.4805\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4975 - accuracy: 0.9280 - dice_coef_loss: 0.4975\n",
      "Epoch 91: loss did not improve from 0.46650\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4975 - accuracy: 0.9280 - dice_coef_loss: 0.4975\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4625 - accuracy: 0.9350 - dice_coef_loss: 0.4625\n",
      "Epoch 92: loss improved from 0.46650 to 0.46249, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 0.4625 - accuracy: 0.9350 - dice_coef_loss: 0.4625\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4620 - accuracy: 0.9302 - dice_coef_loss: 0.4620\n",
      "Epoch 93: loss improved from 0.46249 to 0.46197, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 0.4620 - accuracy: 0.9302 - dice_coef_loss: 0.4620\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4808 - accuracy: 0.9336 - dice_coef_loss: 0.4808\n",
      "Epoch 94: loss did not improve from 0.46197\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4808 - accuracy: 0.9336 - dice_coef_loss: 0.4808\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4492 - accuracy: 0.9415 - dice_coef_loss: 0.4492\n",
      "Epoch 95: loss improved from 0.46197 to 0.44917, saving model to unet_endoscopic.hdf5\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 0.4492 - accuracy: 0.9415 - dice_coef_loss: 0.4492\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4602 - accuracy: 0.9312 - dice_coef_loss: 0.4602\n",
      "Epoch 96: loss did not improve from 0.44917\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4602 - accuracy: 0.9312 - dice_coef_loss: 0.4602\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4531 - accuracy: 0.9388 - dice_coef_loss: 0.4531\n",
      "Epoch 97: loss did not improve from 0.44917\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4531 - accuracy: 0.9388 - dice_coef_loss: 0.4531\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4718 - accuracy: 0.9370 - dice_coef_loss: 0.4718\n",
      "Epoch 98: loss did not improve from 0.44917\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4718 - accuracy: 0.9370 - dice_coef_loss: 0.4718\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4877 - accuracy: 0.9249 - dice_coef_loss: 0.4877\n",
      "Epoch 99: loss did not improve from 0.44917\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 0.4877 - accuracy: 0.9249 - dice_coef_loss: 0.4877\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4692 - accuracy: 0.9363 - dice_coef_loss: 0.4692\n",
      "Epoch 100: loss did not improve from 0.44917\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.4692 - accuracy: 0.9363 - dice_coef_loss: 0.4692\n"
     ]
    }
   ],
   "source": [
    "test_run = test_model.fit(test_gene, verbose = 1, steps_per_epoch = 100, epochs = 100, callbacks = [model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(test_run.history.keys())\n",
    "plt.plot(test_run.history['loss'])\n",
    "plt.plot(test_run.history['accuracy'])\n",
    "plt.title('Test Run')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss', 'accuracy'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAM_PATH_TEST = './test'\n",
    "image_name = '14.tif'\n",
    "img = io.imread(os.path.join(PARAM_PATH_TEST,image_name),as_gray = False)\n",
    "img = trans.resize(img,[256,256])\n",
    "img = np.reshape(img,(1,)+img.shape)\n",
    "\n",
    "results = test_model.predict(img,1,verbose=1)\n",
    "#saveResult(Path,results)\n",
    "img = results[0,:,:]\n",
    "print(results.shape)\n",
    "io.imsave(os.path.join(PARAM_PATH_TEST,\"result.png\"),img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy Code Below\n",
    "### written by Wenfan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from defines import *\n",
    "from model import *\n",
    "from data import *\n",
    "import sys\n",
    "\n",
    "from numpy import loadtxt\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "\n",
    "import glob\n",
    "import os \n",
    "import math\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data_jupyter'# main folder path\n",
    "\n",
    "D = 'all_images'\n",
    "L = 'all_labels'\n",
    "\n",
    "D_P_im = 'polar_im'\n",
    "D_C_im = 'car_im'\n",
    "D_P = 'polar_l'\n",
    "D_C = 'car_l'\n",
    "\n",
    "prev_number_of_D_P = -1\n",
    "prev_number_of_D_C = -1\n",
    "\n",
    "diff = math.inf\n",
    "\n",
    "model_P = unet(PARAM_BETA1[PARAM_BETA_TEST_NUM], PARAM_BETA2[PARAM_BETA_TEST_NUM])\n",
    "model_C = unet(PARAM_BETA1[PARAM_BETA_TEST_NUM], PARAM_BETA2[PARAM_BETA_TEST_NUM])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill in the weights here\n",
    "model_P.load_weights() \n",
    "model_C.load_weights() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "#change file name of D, L\n",
    "for count, filename in enumerate(os.listdir(path+'/'+D)): \n",
    "    dst = str(count) + \".png\"\n",
    "    src = path+'/'+D+'/'+filename\n",
    "    dst = path+'/'+D+'/'+dst\n",
    "\n",
    "    os.rename(src, dst) \n",
    "    \n",
    "for count, filename in enumerate(os.listdir(path+'/'+L)): \n",
    "    dst = str(count) + \".tif\"\n",
    "    src = path+'/'+L+'/'+filename\n",
    "    dst = path+'/'+L+'/'+dst\n",
    "\n",
    "    os.rename(src, dst) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dscore(im, im_name):\n",
    "    label = Image.open(os.path.join(L, im_name))\n",
    "    \n",
    "    pixelIm = im.load()\n",
    "    pixelLabel = label.load()\n",
    "    \n",
    "    upper = 0\n",
    "    lower = im.size[0] * im.size[1]\n",
    "    \n",
    "    for i in range(im.size[0]):\n",
    "        for j in range(im.size[1]):\n",
    "            if pixelIm[i,j] == pixelLabel[i,j]:\n",
    "                upper = upper + 1\n",
    "            \n",
    "    upper = upper * 2\n",
    "    \n",
    "    return upper / lower\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while (diff > 0): \n",
    "    #load model\n",
    "    #if count > 0:\n",
    "    #    model_P.load_weights('model_P_weights_' + (count - 1))\n",
    "    #    model_C.load_weights('model_C_weights_' + (count - 1))\n",
    "    \n",
    "    count = count + 1\n",
    "    \n",
    "    testGene_P, testGene_C = testGenerator(path,D,L)\n",
    "    \n",
    "    #perdict\n",
    "    results_P = model_P.predict(testGene_P, PARAM_N_TESTS, verbose=1)\n",
    "    results_C = model_C.predict(testGene_C, PARAM_N_TESTS, verbose=1)\n",
    "\n",
    "    np.save(PARAM_PATH_TEST_NPY_P, results_P)\n",
    "    saveResult(PARAM_PATH_TEST_RESULTS_P, results_P)\n",
    "    np.save(PARAM_PATH_TEST_NPY_C, results_C)\n",
    "    saveResult(PARAM_PATH_TEST_RESULTS_C, results_C)\n",
    "    \n",
    "    mergeIm(path, D, L, PARAM_PATH_TEST_RESULTS_P, path+'/'+D_P)\n",
    "    mergeIm(path, D, L, PARAM_PATH_TEST_RESULTS_C, path+'/'+D_C)\n",
    "    \n",
    "    #change file name of D_P, D_C\n",
    "    for count, filename in enumerate(os.listdir(path+'/'+D_P)): \n",
    "        dst = str(count) + \".tif\"\n",
    "        src = path+'/'+D_P+'/'+filenaLme\n",
    "        dst = path+'/'+D_P+'/'+dst\n",
    "\n",
    "        os.rename(src, dst) \n",
    "  \n",
    "    for count, filename in enumerate(os.listdir(path+'/'+D_C)): \n",
    "        dst = str(count) + \".tif\"\n",
    "        src = path+'/'+D_C+'/'+filename\n",
    "        dst = path+'/'+D_C+'/'+dst\n",
    "\n",
    "        os.rename(src, dst) \n",
    "    \n",
    "    #find the better one (based on L) and modify D_P, D_P_im, D_C, D_C_im\n",
    "    for file in os.listdir(D):\n",
    "        im_P = Image.open(path+'/'+D_P+'/'+file)\n",
    "        im_C = Image.open(path+'/'+D_C+'/'+file)\n",
    "        \n",
    "        if dscore(im_P, file) > dscore(im_C, file):\n",
    "            shutil.copyfile(path+'/'+D+'/'+file, path+'/'+D_P_im+'/'+file)\n",
    "            os.remove(path+'/'+D_C+'/'+file)\n",
    "        else:\n",
    "            shutil.copyfile(path+'/'+D+'/'+file, path+'/'+D_C_im+'/'+file)\n",
    "            os.remove(path+'/'+D_P+'/'+file)\n",
    "            \n",
    "    number_of_D_P = len(glob.glob(D_P))\n",
    "    number_of_D_C = len(glob.glob(D_C))\n",
    "\n",
    "    # file numbers difference\n",
    "    diff = Math.abs(prev_number_of_D_P - number_of_D_P + prev_number_of_D_C - number_of_D_C) / 2\n",
    "    \n",
    "    prev_number_of_D_P = number_of_D_P\n",
    "    prev_number_of_D_C = number_of_D_P\n",
    "    \n",
    "    #train model_P only on D_P, model_C only on D_C\n",
    "    myGene_P = trainGenerator(PARAM_BATCHES, \n",
    "                            path, \n",
    "                            D_P, \n",
    "                            D_P_im, \n",
    "                            PARAM_DATA_ARGS, \n",
    "                            save_to_dir = PARAM_AUG_FOLDER_P)\n",
    "    \n",
    "    myGene_C = trainGenerator(PARAM_BATCHES, \n",
    "                            path, \n",
    "                            D_C, \n",
    "                            D_C_im, \n",
    "                            PARAM_DATA_ARGS, \n",
    "                            save_to_dir = PARAM_AUG_FOLDER_C)\n",
    "    \n",
    "    model_checkpoint_P = ModelCheckpoint( PARAM_SAVED_MODEL, \n",
    "                                         monitor = PARAM_METRICS, \n",
    "                                         verbose = 1, \n",
    "                                         save_best_only = PARAM_SAVE_BEST_ONLY)\n",
    "    \n",
    "    model_P.fit_generator(myGene_P,\n",
    "                        steps_per_epoch = PARAM_EPOCH_STEPS,\n",
    "                        epochs = PARAM_N_EPOCHS,\n",
    "                        callbacks = [model_checkpoint])\n",
    "    model_C.fit_generator(myGene_C,\n",
    "                        steps_per_epoch = PARAM_EPOCH_STEPS,\n",
    "                        epochs = PARAM_N_EPOCHS,\n",
    "                        callbacks = [model_checkpoint])\n",
    "    \n",
    "    model_P.save_weights('model_P_weights_' + count)\n",
    "    model_C.save_weights('model_C_weights_' + count)\n",
    "    \n",
    "    shutil.rmtree(path+'/'+D_P)\n",
    "    shutil.rmtree(path+'/'+D_C)\n",
    "    shutil.rmtree(path+'/'+D_P_im)\n",
    "    shutil.rmtree(path+'/'+D_C_im)\n",
    "    \n",
    "\n",
    "save_model(model_P, 'model_P.h5')\n",
    "save_model(model_C, 'model_C.h5')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
