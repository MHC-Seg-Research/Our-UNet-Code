{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Approach for Unet Training \n",
    "\n",
    "------\n",
    "\n",
    "## Overview\n",
    "\n",
    "\n",
    "\n",
    "The purpose of this learn.ipynb notebook is to investigate whether an image can exhibit a preference for being segmented more effectively using a UNet model trained on polar or cartesian-dominant images.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Structure\n",
    "```\n",
    "data\n",
    "└── endoscopic\n",
    "    ├── cartesian\n",
    "    │   ├── image\n",
    "    │   └── label\n",
    "    └── polar\n",
    "        ├── image\n",
    "        └── label\n",
    "```\n",
    "\n",
    "Inside of each end folder there are 956 images, named as `0.tif` to `955.tif`\n",
    "and I believe, for now, the naming of the images are one to one correctly matched, meaning the ``/data/endoscopic/**cartesian**/image/0.tif`` is transformed from `/data/endoscopic/**polar**/image/0.tif`\n",
    "\n",
    "Instead of putting a seperate set of images aside to be test set, we chose to use k-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import from files and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from defines import *\n",
    "from model import *\n",
    "from data import *\n",
    "import sys\n",
    "\n",
    "from numpy import loadtxt\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import math\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this if your computer has a cuda visible device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PARAM_SYSTEM_TIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test code for correct file structure setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize folder tree in current directory\n",
    "os.system(\"tree -d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count of files in data directories\n",
    "os.system(\"ls \" + os.path.join(PARAM_PATH_CARTE,PARAM_IMG_FOLDER) + \" | wc -l\")\n",
    "os.system(\"ls \" + os.path.join(PARAM_PATH_CARTE,PARAM_MSK_FOLDER) + \" | wc -l\")\n",
    "os.system(\"ls \" + os.path.join(PARAM_PATH_POLAR,PARAM_IMG_FOLDER) + \" | wc -l\")\n",
    "os.system(\"ls \" + os.path.join(PARAM_PATH_POLAR,PARAM_MSK_FOLDER) + \" | wc -l\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output: \n",
    "956\n",
    "956\n",
    "956\n",
    "956\n",
    "**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training test\n",
    "\n",
    "This part is used to see if we can train a model using the current configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Superparameters (temporary) for a test run of model training test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 256, 256, 64  1792        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 256, 256, 64  36928       ['conv2d[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 128, 128, 64  0           ['conv2d_1[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 128, 128, 12  73856       ['max_pooling2d[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 128, 128, 12  147584      ['conv2d_2[0][0]']               \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0          ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 64, 64, 256)  295168      ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 64, 64, 256)  590080      ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0          ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 32, 32, 512)  1180160     ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 32, 32, 512)  2359808     ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 32, 32, 512)  0           ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0          ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 16, 16, 1024  4719616     ['max_pooling2d_3[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 16, 16, 1024  9438208     ['conv2d_8[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 16, 16, 1024  0           ['conv2d_9[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 32, 32, 1024  0           ['dropout_1[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 32, 32, 512)  2097664     ['up_sampling2d[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 32, 32, 1024  0           ['dropout[0][0]',                \n",
      "                                )                                 'conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 32, 32, 512)  4719104     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 512)  0          ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 64, 64, 256)  524544      ['up_sampling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 64, 64, 512)  0           ['conv2d_5[0][0]',               \n",
      "                                                                  'conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 64, 64, 256)  1179904     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 25  0          ['conv2d_15[0][0]']              \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 128, 128, 12  131200      ['up_sampling2d_2[0][0]']        \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 128, 128, 25  0           ['conv2d_3[0][0]',               \n",
      "                                6)                                'conv2d_16[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 128, 128, 12  295040      ['concatenate_2[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_17[0][0]']              \n",
      "                                8)                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 12  0          ['conv2d_18[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 256, 256, 64  32832       ['up_sampling2d_3[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 256, 256, 12  0           ['conv2d_1[0][0]',               \n",
      "                                8)                                'conv2d_19[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 256, 256, 64  73792       ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 256, 256, 64  36928       ['conv2d_20[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 256, 256, 9)  5193        ['conv2d_21[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 256, 256, 3)  30          ['conv2d_22[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,036,903\n",
      "Trainable params: 31,036,903\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-08 21:50:51.846431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-08 21:50:51.886756: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-08 21:50:51.888659: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-08 21:50:51.890892: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-08 21:50:51.891760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-08 21:50:51.893620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-08 21:50:51.895441: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-08 21:50:52.374047: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-08 21:50:52.375012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-08 21:50:52.375860: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-08 21:50:52.376695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3919 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:04:00.0, compute capability: 7.5\n",
      "/home/zyck/anaconda3/envs/unet/lib/python3.7/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "data_gen_args = dict(rotation_range=50,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    shear_range=0.35,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "temp_save_dir = os.path.join(os.getcwd(),'temp')\n",
    "test_gene = trainGenerator(batch_size, PARAM_PATH_POLAR, PARAM_IMG_FOLDER, PARAM_MSK_FOLDER, data_gen_args)\n",
    "test_model = unet() \n",
    "test_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected output\n",
    "<details>\n",
    "    <summary><b><font color=\"green\">Click here to expand</font></b></summary>\n",
    "    <code>\n",
    "Model: \"model_5\"\n",
    "__________________________________________________________________________________________________\n",
    " Layer (type)                   Output Shape         Param #     Connected to                     \n",
    "==================================================================================================\n",
    " input_6 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
    "                                )]                                                                \n",
    "                                                                                                  \n",
    " conv2d_120 (Conv2D)            (None, 256, 256, 64  1792        ['input_6[0][0]']                \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_121 (Conv2D)            (None, 256, 256, 64  36928       ['conv2d_120[0][0]']             \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " max_pooling2d_20 (MaxPooling2D  (None, 128, 128, 64  0          ['conv2d_121[0][0]']             \n",
    " )                              )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_122 (Conv2D)            (None, 128, 128, 12  73856       ['max_pooling2d_20[0][0]']       \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " conv2d_123 (Conv2D)            (None, 128, 128, 12  147584      ['conv2d_122[0][0]']             \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " max_pooling2d_21 (MaxPooling2D  (None, 64, 64, 128)  0          ['conv2d_123[0][0]']             \n",
    " )                                                                                                \n",
    "                                                                                                  \n",
    " conv2d_124 (Conv2D)            (None, 64, 64, 256)  295168      ['max_pooling2d_21[0][0]']       \n",
    "                                                                                                  \n",
    " conv2d_125 (Conv2D)            (None, 64, 64, 256)  590080      ['conv2d_124[0][0]']             \n",
    "                                                                                                  \n",
    " max_pooling2d_22 (MaxPooling2D  (None, 32, 32, 256)  0          ['conv2d_125[0][0]']             \n",
    " )                                                                                                \n",
    "                                                                                                  \n",
    " conv2d_126 (Conv2D)            (None, 32, 32, 512)  1180160     ['max_pooling2d_22[0][0]']       \n",
    "                                                                                                  \n",
    " conv2d_127 (Conv2D)            (None, 32, 32, 512)  2359808     ['conv2d_126[0][0]']             \n",
    "                                                                                                  \n",
    " dropout_10 (Dropout)           (None, 32, 32, 512)  0           ['conv2d_127[0][0]']             \n",
    "                                                                                                  \n",
    " max_pooling2d_23 (MaxPooling2D  (None, 16, 16, 512)  0          ['dropout_10[0][0]']             \n",
    " )                                                                                                \n",
    "                                                                                                  \n",
    " conv2d_128 (Conv2D)            (None, 16, 16, 1024  4719616     ['max_pooling2d_23[0][0]']       \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_129 (Conv2D)            (None, 16, 16, 1024  9438208     ['conv2d_128[0][0]']             \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " dropout_11 (Dropout)           (None, 16, 16, 1024  0           ['conv2d_129[0][0]']             \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " up_sampling2d_20 (UpSampling2D  (None, 32, 32, 1024  0          ['dropout_11[0][0]']             \n",
    " )                              )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_130 (Conv2D)            (None, 32, 32, 512)  2097664     ['up_sampling2d_20[0][0]']       \n",
    "                                                                                                  \n",
    " concatenate_20 (Concatenate)   (None, 32, 32, 1024  0           ['dropout_10[0][0]',             \n",
    "                                )                                 'conv2d_130[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_131 (Conv2D)            (None, 32, 32, 512)  4719104     ['concatenate_20[0][0]']         \n",
    "                                                                                                  \n",
    " conv2d_132 (Conv2D)            (None, 32, 32, 512)  2359808     ['conv2d_131[0][0]']             \n",
    "                                                                                                  \n",
    " up_sampling2d_21 (UpSampling2D  (None, 64, 64, 512)  0          ['conv2d_132[0][0]']             \n",
    " )                                                                                                \n",
    "                                                                                                  \n",
    " conv2d_133 (Conv2D)            (None, 64, 64, 256)  524544      ['up_sampling2d_21[0][0]']       \n",
    "                                                                                                  \n",
    " concatenate_21 (Concatenate)   (None, 64, 64, 512)  0           ['conv2d_125[0][0]',             \n",
    "                                                                  'conv2d_133[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_134 (Conv2D)            (None, 64, 64, 256)  1179904     ['concatenate_21[0][0]']         \n",
    "                                                                                                  \n",
    " conv2d_135 (Conv2D)            (None, 64, 64, 256)  590080      ['conv2d_134[0][0]']             \n",
    "                                                                                                  \n",
    " up_sampling2d_22 (UpSampling2D  (None, 128, 128, 25  0          ['conv2d_135[0][0]']             \n",
    " )                              6)                                                                \n",
    "                                                                                                  \n",
    " conv2d_136 (Conv2D)            (None, 128, 128, 12  131200      ['up_sampling2d_22[0][0]']       \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " concatenate_22 (Concatenate)   (None, 128, 128, 25  0           ['conv2d_123[0][0]',             \n",
    "                                6)                                'conv2d_136[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_137 (Conv2D)            (None, 128, 128, 12  295040      ['concatenate_22[0][0]']         \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " conv2d_138 (Conv2D)            (None, 128, 128, 12  147584      ['conv2d_137[0][0]']             \n",
    "                                8)                                                                \n",
    "                                                                                                  \n",
    " up_sampling2d_23 (UpSampling2D  (None, 256, 256, 12  0          ['conv2d_138[0][0]']             \n",
    " )                              8)                                                                \n",
    "                                                                                                  \n",
    " conv2d_139 (Conv2D)            (None, 256, 256, 64  32832       ['up_sampling2d_23[0][0]']       \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " concatenate_23 (Concatenate)   (None, 256, 256, 12  0           ['conv2d_121[0][0]',             \n",
    "                                8)                                'conv2d_139[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_140 (Conv2D)            (None, 256, 256, 64  73792       ['concatenate_23[0][0]']         \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_141 (Conv2D)            (None, 256, 256, 64  36928       ['conv2d_140[0][0]']             \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " conv2d_142 (Conv2D)            (None, 256, 256, 9)  5193        ['conv2d_141[0][0]']             \n",
    "                                                                                                  \n",
    " conv2d_143 (Conv2D)            (None, 256, 256, 3)  30          ['conv2d_142[0][0]']             \n",
    "                                                                                                  \n",
    "==================================================================================================\n",
    "Total params: 31,036,903\n",
    "Trainable params: 31,036,903\n",
    "Non-trainable params: 0\n",
    "</code>\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint('unet_endoscopic.hdf5', monitor = 'loss', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 956 images belonging to 1 classes.\n",
      "Found 956 images belonging to 1 classes.\n",
      "Epoch 1/12\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f434919bdd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f434919bdd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-08 21:50:58.348986: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n",
      "2023-09-08 21:50:58.785401: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - ETA: 0s - loss: 0.2711 - accuracy: 0.3481\n",
      "Epoch 1: loss improved from inf to 0.27109, saving model to unet_endoscopic.hdf5\n",
      "500/500 [==============================] - 70s 131ms/step - loss: 0.2711 - accuracy: 0.3481\n",
      "Epoch 2/12\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2389 - accuracy: 0.3188\n",
      "Epoch 2: loss improved from 0.27109 to 0.23889, saving model to unet_endoscopic.hdf5\n",
      "500/500 [==============================] - 66s 132ms/step - loss: 0.2389 - accuracy: 0.3188\n",
      "Epoch 3/12\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2233 - accuracy: 0.3360\n",
      "Epoch 3: loss improved from 0.23889 to 0.22332, saving model to unet_endoscopic.hdf5\n",
      "500/500 [==============================] - 66s 132ms/step - loss: 0.2233 - accuracy: 0.3360\n",
      "Epoch 4/12\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2159 - accuracy: 0.2968\n",
      "Epoch 4: loss improved from 0.22332 to 0.21588, saving model to unet_endoscopic.hdf5\n",
      "500/500 [==============================] - 66s 133ms/step - loss: 0.2159 - accuracy: 0.2968\n",
      "Epoch 5/12\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2082 - accuracy: 0.3212\n",
      "Epoch 5: loss improved from 0.21588 to 0.20816, saving model to unet_endoscopic.hdf5\n",
      "500/500 [==============================] - 66s 132ms/step - loss: 0.2082 - accuracy: 0.3212\n",
      "Epoch 6/12\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2029 - accuracy: 0.2825\n",
      "Epoch 6: loss improved from 0.20816 to 0.20286, saving model to unet_endoscopic.hdf5\n",
      "500/500 [==============================] - 66s 133ms/step - loss: 0.2029 - accuracy: 0.2825\n",
      "Epoch 7/12\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1947 - accuracy: 0.3082\n",
      "Epoch 7: loss improved from 0.20286 to 0.19474, saving model to unet_endoscopic.hdf5\n",
      "500/500 [==============================] - 66s 133ms/step - loss: 0.1947 - accuracy: 0.3082\n",
      "Epoch 8/12\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1914 - accuracy: 0.3039\n",
      "Epoch 8: loss improved from 0.19474 to 0.19144, saving model to unet_endoscopic.hdf5\n",
      "500/500 [==============================] - 66s 133ms/step - loss: 0.1914 - accuracy: 0.3039\n",
      "Epoch 9/12\n",
      " 42/500 [=>............................] - ETA: 1:00 - loss: 0.2039 - accuracy: 0.2452"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31705/2394982297.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_gene\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1399\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m           \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_load_initial_step_from_ckpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1402\u001b[0m             with tf.profiler.experimental.Trace(\n\u001b[1;32m   1403\u001b[0m                 \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.7/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1246\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1248\u001b[0;31m       \u001b[0moriginal_spe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1249\u001b[0m       can_run_full_execution = (\n\u001b[1;32m   1250\u001b[0m           \u001b[0moriginal_spe\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unet/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    639\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_run = test_model.fit(test_gene, verbose = 1, steps_per_epoch = 500, epochs = 12, callbacks = [model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(test_run.history.keys())\n",
    "plt.plot(test_run.history['loss'])\n",
    "plt.plot(test_run.history['accuracy'])\n",
    "plt.title('Test Run')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss', 'accuracy'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAM_PATH_TEST = './test'\n",
    "image_name = '29.tif'\n",
    "img = io.imread(os.path.join(PARAM_PATH_TEST,image_name),as_gray = False)\n",
    "img = trans.resize(img,[256,256])\n",
    "img = np.reshape(img,(1,)+img.shape)\n",
    "\n",
    "results = test_model.predict(img,1,verbose=1)\n",
    "#saveResult(Path,results)\n",
    "img = results[0,:,:]\n",
    "print(results.shape)\n",
    "io.imsave(os.path.join(PARAM_PATH_TEST,\"result.png\"),img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Relocation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following block, the code loads in one analysis file from previous research. \n",
    "\n",
    "### #File name postfix\n",
    "_C_ is the dice scores of the predictions generated by Unet C: this Unet C is trained using all 7404 images, in their cartesian form. The raw image was directly input into the Unet and the prediction was generated.\n",
    "\n",
    "_P_ is the dice scores of the predictions generated by Unet P: this Unet P is trained using all 7404 images but in their polar form. The raw images were transformed, and then input for prediction. The prediction is in polar space.\n",
    "\n",
    "_P2C_ is the dice scores of the predictions generated by the same Unet P as mentioned above, but the dice score is generated by transforming the prediction back to cartesian, and compared to their original label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[311  80 602 127 611 462 459 480 335 105 385 481 135 585 779 468 295 519\n",
      " 308 761 448 107 492 450 464 552 636 251  82 626 929 210 487 526 764 898\n",
      " 366 274 691 357 329 358 103 623 296 598 925 409 558 264 232 550 168 440\n",
      " 208 582 279 690 292 413 347 469 543 436 621 239 402 390 383 306 233 411\n",
      " 404 874 129 212 258 537 316 876 289 255 541 236 323 689 427 542 363 555\n",
      " 235 476 579 434 257 624 302 620  93 380 527 388 649 586 328 576 449 237\n",
      " 229 167 938 359 360 580 696 424 330 688 622 619  85 687 885 452 429 630\n",
      " 748 151 310  86 287  79  94 417 231 399 166 933 447 453 698 955 821 815\n",
      " 322 100 150 221 540 227 332 581  25 158 819 789 587 600 474 837 441 280\n",
      " 663 343 346 240 501 693 433 498 613 794 734 377 467 507 842 386 880 694\n",
      " 606 524 438 678 922 410 270 356 217 610 868 771 291 795 455 446 485 822\n",
      " 545 563 163 209 605 593 286 858 886 353 916 538 225 394 336 677 520 325\n",
      " 735 669 705 604 248 557 570  84 567 318 493 338 941 238 566  60 554 334\n",
      " 583  73 724 373 816 888 374 503 215 572 261 548 199 818 268 872 912 758\n",
      "  17 573 918 477 309 130 733 228 490 668 219 108 494 878 518 216 713 924\n",
      " 275 451 592 285 426 400 473 650 315 680 382 299 827 301 327 908 500 118\n",
      " 512 877 283 230 403 123 475 170 278 104 437 304 533 133 635 122 665 460\n",
      " 612 850 271 931 497 556 596  41 326 627 812 666 608 491 314 909 364 432\n",
      " 631 879 465 395 836 418 478 675 838 739 851 134 184 281 406 803 241 484\n",
      " 616 706 531 119 137 740 171 320 926 897 662 601 454 773 720 341 571 443\n",
      " 389 860 243 423 823 508 753 609 222 276 813 676 539 763 928 249 584 762\n",
      " 575  75 591 808 505 250 414 535 504 904 564 792 546 511 679 923 244 632\n",
      " 765 408 155 430 361 515  76 652 114 736 431 715 331  89 692 801 391 884\n",
      "  24 182 798  95 317 536 825 290 115 939 671 140  90 479  99 721 737 590\n",
      " 495 532 654 183 398 862 717 772 776 172 919 456 143 405 126 746 110  22\n",
      " 643 786 367 340 435 804 639 766 703 218 656 778 224 852 849 303 266 634\n",
      " 863 870 718 136 169 708 950 607 288 659 603  87 814 755 214 657 920 412\n",
      " 568 179 749 948 245 809 817 873 944 305 932  13 854 407 174 561 633 496\n",
      " 588 700  66 684 267  88 510 297 902 148 578  72 307 949 707 387 853 569\n",
      " 747 843 375 159 144 203 269 855 378  91 913 482 658 670 784 793 785 101\n",
      " 889 899 161 352 722 754 895  54 252 529 176 472 915 653 917 422 350 177\n",
      " 732 260 790 401 697 911 223 832 642 799 124 284 725  44 139 660 120 160\n",
      " 234  26 901 702 835 516 300 887 420 629 712  12 370 458 379  30  28 147\n",
      " 672 759 942 157 502 637 132 165  53 313 198 714 298 704 439 952 125 614\n",
      " 577  97 534   4 796 553 369 559 807 173 767 372 867 499 953 841 647 640\n",
      " 738 806 396 188 488 686 149 457 337 428 141 220 805 113   3 954 153 681\n",
      "   5  32 185 770  29 892 846  58 726 896 321 882  96 800 324 664 344 191\n",
      "  70 466  21 727 181  23 211 645  38 549 934 196 930 121 900  31 861 810\n",
      " 840 560 146 162 711  43 864   1 741  59  69 351  74 847  34 787 780 906\n",
      " 263 685 845 376 272 774 797 875 728 701 445 444 415 154  42 615 190  45\n",
      " 242 638 197 349 857 914 723 871 164 152 547 365 788 470 425 682 461 673\n",
      " 757 729 751 760  57 345 869 397 371 683 180 293 826 205 294 509 937 756\n",
      "  56  50 368 514 782 513 951 419 392 945 265 618  55  77 421 339 142 106\n",
      "  92 947 903 791 354 111  62  49 699 525  71  78 483 262 695 617  27 145\n",
      " 521  98 138 935 859  48 828 574  36 674 175 384 348 802   6 648 881  15\n",
      " 156  81 943 921 768 731 834 116 523 277 848 709 416 775  11 856  16 625\n",
      " 730 865 112  51 641 195  83  68 824 273 207 710  10 719 193 866 226 651\n",
      " 910 646 544 194 839  64 752 750 597 783 716 551 769 667 893  46 927 247\n",
      " 565 381  67 946 599 661 830 486 201 628 781 362 644 522 246 905 189  35\n",
      " 562 204 833  18 442 528 282 506 355  19 907  63 200  52 192  47   0  39\n",
      "  61  37 102 811 844 131 831 883 890   7 820 128 517 744 471 186 333  40\n",
      " 319  14 594 891   8  20 117 489 595 743 745 178 936 589   9 530 342 202\n",
      " 254 463 742 393 829 655  65 256 253  33 187 940 312 213   2 894 259 206\n",
      " 109 777]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#file_name = 'analysis_dice_back_Test_C.npy'\n",
    "file_name = 'analysis_dice_back_Test_P.npy'\n",
    "#file_name = 'analysis_dice_back_Test_P2C.npy'\n",
    "np_file = os.path.join(PARAM_PATH_SCORES, file_name)\n",
    "#load npy file\n",
    "img_score = np.load(np_file)\n",
    "#sort scores in descending order and store index\n",
    "sorted_score = np.flip(np.argsort(img_score))\n",
    "print(sorted_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch top polar dominant and non-polar dominant image\n",
    "num_polar = round(len(sorted_score)/2)\n",
    "num_cartesian = len(sorted_score) - num_polar\n",
    "dfPolar = sorted_score.head(num_polar)\n",
    "dfCartesian = sorted_score.tail(num_cartesian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new directories for polar dominant images and cartesian dominant images based on sorted dice scores\n",
    "\n",
    "if os.path.exists(PARAM_PATH_TEMP_POLAR):\n",
    "    shutil.rmtree(PARAM_PATH_TEMP_POLAR)\n",
    "os.makedirs(PARAM_PATH_TEMP_POLAR)\n",
    "\n",
    "if os.path.exists(PARAM_PATH_TEMP_CARTE):\n",
    "    shutil.rmtree(PARAM_PATH_TEMP_CARTE)\n",
    "os.makedirs(PARAM_PATH_TEMP_CARTE)\n",
    "\n",
    "for img in dfPolar:\n",
    "    img_name = img + \".tif\"\n",
    "    src = os.path.join(PARAM_PATH_POLAR, img_name)\n",
    "    shutil.copy2(src, PARAM_PATH_TEMP_POLAR)\n",
    "\n",
    "for img in dfCartesian:\n",
    "    img_name = img + \".tif\"\n",
    "    src = os.path.join(PARAM_PATH_CARTE, img_name)\n",
    "    shutil.copy2(src, PARAM_PATH_TEMP_CARTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K fold Validation (obtain training & testing sets)\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits=PARAM_SPLIT_NUM)\n",
    "for train_index,test_index in kfold.split(dfPolar):\n",
    "    polar_train,polar_test=dfPolar[train_index],dfPolar[test_index]\n",
    "    cartesian_train,cartesian_test=dfCartesian[train_index],dfCartesian[test_index]\n",
    "    print(polar_train,polar_test)\n",
    "    print(cartesian_train,cartesian_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy Code Below\n",
    "### written by Wenfan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from defines import *\n",
    "from model import *\n",
    "from data import *\n",
    "import sys\n",
    "\n",
    "from numpy import loadtxt\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "\n",
    "import glob\n",
    "import os \n",
    "import math\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data_jupyter'# main folder path\n",
    "\n",
    "D = 'all_images'\n",
    "L = 'all_labels'\n",
    "\n",
    "D_P_im = 'polar_im'\n",
    "D_C_im = 'car_im'\n",
    "D_P = 'polar_l'\n",
    "D_C = 'car_l'\n",
    "\n",
    "prev_number_of_D_P = -1\n",
    "prev_number_of_D_C = -1\n",
    "\n",
    "diff = math.inf\n",
    "\n",
    "model_P = unet(PARAM_BETA1[PARAM_BETA_TEST_NUM], PARAM_BETA2[PARAM_BETA_TEST_NUM])\n",
    "model_C = unet(PARAM_BETA1[PARAM_BETA_TEST_NUM], PARAM_BETA2[PARAM_BETA_TEST_NUM])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill in the weights here\n",
    "model_P.load_weights() \n",
    "model_C.load_weights() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "#change file name of D, L\n",
    "for count, filename in enumerate(os.listdir(path+'/'+D)): \n",
    "    dst = str(count) + \".png\"\n",
    "    src = path+'/'+D+'/'+filename\n",
    "    dst = path+'/'+D+'/'+dst\n",
    "\n",
    "    os.rename(src, dst) \n",
    "    \n",
    "for count, filename in enumerate(os.listdir(path+'/'+L)): \n",
    "    dst = str(count) + \".tif\"\n",
    "    src = path+'/'+L+'/'+filename\n",
    "    dst = path+'/'+L+'/'+dst\n",
    "\n",
    "    os.rename(src, dst) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dscore(im, im_name):\n",
    "    label = Image.open(os.path.join(L, im_name))\n",
    "    \n",
    "    pixelIm = im.load()\n",
    "    pixelLabel = label.load()\n",
    "    \n",
    "    upper = 0\n",
    "    lower = im.size[0] * im.size[1]\n",
    "    \n",
    "    for i in range(im.size[0]):\n",
    "        for j in range(im.size[1]):\n",
    "            if pixelIm[i,j] == pixelLabel[i,j]:\n",
    "                upper = upper + 1\n",
    "            \n",
    "    upper = upper * 2\n",
    "    \n",
    "    return upper / lower\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while (diff > 0): \n",
    "    #load model\n",
    "    #if count > 0:\n",
    "    #    model_P.load_weights('model_P_weights_' + (count - 1))\n",
    "    #    model_C.load_weights('model_C_weights_' + (count - 1))\n",
    "    \n",
    "    count = count + 1\n",
    "    \n",
    "    testGene_P, testGene_C = testGenerator(path,D,L)\n",
    "    \n",
    "    #perdict\n",
    "    results_P = model_P.predict(testGene_P, PARAM_N_TESTS, verbose=1)\n",
    "    results_C = model_C.predict(testGene_C, PARAM_N_TESTS, verbose=1)\n",
    "\n",
    "    np.save(PARAM_PATH_TEST_NPY_P, results_P)\n",
    "    saveResult(PARAM_PATH_TEST_RESULTS_P, results_P)\n",
    "    np.save(PARAM_PATH_TEST_NPY_C, results_C)\n",
    "    saveResult(PARAM_PATH_TEST_RESULTS_C, results_C)\n",
    "    \n",
    "    mergeIm(path, D, L, PARAM_PATH_TEST_RESULTS_P, path+'/'+D_P)\n",
    "    mergeIm(path, D, L, PARAM_PATH_TEST_RESULTS_C, path+'/'+D_C)\n",
    "    \n",
    "    #change file name of D_P, D_C\n",
    "    for count, filename in enumerate(os.listdir(path+'/'+D_P)): \n",
    "        dst = str(count) + \".tif\"\n",
    "        src = path+'/'+D_P+'/'+filenaLme\n",
    "        dst = path+'/'+D_P+'/'+dst\n",
    "\n",
    "        os.rename(src, dst) \n",
    "  \n",
    "    for count, filename in enumerate(os.listdir(path+'/'+D_C)): \n",
    "        dst = str(count) + \".tif\"\n",
    "        src = path+'/'+D_C+'/'+filename\n",
    "        dst = path+'/'+D_C+'/'+dst\n",
    "\n",
    "        os.rename(src, dst) \n",
    "    \n",
    "    #find the better one (based on L) and modify D_P, D_P_im, D_C, D_C_im\n",
    "    for file in os.listdir(D):\n",
    "        im_P = Image.open(path+'/'+D_P+'/'+file)\n",
    "        im_C = Image.open(path+'/'+D_C+'/'+file)\n",
    "        \n",
    "        if dscore(im_P, file) > dscore(im_C, file):\n",
    "            shutil.copyfile(path+'/'+D+'/'+file, path+'/'+D_P_im+'/'+file)\n",
    "            os.remove(path+'/'+D_C+'/'+file)\n",
    "        else:\n",
    "            shutil.copyfile(path+'/'+D+'/'+file, path+'/'+D_C_im+'/'+file)\n",
    "            os.remove(path+'/'+D_P+'/'+file)\n",
    "            \n",
    "    number_of_D_P = len(glob.glob(D_P))\n",
    "    number_of_D_C = len(glob.glob(D_C))\n",
    "\n",
    "    # file numbers difference\n",
    "    diff = Math.abs(prev_number_of_D_P - number_of_D_P + prev_number_of_D_C - number_of_D_C) / 2\n",
    "    \n",
    "    prev_number_of_D_P = number_of_D_P\n",
    "    prev_number_of_D_C = number_of_D_P\n",
    "    \n",
    "    #train model_P only on D_P, model_C only on D_C\n",
    "    myGene_P = trainGenerator(PARAM_BATCHES, \n",
    "                            path, \n",
    "                            D_P, \n",
    "                            D_P_im, \n",
    "                            PARAM_DATA_ARGS, \n",
    "                            save_to_dir = PARAM_AUG_FOLDER_P)\n",
    "    \n",
    "    myGene_C = trainGenerator(PARAM_BATCHES, \n",
    "                            path, \n",
    "                            D_C, \n",
    "                            D_C_im, \n",
    "                            PARAM_DATA_ARGS, \n",
    "                            save_to_dir = PARAM_AUG_FOLDER_C)\n",
    "    \n",
    "    model_checkpoint_P = ModelCheckpoint( PARAM_SAVED_MODEL, \n",
    "                                         monitor = PARAM_METRICS, \n",
    "                                         verbose = 1, \n",
    "                                         save_best_only = PARAM_SAVE_BEST_ONLY)\n",
    "    \n",
    "    model_P.fit_generator(myGene_P,\n",
    "                        steps_per_epoch = PARAM_EPOCH_STEPS,\n",
    "                        epochs = PARAM_N_EPOCHS,\n",
    "                        callbacks = [model_checkpoint])\n",
    "    model_C.fit_generator(myGene_C,\n",
    "                        steps_per_epoch = PARAM_EPOCH_STEPS,\n",
    "                        epochs = PARAM_N_EPOCHS,\n",
    "                        callbacks = [model_checkpoint])\n",
    "    \n",
    "    model_P.save_weights('model_P_weights_' + count)\n",
    "    model_C.save_weights('model_C_weights_' + count)\n",
    "    \n",
    "    shutil.rmtree(path+'/'+D_P)\n",
    "    shutil.rmtree(path+'/'+D_C)\n",
    "    shutil.rmtree(path+'/'+D_P_im)\n",
    "    shutil.rmtree(path+'/'+D_C_im)\n",
    "    \n",
    "\n",
    "save_model(model_P, 'model_P.h5')\n",
    "save_model(model_C, 'model_C.h5')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
